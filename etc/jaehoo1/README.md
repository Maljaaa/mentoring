# ETC

## 블락 논블락/싱크 어싱크

### 블럭 / 논블럭
함수 호출에 대한 이야기. 기술적으로 명확히 구분된다.  
  
**Block**
* 함수 A를 호출했을 때, 함수 A의 수행이 모두 끝날 때 까지 기다린다(Block)
* 함수 A의 수행이 모두 끝나고 리턴되면, 함수 A를 호출한 부분의 다음 부분부터 이어서 실행한다.
* 호출된 함수가 자신이 할 일을 모두 마칠 때까지 제어권을 계속 가지고서 호출한 함수에게 바로 return하지 않으면 Block이다.

**Non-Block**
* 함수 A를 호출했을 때, 함수 A의 실행을 요청하고 바로 리턴된다(Non-Block).
* 호출된 함수가 자신이 할 일을 마치지 않았더라도 바로 제어권을 바로 return하여 호출한 함수가 다른 일을 진행할 수 있도록 하면 Non-Block이다.

### 동기 / 비동기
행위에 대한 이야기. 기술적으로는 구분되지 않지만 추상적으로 구분한다.  
  
작업A와 작업B가 있다고 함  
**Synchronous**
* 작업A가 먼저 모두 처리되고 나서 작업 B가 처리되기 시작하면(하나씩 순차적으로 처리되면) 동기이다.
* 작업A가 작업B를 관찰하는 작업이라면, 작업A와 작업B가 동시에 처리되더라도 동기이다. (여기서 작업A와 작업B를 서로 바꾸어 생각해도 똑같다.)
* 호출된 함수의 수행 결과 및 종료를 호출된 함수 뿐 아니라 호출한 함수도 함께 신경쓰면 동기이다.

**Asynchoronous**
* 작업A와 작업B가 동시에 처리되면 비동기이다.
* 작업A와 작업B는 인과관계가 있어야 한다.
* 작업A와 작업B가 인과관계가 없으면, 동시에 처리되더라도 비동기라고 볼 수 없다.
* 호출된 함수의 수행 결과 및 종료를 호출된 함수 혼자 직접 신경쓰고 처리하면 비동기이다.

### 조합
**블럭 & 동기**  
![image](https://user-images.githubusercontent.com/44667299/163563806-c9df9aed-9019-4364-9aac-addb9ed0c625.png)  
A가 실행되다가 B라는 일을 수행하는 함수를 호출해서 B를 시작한다. B라는 일이 끝나면 함수를 리턴한다. A와 B는 순차적으로 진행되기 때문에 동기이며,  B라는 일을 하는 함수를 호출하고 그 일이 끝나고 나서야 리턴되므로 블럭된 것이다. 따라서 블럭/동기
>손님 : 아메리카노 주문  
>직원 : 아메리카노 만드는 중  
>손님 : (그 자리에 서서 기다리는 중. 결과가 궁금함. 테이블 못가고 서있음.)

<br/>

**블럭 & 비동기**  
![image](https://user-images.githubusercontent.com/44667299/163564201-001675ce-4280-4e0e-8d1d-f7069f3c77af.png)  
A는 B라는 일을 시킨다. 그리고 바로 리턴하고 (여기서는 논블럭)  B는 일을 시작하고, A도 자신의 일을 한다. A는 중간에 B라는 일이 하는 중간 결과를 보고 받아서 처리해야한다. A는 B에게 요청을 해서 중간결과를 기다린다(블록), 요청의 결과를 받고 나서 그 결과를 이용해서 A는 자신의 일을 처리한다. 동시에 B 는 또 자신의 일을 동시에 한다. (비동기) A는 다시 B에게 중간결과를 요청해서 기다린다 (블록) , 요청의 결과를 받고 A는 자신의 일을, B는 자신의 일을 한다. 반복된다.  
  
이 글을 읽고, 사실 갸우뚱 해야한다. 중간에 블록되는 동안에는 "동기" 라고 말할 수 있기 때문이다. 즉 어느 한 순간에 대해 해석하자면 틀릴 수도 있는 것이다. "정답"이 존재하지 않는다. 다만 이런 패턴들이 분명히 사용되고 있구나라고 감을 잡는게 목적이다.  
  
블럭 & 비동기는 결국 다른 작업이 끝날 때를 기다려야 하기 때문에 동기 & 비동기와 비슷한 효율이 나온다.
>손님 : 아메리카노 주문  
>직원 : 아메리카노 만드는중  
>손님 : (안궁금함. 테이블에 가고싶지만 못가고 서있음.)

<br/>

**논블럭 & 동기**  
![image](https://user-images.githubusercontent.com/44667299/163564556-a463f3ac-de02-431a-95aa-88ccea5ad7f3.png)  
A는 B라는 일을 시킨다. 바로 리턴한다. (논블럭) B는 일을 시작하는데, A는 자신의 일을 하지 않는다. A의 하는 일이란 그저 B가 하는 일을 확인하는 것이다. B가 결과 보고(중간 보고가 아니다) 를 했는지를 확인하는 함수를 호출하고, 바로 리턴한다 (논블럭) 즉 결과 보고를 받을 때 까지 기다리는게 아니라, 결과 보고가 나왔는지 확인하고 바로 리턴하는 것이다. 이 짓을 계속한다. 즉 함수를 계속 논블럭으로 호출되긴 하나, A는 그저 B를 염탐할 뿐이다. 이 상태를 말한다. 그냥 염탐하지 말고 B가 일을 모두 끝마치고 리턴되길 기다리지(그냥 블럭/동기로 하는게 나은 상황이 연출된다)  
  
이후에 B가 결과보고를 하면, B는 자신의 일이 끝난 것이고 A는 이제서야 자신의 일을 처리하게 된다. 즉 순차적이라는 말이다. 따라서 동기  
  
논블로킹으로 자신의 작업을 계속하고 있지만 다른 작업과의 동기를 위해 계속해서 다른 작업이 끝났는지 조회한다. 즉, 호출된 함수가 호출한 함수에게 제어권을 바로 return하여 호출한 함수가 다른 업무를 볼 수 있었음(Non-Blocked)에도 불구하고, 여전히 호출된 함수의 업무 결과에만 계속 함께 신경쓰느라(Synchronous) 제 할일을 못하게 되는 현상이 일어난다. 논블럭 & 동기도 효율이 좋지 않다.
>손님 : 아메리카노 주문  
>직원 : 아메리카노 만드는중  
>손님 : 재촉

<br/>

**논블럭 & 비동기**  
![image](https://user-images.githubusercontent.com/44667299/163565103-59e46cb6-9f78-4626-95eb-41cc4cad0778.png)  
A는 B의 일을 시작시키고 바로 리턴한다. (논블럭) 그리고 A와B는 각자 자신의 일을 한다. (비동기)  
  
자원이 충분하다면 효율이 좋다. 자신의 작업이 멈추지도 않고, 다른 주체가 하는 작업의 결과가 나왔을 때 콜백을 설정하기도 한다. 다른 주체에게 작업을 맡겨놓고 자신이 하던 일을 계속할 수 있기 때문에 해야 할 작업이 대규모이고, 동기가 필요하지 않을 때 효과적이다.
>손님 : 아메리카노 주문  
>직원 : 아메리카노 만드는 중  
>손님 : 자리가서 SNS, 유튜브 시청  
>직원 : 아메리카노 제작 완료

<br/>

출처 : https://hamait.tistory.com/930  
사진 출처 : https://velog.io/@leehyunho2001/%EB%8F%99%EA%B8%B0-%EB%B9%84%EB%8F%99%EA%B8%B0-%EB%B8%94%EB%9F%AD-%EB%84%8C%EB%B8%94%EB%9F%AD

### 결론
정답은 없다.  
  
1 구분하지 않는다.  
  
블럭/동기는 같이 말하며, 논블럭/비동기도 함께 묶어 말한다.  
애초에 구분할 필요가 없다.  

<br/>

2 굳이 구분할 경우  
  
블럭/논블럭은 동시성과는 무관한 이야기이다. 단지 메서드 호출한 후로 시간이 오래 걸리면 블로킹이다. 즉 메서드가 얼마나 오래 걸리냐의 문제로 블록과 논블록은 귀결된다.

## WebServer VS WebApplicationServer

### WebServer
웹 브라우저의 요청을 받아 HTTP를 통해 웹 브라우저에서 요청하는 HTML 문서나 오브젝트(이미지 파일 등)를 전송해주는 서버  
>예 : Apache HTTP Server, Microsoft Internet Information Service, Google Web Server 등

### WebApplicationServer
사용자에게 동적 서비스를 제공하기 위해 웹 서버로부터 요청을 받아 데이터 처리를 수행하거나, 웹 서버와 데이터베이스 서버 또는 웹 서버와 파일 서버 사이에서 인터페이스 역할을 수행하는 서버
>예 : Oracle WebLogic, Apache Tomcat, IBM WebSphere, JEUS 등

### WebServer가 필요한 이유?
* 클라이언트(웹 브라우저)에 이미지 파일(정적 컨텐츠)을 보내는 과정
  * 이미지 파일과 같은 정적인 파일들은 웹 문서(HTML 문서)가 클라이언트로 보내질 때 함께 가는 것이 아니다.
  * 클라이언트는 HTML 문서를 먼저 받고 그에 맞게 필요한 이미지 파일들을 다시 서버로 요청하면 그때서야 이미지 파일을 받아온다.
  * Web Server를 통해 정적인 파일들을 Application Server까지 가지 않고 앞단에서 빠르게 보내줄 수 있다.
* 따라서 Web Server에서는 정적 컨텐츠만 처리하도록 기능을 분배하여 서버의 부담을 줄일 수 있다.

### WAS가 필요한 이유?
* 웹 페이지는 정적 컨텐츠와 동적 컨텐츠가 모두 존재
  * 사용자의 요청에 맞게 적절한 동적 컨텐츠를 만들어서 제공해야 한다.
  * 이때, WebServer만을 이용한다면 사용자가 원하는 요청에 대한 결과값을 모두 미리 만들어 놓고(정적 컨텐츠) 서비스를 해야 한다.
  * 하지만 이렇게 수행하기에는 자원이 절대적으로 부족하다.
* 따라서 WAS를 통해 요청에 맞는 데이터를 DB에서 가져와서 비즈니스 로직에 맞게 그때 그때 결과를 만들어서 제공함으로써 자원을 효율적으로 사용할 수 있다.

### 그렇다면 WAS가 Web Server의 기능도 모두 수행하면 되지 않을까? X
* 기능을 분리하여 서버 부하 방지
  * WAS는 DB 조회나 다양한 로직을 처리하느라 바쁘기 때문에 단순한 정적 컨텐츠는 WebServer에서 빠르게 클라이언트에 제공하는 것이 좋다.
  * WAS는 기본적으로 동적 컨텐츠를 제공하기 위해 존재하는 서버이다.
  * 만약 정적 컨텐츠 요청까지 WAS가 처리한다면 정적 데이터 처리로 인해 부하가 커지게 되고, 동적 컨텐츠의 처리가 지연됨에 따라 수행 속도가 느려진다.
  * 즉, 이로 인해 페이지 노출 시간이 늘어나게 될 것이다.
* 물리적으로 분리하여 보안 강화
  * SSL에 대한 암복호화 처리에 WebServer를 사용
* 여러 대의 WAS를 연결 가능
  * Load Balancing을 위해서 WebServer를 사용
  * fail over(장애 극복), fail back 처리에 유리
  * 특히 대용량 웹 어플리케이션의 경우(여러 개의 서버 사용) WebServer와 WAS를 분리하여 무중단 운영을 위한 장애 극복에 쉽게 대응할 수 있다.
  * 예를 들어, 앞 단의 WebServer에서 오류가 발생한 WAS를 이용하지 못하도록 한 후 WAS를 재시작함으로써 사용자는 오류를 느끼지 못하고 이용할 수 있다.
* 여러 웹 어플리케이션 서비스 가능
  * 예를 들어, 하나의 서버에서 PHP Application과 Java Application을 함께 사용하는 경우
* 기타
  * 접근 허용 IP 관리, 2대 이상의 서버에서의 세션 관리 등도 WebServer에서 처리하면 효율적이다.

즉, 자원 이용의 효율성 및 장애 극복, 배포 및 유지보수의 편의성을 위해 Web Server와 WAS를 분리한다.  
WebServer를 WAS 앞에 두고 필요한 WAS들을 WebServer에 플러그인 형태로 설정하면 더욱 효율적인 분산 처리가 가능하다.

>failover : 시스템, 서버, 네트워크가 이상이 생겼을 경우 예비시스템으로 전환되는 기능  
>failback : failover에 따라 전환된 서버/시스템/네트워크를 장애 발생전으로 되돌리는 처리

## Monolithic service Application VS Micro Service Application
MSA는 Micro Service Architecture의 줄임말로서 하나의 큰 어플리케이션을 여러 개의 작은 어플리케이션으로 나눠 만드는 아키텍쳐다. MSA가 등장하기 이전에는 하나의 서비스는 하나의 어플리케이션으로 만드는 것이 일반적이었고, 이를 Monolithic architecture, 모놀리식 아키텍쳐 라고 한다.

### Monolithic Architecture
하나의 프로젝트에 대해서 하나의 어플리케이션이 대응. 때문에 이 어플리케이션은 큰 규모를 이루게 된다.  
  
장점
* 로컬 환경에서 개발이 편리
* 통합 시나리오 테스트 진행이 수월
* 배포가 간편

단점
* 코드의 수정 및 추가가 힘듦
* 효율적인 자원 관리가 힘듦
* 자주 업데이트 불가능
* 새로운 기술 적용이 힘듦
* 부분의 장애가 서비스 전체적인 장애
* scale out이 불가능
>scale out  
>서버를 운영하다보면 갑작스런 이용자의 증가, 사업 확장 등의 이유로 더 많은 서버 용량과 성능이 필요하게 된다. 이럴 경우 서버를 확장시키는 여러 방법이 있는데 scale out은 서버를 여러 대 추가하여 확장하는 방법이다.  
>만약 기능 별로 분리가 되어 있다면 수강신청의 경우, 로그인하는 서버와 수강신청을 하는 서버만 확장을 시킴으로서 많은 트래픽을 견딜 수 있지만 기능 별로 분리가 안 되어 있다면 모든 서버를 통째로 추가해야 할 것  
>ex : 대학교의 수강신청 등

장점과 단점 모두 Monolithic Architecture의 공통적인 특징, 단순함 때문에 야기된다.  
프로젝트가 하나의 어플리케이션으로 이루어져 있으니 개발하기도 편하고, 전체적인 테스트가 수월하다. 당연히 배포도 하나의 어플리케이션만 하면 된다.  
하지만 프로젝트 규모가 점점 커질수록 단순함은 독이 된다.  
너무 많은 기능들이 하나의 어플리케이션에 묶여있다보니 서로 의존성이 높아지고 이는 개발자들에게 있어서는 이해하기 어려운 코드가 될 것  
  
이러한 장단점이 극명하기 때문에 Monolithic Architecture가 좋지않다고만 볼 수는 없다.  
실제로 아직 많은 소프트웨어가 Monolithic 방식으로 개발되고 유지되고 있으며 특히 소규모 프로젝트의 경우에는 특별히 나눌 필요없이 Monolithic Architecture가 더 합리적일 수 있다.  
하지만 프로젝트의 규모가 커지고 한 프로젝트에 속한 개발자가 많아질수록 부적합해진다.  
최근에 등장하는 프로젝트들은 모두 규모가 크고 많은 기능들을 필요로 하고, 그렇기 때문에 MSA가 등장하였고 더 각광받은 것

### Micro Service Architecture
장점
* 빌드 및 테스트 시간을 단축  
물론 처음부터 끝까지 서비스를 빌드하고 테스트하는 시간은 같다.  
하지만 개발을 하다보면 부분적으로 테스트를 해야하는 순간도 필요할텐데 MSA는 이를 가능하게 하여 시간을 절약할 수 있음
* 유연하게 기술을 적용  
서버가 분리되다보니 각 서버의 언어와 프레임워크도 유연하게 가져갈 수 있다.  
auth 서버는 django, 채팅서버는 node로 구현하는 방식으로 말이다.
* scale out 가능
* 서비스간의 연관성 낮음  
한 서버에서의 문제가 다른 서버에 영향을 미치지 않게 되므로 긍정적인 부분
  
단점
* 성능 이슈  
Monolithic의 경우 다른 기능을 호출할 경우 같은 프로젝트 내에서 method 호출로 끝남  
이는 단순히 메모리 안에서 일어나 매우 빠르고 문제의 소지가 적음. 다른 서비스 간에 Network 통신(주로 http)을 주고 받게 됨.  
method를 호출하는 것과는 많은 차이가 있다.  
Micro Service Architecture의 경우에는 이렇게 단순하게 처리할 수 없다.
* 트랜잭션이 불편  
서버가 나뉘고 다른 서버 간의 트랜잭션 처리를 해야할 경우, 불편함이 따른다.  
트랜잭션을 위한 로직이 또 필요해짐
* 개발 시간 증가  
MSA는 서버가 분리 됨에 따라 이에 따라 관리가 필요.  
DB가 서버에 맞춰 증가할 수도 있고, 로깅, 모니터링, 배포, 테스트 등 여러 관리에 신경을 더 써야함

### 결론
각 프로젝트의 상황에 맞게 적절한 아키텍쳐를 골라야함  
  
출처 : https://ssungkang.tistory.com/entry/MSA-Monolithic-Architecture-VS-Micro-Service-Architecture

## Multi Module VS MSA

### Multi Module
서로 독립적인 프로젝트(인증, 어플리케이션)를 하나의 프로젝트로 묶어 모듈로서 사용되는 구조. 멀티 모듈을 사용하면 공통적인 기능을 모아 하나의 모듈로 만드는 것이 가능하다. 즉, 인증과 어플리케이션에서 공통으로 사용하는 util, domain, Repository등을 모듈로 분리해 사용할 수 있는 것  
* MSA와 멀티 모듈은 다름  
멀티 모듈로 이루어진 마이크로 서비스가 있고, 이 서비스들 간에 구성되어 있는 형태가 MSA
* 모놀릭스는 멀티모듈을 못쓰나? → no  
쓸 수 있음
* 멀티 모듈은 모놀릭스 <-> MSA 간 서로 전환하는 작업을 수월하게 할 수 있는 구조가 되도록 도와줌

장점
* 재사용, 공유 할 수 있음  
멀티 모듈의 각 모듈들을 독립적이고 필요한 최소 의존성을 가지고 있기 때문에 다른 영향을 고려하지 않고 재사용이 가능
* 빌드를 쉽게 할 수 있음  
멀티 프로젝트의 경우에는 각 프로젝트마다 빌드를 해줘야 한다. 하지만 멀티 모듈은 최상위 모듈에서 전체 프로젝트를 빌드 할 수 있다는 점이 큰 장점. 모듈 별도 빌드와 테스트도 아주 큰 장점이다. 싱글 모듈인 경우에는 한 가지 기능만 수정했다해도 전체를 빌드해야한다. 전체 빌드와 한 모듈 빌드 차이
* 변경으로 인한 영향 최소화  
버그를 발견하면 전체 시스템이 아닌 버그가 포함된 모듈만 업데이트하면 된다. 그로 인해 수정으로 인한 영향이 최소화 됨. 한 곳을 수정했는데 예상치 못한 곳에서 다른 에러가 터지는 불상사들이 다 얽히고 설킨 의존성 때문. 전체를 빌드, 재배포할 필요없이 편하게 버그 모듈만 빌드 재배포할 수 있는 장점도 있다.
* 하나의 모듈을 업데이트할 때 관련 프로젝트 전체를 이해할 필요가 없다.  
각 모듈이 갖는 책임과 역할이 명확해 리팩토링, 기능 변경 영향 파악하기가 쉬워졌기 때문
* 의존성을 최소화  
의존성을 최소화하면 변경으로 인한 영향을 최소화할 수 있다. 즉 결합도가 낮아짐. 또한 각 모듈을 가볍게 유지해서 빌드 시간을 줄이고 생산성을 향상시킬 수 있음
  
단점
* 멀티 모듈 학습에 대한 비용
* 여러 모듈을 유지 관리하기가 더 어려울 수 있음
* 기능이 추가될수록 처음 설계와 다르게 의존성이 꼬일 가능성

### 결론
Monolithic → MSA로 한 번에 가긴 힘들다.  
프로젝트가 커지면 커질수록 멀티 모듈은 거의 필수가 된다고 한다. 하지만 크기가 작은 프로젝트의 경우에는 멀티 모듈의 장점을 살릴 수 없는 의미없는 멀티 모듈이 될 확률이 높다.

## NginX VS Apache
예전에는 웹 서버로 Apache를 많이 사용하였지만 최근에는 Nginx를 사용하는 추세  
어떤 이유 때문에 Nginx를 점점 더 사용하는 것일까?  
Nginx가 트래픽이 많은 웹사이트에 적합하기 때문  
  
Nginx는 **대용량 트래픽을 처리하기 위해 가벼움과 높은 성능을 목표로 하는 경량 웹 서버**이다.  
  
초기에는 정적 파일을 제공하는 웹 서버로 Apache를 보조하는 역할을 수행하였지만 오늘날에는 리버스 프록시, 로드 밸런서, 메일 프록시 및 HTTP 캐싱 등 전체 범위의 서버 작업을 처리하는 웹 서버로 발전하였다.  
  
즉, Nginx 웹 서버는 Apache 웹 서버의 성능 제한을 해결하기 위해 탄생한 웹 서버이다.

### 설계 아키텍처의 차이
**Nginx**
* 이벤트 중심 접근 방식으로 하나의 스레드 내에서 여러 요청을 처리하는 구조
* 비동기 Event-Driven 구조 : Event Handler에서 비동기 방식으로 먼저 처리되는 요청을 진행 
* 코어 모듈이 Apache보다 적은 리소스로도 많은 트래픽을 효율적으로 처리 가능
![image](https://user-images.githubusercontent.com/44667299/163663954-fe35e8ca-6a51-47e3-bc2e-01a4a3718bfa.png)  
  
Nginx는 Event-Driven 구조로 동작하기 때문에 한 개 또는 고정된 프로세스만 생성하여 사용하고, 비동기 방식으로 요청들을 Concurrency 하게 처리할 수 있다. Nginx는 새로운 요청이 들어오더라도 새로운 프로세스와 쓰레드를 생성하지 않기 때문에 프로세스와 쓰레드 생성 비용이 존재하지 않고, 적은 자원으로도 효율적인 운용이 가능하다. 이러한 Nginx의 장점 덕분에 단일 서버에서도 동시에 많은 연결을 처리할 수 있다.  
  
**Apache**
* 프로세스 기반 접근 방식으로 하나의 스레드가 하나의 요청을 처리하는 구조
* 매 요청마다 스레드를 생성 및 할당해야 하기 때문에 리소스를 많이 잡아먹음
![image](https://user-images.githubusercontent.com/44667299/163664074-5c943864-33b8-4522-b50d-15f456577579.png)  
  
Apache는 클라이언트로부터 받은 요청을 처리할 때 새로운 프로세스 또는 쓰레드를 생성하여 처리한다. 요청마다 쓰레드가 생성되므로 접속하는 사용자가 많으면 그만큼 쓰레드가 생성되어 CPU와 메모리 자원의 소모가 커진다.

### 성능 차이
Nginx와 Apache 두 웹 서버 모두 정적 및 동적 컨텐츠를 제공하는 방식이 다르다.  
  
**정적 컨텐츠**
* 서버 PC의 디스크에 저장하는 파일 기반 방법으로 정적 컨텐츠 제공
* 설계 아키텍처 구조상 Nginx가 적은 비용으로 효율적으로 제공

**동적 컨텐츠**
* 두 웹 서버 모두 서버 자체에서 동적 컨텐츠 처리 가능
* Nginx는 SCGI 핸들러와 FastCGI 모듈을 사용해서 동적 컨텐츠 제공할 수 있음
* 동적 컨텐츠는 두 웹 서버 성능이 비슷함

### OS 지원 여부
**Nginx**
* 거의 모든 Unix 계열 OS 지원
* Windows는 부분적으로 지원

**Apache**
* Linux 및 BSD를 포함한 모든 Unix 계열 OS 지원
* Windows 모두 지원

### 분산/중앙 집중식 구성
**Nginx**
* 추가 구성을 허용하지 않음
* 권한이 없는 사용자가 웹 사이트의 특정 측면을 제어할 수 없지만 추가 구성을 제공하지 않음으로써 성능 향상
* 디렉토리 구성을 허용하지 않음으로 .htaccess 파일을 검색하고 사용자가 만든 요구 사항을 해석할 필요 없기 때문에 Apache보다 빠르게 요청을 처리할 수 있음

**Apache**
* .htaccess 파일을 통해 디렉토리 별로 추가 구성을 허용
* 이로 인해 권한이 없는 사용자가 웹 사이트의 특정 측면을 제어할 수 있음

### 요청을 처리 및 해석하는 방법의 차이
**Nginx**
* 요청을 해석하기 위해 URI를 전달
* URI로 전달함으로써 웹 서버뿐만 아니라 프록시 서버, 로드 밸런서 및 HTTP 캐시로 쉽게 동작 가능
* 서버에서 클라이언트로 데이터가 전송되는 속도가 Apache보다 더 빠름

**Apache**
* 요청을 해석하기 위해 파일 시스템 위치 전달
* URI 위치를 사용하지만 일반적으로 더 추상적인 디렉토리 구조를 사용

### 기능 모듈의 차이
**Nginx**
* 타사 플러그인 과정으로 선택되고 컴파일되기 때문에 동적으로 모듈을 로드할 수 없음
* 따라서 사용하려는 기능만 선택해서 서버를 실행 = 가벼움

**Apache**
* 동적으로 로드 가능한 다양한 60개의 공식 모듈을 제공
* 모든 모듈을 가지고 서버가 실행되지만 실제 사용되는 모듈을 소수임 = 무거움

### 유연성
**Nginx**
* 아직까지는 동적 모듈과 로딩을 지원하지 않음

**Apache**
* 동적 모듈, 로딩 지원

### 보안
두 웹 서버 모두 C언어 기반으로 확장된 보안을 제공. 하지만 Nginx가 코드가 더 작기 때문에 미래 지향적인 보안 관점에서 장점을 가진다.  
  
즉, 비슷하지만 Nginx가 조금 더 안전한 것으로 간주

### 결론
Apache는 .htacess 파일을 제공하기 때문에 이를 활용하거나 Nginx에게 없는 핵심 모듈을 사용할 경우 Apache를 사용하며, 빠른 정적 컨텐츠를 처리하고 싶고 대용량 트래픽을 처리하는 웹 사이트인 경우는 Nginx를 사용하면 된다.  
또한, 두 서버를 함께 사용해도 된다. Apache 앞단에 Nginx를 프록시 서버로 활용할 수 있다.  
  
Apache는 Nginx 에 비해 모듈이 다양하다.  
Apache는 안정성, 확장성, 호환성을 장점으로 들자면, Nginx는 성능이 우세하다는 장점이 있다.  
  
Apache와 NginX는 모두 강력하고 유연한 웹 서버이다. 어떤 웹 서버가 더 좋다 라는 결론은 없다.  
상황과 비용에 따라, 혹은 안정성이나 효율성에 따라 적합한 웹 서버를 사용

|Apache|NginX|
|---|---|
|요청 당 스레드 또는 프로세스가 처리하는 구조|비동기 이벤트 기반으로 요청|
|CPU/메모리 자원 낭비 심함|CPU/메모리 자원 사용률 낮음|
|NginX보다 모듈이 다양|Apache에 비해 다양한 모듈이 없음|
|PHP 모듈 등 직접 적재 가능|많은 접속자들 대응 가능|
|안정성, 확장성, 호환성 우세|성능 우세|
|동적 컨텐츠 단독 처리 가능|동적 컨텐츠 단독 처리 불가능|
  
참고 : https://sorjfkrh5078.tistory.com/289

## Servlet VS Netty
### Servlet
Dynamic Web Page를 만들 때 사용되는 자바 기반의 웹 애플리케이션 프로그래밍 기술. 클라이언트의 요청을 처리하고, 그 결과를 반환하는 Servlet 클래스의 구현 규칙을 지킨 자바 웹 프로그래밍 기술. 웹 요청과 응답의 흐름을 간단한 메서드 호출만으로 체계적으로 다룰 수 있게 해주는 기술  
  
자바 클래스로 웹 애플리케이션을 작성한 뒤 이후 웹 서버 안에 있는 웹 컨테이너에서 이것을 실행하고, 웹 컨테이너에서는 서블릿 인스턴스를 생성 후 서버에서 실행되다가 웹 브라우저에서 서버에 요청(Request)을 하면 요청에 맞는 동작을 수행하고 웹 브라우저에 HTTP형식으로 응답(Response)한다.  
  
**특징**
* 클라이언트의 Request에 대해 동적으로 작동하는 웹 애플리케이션 컴포넌트
* HTML을 사용하여 Response 한다.
* JAVA의 스레드를 이용하여 동작
* MVC 패턴에서의 컨트롤러로 이용됨
* HTTP 프로토콜 서비스를 지원하는 javax.servlet.http.HttpServlet 클래스를 상속받음
* UDP보다 속도가 느리다.
* HTML 변경 시 Servlet을 재 컴파일해야 하는 단점

**서블릿 컨테이너**  
서블릿을 담고 관리해주는 컨테이너.  구현되어 있는 servlet 클래스의 규칙에 맞게 서블릿은 관리해주며 클라이언트에서 요청을 하면 컨테이너는 HttpServletRequest, HttpServletResponse 두 객체를 생성하며 post, get여부에 따라 동적인 페이지를 생성하여 응답을 보낸다.  
  
**서블릿 컨테이너 주요 기능**
* 생명주기 관리
* 통신 지원
* 멀티스레딩 관리
* 선언적인 보안관리

**Servlet을 쓰는 이유**  
서블릿을 사용하지 않고 직접 HTTP 통신으로 오고가는 문자열을 파싱하여 서블릿과 같은 기능을 구현해도 무방하지만, 이미 편리하게 사용할 수 있는 서블릿을 놔두고 직접 문자열 파싱을 구현하는 것은 개발자가 온전히 비즈니스 로직에 집중하지 못하게 만들 수 있다.  
서블릿을 통해 문자열 파싱 등에 열올리지 않고 비즈니스 로직에 더욱 집중할 수 있다.

### Netty
TCP, UDP 소켓 서버 개발과 같은 네트워크 프로그래밍을 매우 간단하고 능률적으로 만들어주는 비동기 이벤트 드리븐 자바 네트워크 프레임워크  
  
단순히 네트워크 통신과 관련된 기능을 제공할 뿐만 아니라 일반적으로 네트워크 애플리케이션에서 사용하는 다양한 기술들을 포함하고 있다. 덕분에 자바 프로그래머들은 네트워크 프로그래밍이나 멀티스레드와 관련된 처리보다는 자신들의 비즈니스 로직에 좀 더 집중할 수 있게 됨. 네티를 이용한 애플리케이션은 최소 10만개 이상의 클라이언트 커넥션을 처리할 수 있을 정도로 안정되어 있다.  
  
Netty는 자바 개발자가 네트워크 애플리케이션을 빠르고 쉽게 개발할 수 있도록 다양하고 강력한 기능들을 제공한다.  
  
**특징**
* Asynchronous IO (비동기 입출력)
  * Netty 프레임워크는 비동기처리를 지향
* Event Model
  * 입출력을 위해 잘 정의된(Well-defined) 이벤트 모델을 가지고 있음
  * 사용자가 코어 로직을 손대지 않고도 직접 이벤트 타입을 구현할 수 있도록 지원한다. 각 이벤트 타입은 엄격하게 계층화되어 있어 서로 잘 구분된다. 다른 NIO 프레임워크들은 이벤트 타입을 추가할 경우 기존 코드에 영향을 주거나 아예 커스텀 이벤트 추가를 막는 경우도 많다.
* Universal Asynchoronous I/O API
  * 자바의 전통적인 IO API는 TCP, UDP에 따라 다른 형태의 API를 제공한다. 이 때문에 TCP 애플리케이션을 UDP로 포팅하는게 마냥 쉽지만은 않다.
  * Netty는 Channel이라는 Async I/O 인터페이스를 가지고 있다. 이 채널은 Point-to-Point 통신을 추상화한 개념이다. 일단 Netty앱을 개발하면 추상화를 통해서 실제 통신 부분과 상관없이 로직을 개발할 수 있다. Netty는 여러 개의 필수적인 transports를 하나의 API를 통해서 제공한다.
    * NIO 기반의 TCP/IP
    * Old IO 기반의 TCP/IP
    * Old IO 기반의 UDP/IP
    * Local transport
  * 이 transport 사이를 전환하는 것은 팩토리 클래스인 ChannelFactory를 고르는 몇 줄만 고치면 된다. 심지어는 아직 구현되지 않은 transport를 사용하는 클라이언트 코드를 미리 구현할 수도 있다. transport 역시 직접 구현해서 사용할 수 있다.
* ChannelBuffer
  * Netty는 독자적인 버퍼를 구현했다. 독자적인 버퍼를 구현해서 제로카피(Zero Copy)도 지원하고, ByteBuffer보다 빠른 성능을 구현했다. 다이나믹 버퍼 타입도 지원한다.
* 기타
  * 그 밖에 빠른 개발을 위한 수 많은 컴포넌트들을 가지고 있음
  * 단순하든 복잡하든 바이너리든 아니든 상관없이 프로토콜 코덱을 작성할 때 마주하게 될 대부분의 이슈를 해결할 수 있도록 기본적인 코덱과 고급 코델을 제공
  * NIO 이면서도 SSL을 지원
  * Google Protobuf 와 통합이 가능

>제로카피(Zero Copy) : 컴퓨터 시스템에서 CPU의 개입을 받지 않고 한 메모리의 영역에서 다른 메모리의 영역으로 데이터를 카피하는 작업을 말한다. 이는 CPU 사이클을 절약하여서 네트워크나 SSD와 같이 빠른 데이터가 필요한 시스템에서 유용하게 이용

**Netty를 쓰는 이유**  
* 성능이 좋음
  * Non-blocking Asynchronous가 기본
  * 적은 thread로 많은 요청 처리
  * GC부하를 최소화하는 Zero-copy ByteBuf 지원
* 유연하고 쓰기 쉬움
  * 각종 network protocol 기본 지원
  * 필요한 부분을 쉽게 조립해 쓸 수 있는 구조
  * multithread 처리 없이도 사용 가능

## 로드밸런싱
* 서버에 가해지는 부하를 분산해주는 장치 또는 기술
* 클라이언트와 서버풀 사이에 위치해 한 대의 서보로 부하가 집중되지 않도록 트래픽을 관리
* 각각의 서버가 최적의 퍼포먼스를 보일 수 있도록 관리
* 스케일 아웃으로 시스템 확장을 했다면, 반드시 동반되어야하는 기술

### 로드 밸런싱 알고리즘
**라운드 로빈 방식(RR, Round Robin)**
* 서버에 들어온 요청을 순차적으로 배정
* 각 서버가 동일한 스펙을 가지고 있고, 세션이 오래 지속되지 않는 경우에 적합

**가중 라운드로빈 방식(Weighted Round Robin)**
* 각각의 서버마다 가중치를 매기고 가중치가 높은 서버에 우선적으로 배정
* 각각의 서버의 트래픽 처리 속도가 상이한 경우에 적합

**IP 해시 방식(IP Hash)**
* 클라이언트의 IP 주소를 해시 함수를 통해 특정 서버에 매핑
* 사용자가 항상 동일한 서버로 연결되는 것을 보장

**최초 연결 방식(Least Connection)**
* 요청이 들어온 시점에 가장 적은 연결 상태를 보이는 서버에 우선적으로 배정
* 서버에 분배된 트래픽이 일정하지 않은 경우 적합

**최소 응답시간 방식(Least Response Time)**
* 서버의 현재 연결 상태와 응답시간을 모두 고려해 트래픽 배분

### 로드 밸런서 종류
* OSI 7 계층에 따라 L1 로드밸런서부터 L7로드 밸런서까지 존재
* L4 로드밸런서부터 포트 정보를 바탕으로 로드를 분산하는 것이 가능하므로 L4와 L7이 가장 많이 활용
* 한 대의 서버에 다수의 서버 프로그램을 운영하는 경우 최소 L4 이상의 로드밸런서를 사용해야함

**L4 로드밸런서**
* 네트워크 계층(IP)이나 전송 계층(TCP, UDP)의 정보를 바탕으로 로드 분산
* IP 주소, 포트번호, Mac 주소, 전송 프로토콜에 따라 로드 분산
* (+) 데이터를 확인하지 않고 패킷레벨에서만 로드를 분산하기 때문에 빠르고 효율적
* (+) 데이터의 내용을 복호화할 필요가 없으므로 안전
* (+) 저렴
* (-) 섬세한 라우팅 불가
* (-) 사용자의 IP가 수시로 바뀌는 경우 연속적인 서비스 제공 불가

**L7 로드 밸런서**
* 애플리케이션 계층(HTTP, FTP, SMTP)에서 로드를 분산
* HTTP 헤더, 쿠키 등과 같은 사용자 요청을 기준으로 특정 서버에 트래픽 분산 가능
* 즉, 패킷의 내용을 확인하고, 그 내용에 따라 로드를 분산 가능
* (+) 클라이언트의 요청을 보다 세분화해 서버에 전달
* (+) 캐싱 기능 제공
* (+) DOS같은 비정상적인 트래픽을 필터링할 수 있어 안전성이 높음
* (-) 패킷 내용을 복호화 해야하므로 높은 비용
* (-) 클라이언트와 로드밸런서가 인증서를 공유해야하기 때문에 보안상의 위험이 존재

참고 : https://dheldh77.tistory.com/entry/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%A1%9C%EB%93%9C-%EB%B0%B8%EB%9F%B0%EC%8B%B1Load-Balancing?category=823110

## Reverse Proxy
애플리케이션 서버의 앞에 위치하여 클라이언트가 서버를 요청할 때 리버스 프록시를 호출하고, 리버스 프록시가 서버로부터 응답을 전달받아 다시 클라이언트에게 전송하는 역할  
  
이 경우, 클라이언트는 애플리케이션 서버를 직접 호출하는 것이 아니라 프록시 서버를 통해 호출하기 때문에 리버스 프록시는 애플리케이션 서버를 감추는 역할  
![image](https://user-images.githubusercontent.com/44667299/163663749-2f23cdbe-7526-4f14-83a0-886df1effeb7.png)  
사진 출처 : https://sujinhope.github.io/2021/06/13/Network-%ED%94%84%EB%A1%9D%EC%8B%9C(Proxy)%EB%9E%80,-Forward-Proxy%EC%99%80-Reverse-Proxy.html  
  
### 리버스 프록시의 특징/역할
* 로드밸런싱 : 리버스 프록시 뒤에 여러 개의 WAS를 둠으로써, 사용자 요청을 분산할 수 있다. End-point 마다 호출 서버를 설정할 수 있어 역할에 따라 서버의 트래픽을 분산할 수도 있다.
* 보안 : 보안 상의 이유로 서버에 직접 접근하는 것을 막기 위해 DMZ같은 네트워크에 리버스 프록시를 구성하여 접근하도록 한다.
* 속도와 안전성
* 신뢰성 증대

## CDN
* 느린 응답 속도/다운로딩 시간을 극복하기 위한 기술
* 지리적, 물리적으로 떨어져 있는 사용자에게 컨텐츠를 더 빠르게 제공하기 위한 기술
* 사용자와 가까운 곳에 위치한 Cache 서버에 해당 컨텐츠를 저장하고 컨텐츠 요청 시 Cache 서버가 응답

각 지역에 캐시 서버(PoP, Points of presence)를 분산 배치해, 근접한 사용자의 요청에 원본 서버가 아닌 캐시 서버가 콘텐츠를 전달함

## 캐시
데이터나 값을 미리 복사해 놓는 임시 장소

### 캐싱
캐싱은 애플리케이션의 처리 속도를 높여 준다. 이미 가져온 데이터나 계산된 결과값의 복사본을 저장함으로써 처리속도를 향상시키며, 이를 통해 향후 요청을 더 빠르게 처리할 수 있다. 대부분의 프로그램이 동일한 데이터나 명령어에 반복해서 액세스하기 때문에 캐싱은 효율적인 아키텍처 패턴이다.

### 웹 캐시
사용자가 웹사이트(client)에 접속할 때, 정적 컨텐츠(JS,이미지, CSS)을 특정 위치에 저장하여 웹 사이트 서버에 해당 컨텐츠를 매번 요청하여 받는 것이 아닌 특정 위치에서 불러옴으로서 사이트 응답 시간을 줄이고 서버 트래픽 감소 효과를 볼 수 있는 것을 말함  
  
**종류**  
장소에 따라 나뉨
* Browser Cashes
  * 브라우저 또는 HTTP 요청을 하는 Client Appliction에 의해 내부 디스크에 캐쉬
  * 캐시된 리소스를 공유하지 않는 한 개인에 한정된 캐시
  * 브라우저의 back버튼 또는 이미 방문한 페이지를 재 방문하는 경우 극대화
* Proxy Caches
  * Browser Cashes와 동일한 원리로 동작하며 Client나 Server가 아닌 네트워크 상에서 동작
  * 큰 회사나 IPS의 방화벽에 설치 되며 대기시간 & 트래픽 감소, 접근 정책 & 제한 우회, 사용률 기록 등을 수행
  * 한정된 수의 클라이언트를 위해 무한 대의 웹 서버 컨텐츠를 캐시
* GateWay Caches
  * 서버 앞 단에 설치되어 요청에 대한 캐시 및 효율적인 분배를 통해 가용성, 신뢰성, 성능 등을 향상
  * Encryption, SSL acceleration, Load balancing, Server / cache static content, Compression 등을 수행
  * 무한 대의 클라이언트들에게 한정된 수의 웹 서버 컨텐츠를 제공

### 어떻게 캐쉬를 컨트롤 하나
* **HTML Meta Tags**
```HTML
<META HTTP-EQUIV="EXPIRES" CONTENT="Mon, 22 Jul 2002 11:12:01 GMT">

<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
```
첫 번째 방법은 위와 같이 HTML Meta Tag를 페이지에 삽입하는 방법이다. 하지만 이 방법은 과거의 몇몇 브라우저에게만 유효 했으며 지금은 더 이상 사용하지 않는 방법이다.  

<br/>

* **HTTP Headers**

두 번째 방법은 HTTP header를 사용하는 방법으로 현재 사용하는 방식이다.  
  
파일이 이전과 비교하며 변경되었는가를 체크하는 validation과 캐쉬의 만료 여부를 체크하는 freshness로 구성. request와 response에 따라 서로 사용 될 수 있는 값이 다르며 HTTP 1.0 에서 HTTP 1.1 로 넘어오면서 약간의 변화가 있다. HTTP 1.1에서는 하위 호환 되므로 1.0의 Header를 사용하여도 정상 동작하지만 중복으로 선언된다면 1.1에 정의된 것이 우선 순위를 가지게 된다.  
  
예를 들어 Last-Modified와 Etag가 동시에 있다면 Etag가 우선순위를 가진다. Expires와 Cache-control도 마찬가지  
  
HTTP 1.1 의 Cache-Control은 하나의 값이 아니라 다양한 지시자를 이용하여 값을 전달할 수 있다. 그로 인해 여러가지 컨트롤을 가능하게 만들어준다.  
ex) `Cache-Control : max-age=3600, must-revaliate`

### 어떻게 캐쉬가 동작하나
**첫 요청**
1. 브라우저는 서버에 index.html 파일 요청
2. 서버는 index.html 파일을 찾아보고 존재하는 파일이라면 파일 내용을 브라우저에게 몇 가지 header값과 함께 응답
3. 브라우저는 응답 받은 내용을 브라우저에 표시하고 응답 헤더의 내용에 따라 캐쉬 정책을 수행
  * 만약 응답 헤더에 Last-Modified, Etag, Expires, Cache-Control:max-age 항목이 존재 한다면 복사본을 생성하고 그 값을 저장

**재 요청**
1. LAST-MODIFIED
* 브라우저는 최초 응답 시 받은 Last-Modified 값을 If-Modified-Since 라는 헤더에 포함 시켜 페이지를 요청
* 서버는 요청 파일의 수정 시간을 If-Modified-Since 값과 비교하여 동일하다면 304 NOT Modified로 응답하고 다르다면 200 OK와 함께 새로운 Last-Modified 값을 응답 헤더에 전송
2. Etag(Entitiy Tag)
* 브라우저는 최초 응답 시 받은 Etag값을 If-None-Match 라는 헤더에 포함 시켜 페이지를 요청
* 서버는 요청 파일의 Etag값을 If-None-Match값과 비교하여 동일하다면 304 Not Modified로 응답하고 다르다면 200 OK와 함께 새로운 Etag 값을 응답 헤더에 전송
* 브라우저는 응답 코드가 304인경우 캐쉬에서 페이지를 로드하고 200이라면 새로 다운받은 후 Etag값을 갱신
* Etag는 서버마다 생성하는 값이 다르며 파일마다 고유한 값을 가짐
* LAST-MODIFED(1.0) 와 ETAG(1.1) 는 validation을 체크. 이를 체크하기 위해 서버와 한번의 통신이 발생하게 되며 그로 인해 요청과 응답에서 header와 cookie등에 의한 데이터 전송(1KB)이 발생하게 됨
3. Expires
* 브라우저는 최초 응답 시 받은 Expires 시간을 비교하여 기간 내라면 서버를 거치지 않고 바로 캐쉬에 페이지를 로드. 만약 기간이 만료되었다면 위에 설명한 Validation 작업을 수행
4. Cache-Control
* 브라우저는 최초 응답 시 받은 Cache-Control 중 max-age값을 GMT와 비교하여 기간 내라면 서버를 거치지 않고 캐쉬에서 페이지를 로드. 만약 기간이 만료 되었다면 Validation 작업을 수행
* Expires(1.0)와 Cache-Control : max-age(1.1)는 freshness를 체크. 기간 내라면 서버와 통신을 하지 않고 캐쉬를 사용
* 시간은 HTTP date 형태이며 로컬 타임이 아닌 GMT를 사용
* 서버가 Last Modified Time 또는 Last Access Time을 기준으로 하여 일정 시간 이후로 Expires 또는 max-age를 설정

### 캐시 서버
웹 캐시 서버는 프록시의 한 형태라고 할 수 있다. 웹 캐시 서버는 클라이언트가 요청한 컨텐츠들을 기억하고 있다가 어느 한 클라이언트(동일사용자 일수도 있고, 다른 사용자일수도 있는)가 웹 캐시 서버가 기억하고 있는 동일한 컨텐츠를 또 다시 요청하는 경우 이를 직접 응답하여 웹 서버의 부하를 절감시켜 주는 역할을 한다.  
  
캐시서버는 일반적으로 기업 내의 인터넷 사용자와 비교적 가까이 있는 서버로서, 모든 사용자들이 자주 요청할 만한 웹페이지나, FTP 및 기타 다른 파일들을 저장하고 있다가, 이들 페이지나 파일들에 대한 이어지는 요구들을 (그때마다 인터넷에 가서 찾지 않더라도) 쉽게 만족시켜줄 수 있도록 하기 위한 서버이다. 캐시서버는 사용자들이 요구하는 정보를 더 빠르게 제공할 뿐 아니라, 인터넷의 트래픽을 획기적으로 줄여준다.

## E-TAG
HTTP response header에서 특정 버전의 리소스를 식별하는 식별자. 쉽게 말하면, 리소스가 바뀌었는지 확인하는 식별자

### 왜 사용할까
ETag는 사용하는 캐시가 유효한지 검증하기 위해 사용한다. 서버의 리소스가 변경된다면 저장해 놓은 캐시의 데이터와 서버의 리소스 데이터는 다른 값이다. 그때 캐시가 서버에게 리소스가 변경되었는지 안 되었는지 물어보는 것을 캐시 유효성 검사라고 한다. ETag를 사용하여 캐시 유효성 검사를 한다.

## 성능 테스트
특정 워크로드에서 애플리케이션의 안정성과 속도, 확장성 및 반응성이 어떻게 유지되는지를 판별하는 비기능적 소프트웨어 테스트 기법. 성능 테스트의 주요 목적은 소프트웨어 애플리케이션의 성능 병목 현상을 식별하고 제거하는 것
>워크로드 : 지정된 시간(매일 작업 중, 사용량이 가장 많은 시간, 시스템이 가장 많이 사용되는 날 등)에 시스템의 예상로드를 혼합한 것으로 정의

### 성능 테스트가 필요한 이유
조직들은 다음과 같은 이유 중 하나 때문에 성능 테스트를 함
* 애플리케이션이 성능 요건을 충족하는지 판별(예를 들어 시스템은 최대 1,000명의 동시 사용자를 처리해야 함)
* 애플리케이션 내 컴퓨팅 병목 현상을 유발하는 위치 파악
* 실제 성능 수준이 소프트웨어 벤더가 주장하는 성능 수준과 동일한지 판별
* 두 개 이상의 시스템 비교 및 가장 성능이 좋은 시스템 식별
* 최대 트래픽 이벤트에서 안정성 측정

### 성능 테스트 속성
* 속도  
소프트웨어 제품이 빠르게 반응하는지 여부를 결정
* 확장성  
소프트웨어 제품이 한 번에 처리 할 수 있는 로드 양을 결정
* 안정성  
다양한 워크로드의 경우 소프트웨어 제품이 안정적인지 여부를 결정
* 신뢰성  
소프트웨어 제품이 안전한지 여부를 결정

### 성능 테스트의 목적
* 성능 테스트의 목적은 성능 정체를 제거하는 것
* 제품이 시장에 출시되기 전에 개선해야 할 사항을 파악
* 성능 테스트의 목적은 소프트웨어를 신속하게 만드는 것
* 성능 테스트의 목적은 소프트웨어를 안정적이고 신뢰할 수 있도록 만드는 것

### Virtual User
### TPS(RPS)
### MAU/DAU
# 기술
## 로깅 라이브러리 비교(스프링/자바 -> 보안 이슈 적지 말아라)
## RabbitMq
## ActiveMq
## 카프카
## ELK(elasticStack)
## 레디스
## 도커
## 쿠버네티스
## 프로메테우스
## 그라파나 
## 코틀린 

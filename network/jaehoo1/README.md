# Network
## TCP
TCP(Transmission Control Protocol)는 IP 프로토콜 위에서 연결형 서비스를 지원하는 전송 계층 프로토콜로, 인터넷 환경에서 기본으로 사용한다.
* 연결형 서비스를 제공 (UDP : 비연결형)
* 전이중(Full Duplex) 방식, 점대점(point to point) 방식
* 신뢰성 있는 데이터 전송, 순차적인 전달을 보장
>전이중 통신(Full Duplex) : 전송이 양방향으로 동시에 일어날 수 있음  
>점대점(point to point) : 각 연결이 정확히 2 개의 종단점을 가지고 있음

TCP 서비스는 송신자와 수신자 모두가 소켓이라고 부르는 종단점을 생성함으로써 이루어진다. TCP는 데이터를 세그먼트(Segment)라는 블록 단위로 분할해 전송한다. TCP는 멀티캐스팅이나 브로드캐스팅을 지원하지 않는다.  
  
신뢰성 있는 전달을 위해 오버헤드가 발생하여 UDP보다 속도가 느린 편이다. 속도보다 신뢰성이 중요할 때 사용한다.

### TCP 3 way handshake
TCP가 장치간 논리적인 연결을 성립하기 위해 3 way handshake 방식을 사용한다.  
통신을 하는 응용프로그램이 데이터를 전송하기 전에 먼저 정확한 전송을 보장하기 위해 상대방 컴퓨터와 사전에 세션을 수립하는 과정  
  
![image](https://user-images.githubusercontent.com/44667299/162578377-7b237f0f-d7ee-426f-b641-617b8d228477.png)  
사진 출처 : https://asfirstalways.tistory.com/356  
  
1. 클라이언트는 서버에 접속을 요청하는 SYN(a) 패킷을 보낸다. 클라이언트는 SYN을 보내고 SYN/ACK 응답을 기다리는 SYN_SENT 상태가 된다.
2. 서버는 클라이언트의 요청인 SYN(a)를 받고 클라이언트에게 요청을 수락한다는 ACK(a+1)와 SYN(b)이 설정된 패킷을 발송한다. 서버는 클라이언트가 ACK으로 응답하기를 기다리는 SYN_RECEIVED 상태가 된다.
3. 클라이언트는 서버의 수락 응답인 ACK(a+1), SYN(b) 패킷을 받고 ACK(b+1)를 서버로 보내면 연결이 성립(ESTABLISHED)된다.
>a : 임의의 번호(random number)  
>b : 서버가 클라이언트에게 주는 번호  
>SYN : SYNchronize sequence number - 요청에 대한 패킷  
>ACK : ACKnowledgement - 응답에 대한 패킷
  
**왜 3 way인가?**  
2번으로는 부족한가? 부족하다.  
좋은 비유가 있어서 가져옴  
클라이언트가 자신의 목소리가 들리는지 물어봄 : SYN(a)  
서버는 클라이언트의 목소리가 들린다고 응답 : ACK(a+1)  
그리고 자신의 목소리가 들리는지 물어봄 : SYN(b)  
클라이언트는 서버의 목소리가 들린다고 응답 : ACK(b+1)  
TCP는 양방향성이다. 클라이언트에서 서버에게 존재를 알리고 패킷이 전송가능함을 알리듯, 서버에서도 클라이언트에게 존재를 알리고 패킷이 전송가능함을 알려야 한다. 그래서 2 way로는 부족하다.  
  
**왜 난수를 사용하나?**  
연결을 맺을 때 사용하는 포트 번호는 시간이 지남에 따라 재사용하는데, 난수가 아니라 순차적인 번호를 사용한다면 이전의 연결에서 오는 패킷으로 인식할 수 있다.

### TCP 4 way handshake
3 way handshake가 TCP의 연결을 초기화 할 때 사용한다면, 4 way handshake는 연결(세션)을 해제하기 위해 사용  
  
![image](https://user-images.githubusercontent.com/44667299/162579953-cf62db42-2f6c-4225-b3fa-e782b17b438c.png)  
  
1. 클라이언트가 연결을 종료하겠다는 FIN 플래그를 전송한다.
2. 서버는 클라이언트의 요청(FIN)을 받고 일단 확인메시지(ACK)를 보내고 자신의 통신이 끝날 때까지(데이터를 모두 보낼 때까지) 기다린다(TIME_OUT).
3. 서버가 통신이 끝났으면 연결이 종료되었다고 클라이언트에게 FIN 플래그를 전송한다.
4. 클라이언트는 확인했다는 메시지(ACK)를 보낸다.
  
**TIME_WAIT**  
클라이언트는 FIN을 수신했어도 서버에서 FIN을 전송하기 전에 전송한 패킷이 FIN보다 늦게 올 것을 대비해 일정 시간동안 세션을 남겨놓고 잉여 패킷을 기다리는데 이 과정을 TIME_WAIT이라 함  
  
**FIN_WAIT, CLOSE_WAIT**  
커널 옵션으로 타임아웃 조절이 가능한 FIN_WAIT이나 재사용이 가능한 TIME_WAIT과 달리, CLOSE_WAIT는 포트를 잡고 있는 프로세스의 종료 또는 네트워크 재시작 외에는 제거할 방법이 없다. 즉, 로컬 어플리케이션이 정상적으로 close()를 요청하는 것이 가장 좋은 방법  
  
**왜 연결 설정(3 way)과 연결 종료(4 way) 과정이 차이나나?**
* 클라이언트가 데이터 전송을 마쳤다고 하더라도 서버는 아직 전송할 데이터가 남아있을 수 있음
* 일단 FIN에 대한 ACK 전송 후, 서버의 데이터 전송이 끝나고 FIN을 전송하므로 한 단계 더 거침

### 흐름제어
송신측과 수신측의 데이터 처리 속도 차이를 해결하기 위한 기법. 만약 송신측의 전송량이 수신측의 처리량보다 많은 경우, 전송된 패킷은 수신측의 큐(버퍼)를 넘어서 손실될 문제가 발생할 수 있기 때문에 송신측의 패킷 전송량을 제어하게 된다.  
  
**1) Stop and Wait(정지-대기)**  
* 매번 전송한 패킷에 대한 확인 응답을 받아야 다음 패킷을 전송
* 구조가 간단한 대신, 하나를 주고 하나를 받기 때문에 비효율적

**2) Sliding Window(슬라이딩 윈도우)**
* 수신측에서 설정한 Window size만큼 송신측에서 확인 응답없이 패킷을 전송해, 데이터흐름을 동적으로 조절
* 패킷에 대한 응답이 확인되는 대로 옆으로 Window size만큼 다음 패킷의 데이터를 전송

전송측 윈도우  
![image](https://user-images.githubusercontent.com/44667299/162582043-4de310ed-88e2-4188-b98f-7e94a72dbb98.png)  

수신측 윈도우  
![image](https://user-images.githubusercontent.com/44667299/162582055-87fd0b51-947c-4dc0-86a7-93885adaaaf0.png)  
  
사진 출처 : https://woovictory.github.io/2018/12/28/Network-Erro-Flow-Control/

### 혼잡제어
네트워크에 존재하는 전송 패킷의 수가 많아질수록 네트워크의 성능은 자연스럽게 감소한다. 이와 같은 성능 감소 현상이 급격하게 악화되는 현상을 혼잡(Congestion)이라 한다.  
  
흐름제어는 송신 호스트와 수신 호스트 사이의 논리적인 점대점 전송 속도를 다룬 반면, 혼잡제어는 더 넓은 관점에서 호스트와 라우터를 포함한 서브넷에서 네트워크의 전송 능력 문제를 다룬다.  
  
송신측의 데이터 전송 속도와 네트워크의 데이터 처리속도의 차이를 해결하기 위한 기법  
  
**혼잡의 원인**
* 초기 혼잡 과정에서 타임 아웃 시간이 작으면 혼잡도가 급격히 증가
* 패킷 도착 순서가 다른 상황에서 패킷을 분실 처리하면 타임아웃 증가
* 의도적으로 피기배킹을 사용하면 응답시간이 느려져 타임아웃 증가
* 패킷 생존 시간을 작게 하면 패킷이 강제로 제거되어 타임아웃 증가
* 라우팅 알고리즘 : 혼잡이 발생하지 않는 경로를 설계해야 함
* 혼잡이 발생하는 경로를 선택하면 혼잡이 주변으로 확대됨
>피기배킹(Piggybacking) : 양방향으로 동시에 정보 프레임과 응답 프레임을 교차하여 전송하는 경우를 사용하는 방식이다. 정보 프레임과 응답 프레임을 각각 보내는 것이 아니라 정보 프레임을 전송하면서 응답 기능까지 동시에 수행하도록 프레임 구조를 변형시킨 것이다. 이렇게 되면 응답 프레임의 전송 횟수를 줄이는 효과가 있어 전송 효율을 높일 수 있다.  
>피기배킹 방식을 사용하는 응답 방식은 혼잡이 발생했을 때 송신 호스트의 타임아웃 기능을 통한 재전송을 유발하여 혼잡을 오히려 가중시킬 우려도 있다.

<br/>  

**1) AIMD(Additive Increase / Muticative Decreas)(합 증가 / 곱 감소)**  
처음에 패킷을 하나씩 보내고 이것이 문제없이 도착할 경우 윈도 크기를 1씩 증가시켜 가면서 전송하는 방법이다. 만약 패킷 전송에 실패하거나 일정 시간을 넘길 경우 패킷을 보내는 속도를 절반으로 줄인다.  
  
공평한 방식으로 여러 호스트가 한 네트워크를 공유하고 있으면 나중에 진입하는 쪽이 처음에는 불리하지만, 시간이 흐르면 평형 상태로 수렴하게 되는 특징이 있다.  
  
초기에는 네트워크의 높은 대역폭을 사용하지 못하기 때문에 오랜 시간이 걸리게 되고, 네트워크가 혼잡해지는 상황을 미리 감지하지 못한다는 문제점이 있다. 즉, 네트워크가 혼잡해지고 나서야 대역폭을 줄이는 방식이다.  
<br/>  

**2) Slow Start**  
미리 정해진 임계치에 도달할 때까지 원도의 크기를 2배씩 증가시킨다.  
  
AIMD 방식은 네트워크의 수용량 주변에서는 효율적으로 작동하지만 처음에 전송 속도를 올리는 데 걸리는 시간이 너무 길다는 단점이 있다.  
  
Slow Start 방식은 AIMD와 마찬가지로 패킷을 하나씩 보내면서 시작하고 패킷이 문제없이 도착할 경우 각각의 ACK 패킷마다 윈도 사이즈를 1씩 늘려준다. 즉, 한 주기가 지나면 윈도 사이즈가 2배가 되기 때문에 선형적으로 증가하지 않고 지수적으로 증가한다. 대신 혼잡현상이 발생할 경우는 윈도의 크기를 1로 떨어뜨리게 된다.  
  
처음에는 네트워크의 수용량을 예상할 수 있는 정보가 없지만 한 번 혼잡 현상이 발생하고 나면 네트워크의 수용량을 어느 정도 예상할 수 있다. 그러므로 혼잡 현상이 발생했던 윈도 크기 절반까지는 지수로 윈도 크기를 증가시키고 그 이후부터는 완만하게 1씩 증가시킨다.
1. 초기 혼잡 Window Size 1로 전송 = 전송 호스트는 하나의 패킷만 전송
2. 수신 호스트로부터 수신응답을 수신하면 윈도우의 크기를 2로 하여 전송
3. 수신 호스트로부터 수신응답을 수신하면 윈도우의 크기를 4로 하여 전송
4. 수신 호스트로부터 수신응답을 수신하면 윈도위의 크기를 8로 하여 전송
* 미리 정해진 임계 값(threshold)에 도달할 때까지 윈도우의 크기를 2배씩 증가시킨다.
* 매 전송마다 두 배씩 증가하기 때문에 전송되어지는 데이터의 크기는 지수 함수적으로 증가한다.

전송되는 데이터 크기가 임계 값에 도달할 경우 혼잡 회피 단계로 넘어간다.  
<br/>  

**3) Congestion Avoidance(혼잡 회피)**  
느린 출발의 지수적 증가가 임계치에 도달하게 되면 혼잡으로 간주하고, 회피를 위해 주고받는 윈도 크기가 선형적으로 증가하여 혼잡을 예방한다.  
  
윈도 크기가 임계 값에 도달한 이후에는 혼잡에 의해 데이터 손실이 발생할 확률이 높아지게 된다. 그렇기에 데이터를 전송하는 데 있어서 조심하는 단계이다.  
  
전송한 데이터에 대한 ACK를 받으면 윈도우의 크기를 1씩 증가시킨다.  
전송하는 데이터의 증가를 왕복시간 동안에 하나씩만 증가시킨다.
* 수신 측으로부터 일정 시간 동안까지 ACK를 수신하지 못하는 경우
  * 타임아웃 발생
  * 네트워크에 혼잡이 발생했다고 인식
    * 윈도우의 크기를 1로 줄임
    * 임계 값을 패킷 손실이 발생하였을 때의 윈도 크기의 반으로 줄임

<br/>  

**4) Fast Retransmission(빠른 재전송)**  
송신 측에서 3개의 중복 패킷을 받게 되면 해당 패킷이 손실되었다고 간주해 타임아웃을 기다리지 않고(타임아웃이 발생하기 전에) 즉시 재전송한다.  
이 현상이 일어난 것은 약간의 혼잡이 발생한 것이므로 Window Size를 반으로 줄인다.  
<br/>  

**5) Fast Recovery(빠른 회복)**  
빠른 재전송 이후 느린 출발이 아닌 혼잡 회피 상태에서 선형적 전송을 하는 기법이다.  
  
빠른 회복 정책은 혼잡한 상태가 되면 윈도 크기를 1로 줄이지 않고 반으로 줄이고 선형 증가시키는 방법이다. 빠른 회복 정책까지 적용하면 혼잡 상황을 한번 겪고 나서부터는 순수한 합 증가/곱 감소 방식으로 동작하게 된다.  
<br/>  

**6) TCP Reno**  
N개의 중복 ACK 발생 시 ssthresh(slow start threshold)값을 Congestion Window(cwnd) 사이즈의 반으로 줄여 빠른 복구(Fast Recovery)를 수행하여 선형적 증가를 하게 되며, TCP Time Out에 이르면 Slow Start를 시작한다.  
<br/>  

**7) TCP Tahoe**  
N개의 중복 ACK 발생 시 바로 Slow Start를 시작한다.  
  
TCP Tahoe와 TCP Reno는 ssthresh(slow start threshold) 값까지 지수적 증가(Slow Start)를 하게 되고 ssthresh를 넘어서면 선형적 증가(Additive Increase)를 하는 것까지는 동일하다. 차이가 생기는 기준은 N개의 중복 ACK가 발생할 경우이다.

### 오류제어
전송된 데이터의 오류를 검출/정정하는 기법  
  
**오류 인지**  
오류를 제어하기 위해선 먼저 오류가 발생했음을 인지 해야함  
TCP 에서 오류를 파악하는 방법은 크게 두가지
1. 수신측에서 송신측으로 명시적으로 NAK 를 전송
2. 전송한 패킷에 대한 ACK 가 오지 않거나 중복된 ACK 가 전송될 때

중복된 ACK 란 보통 3개 이상이 전달 될 때 오류 발생으로 파악하며 1번 방법 사용시 송신측에 NAK를 확인하는 새로운 로직이 필요하기 때문에 일반적으로 2번 방법을 적용해 오류를 인지한다.  
<br/>  

**ARQ(Automatic Repeat reQuest)**
* 수신 측에서 수신한 정보에 오류가 있을 경우, 송신측에 재전송을 요청해 오류를 제어하는 방식
* 프레임이 손상되었거나 손실되었을 경우, 재전송을 통해 오류를 복구한다. ARQ 기법은 흐름 제어 기법과 연관되어 있다.

**1) Stop and Wait ARQ**  
데이터를 보내면 제대로 받았다라는 응답이 올 때까지 대기  
  
![image](https://user-images.githubusercontent.com/44667299/162610241-711d4100-6599-45f3-8283-ec2c23900cd8.png)  
사진 출처 : https://evan-moon.github.io/2019/11/22/tcp-flow-control-error-control/
* 송신측에서 한 개의 프레임을 전송한 후 수신 측으로부터 응답(ACK/NAK)을 기다리는 기법
* 구현이 간단
* 프레임을 전송할 때마다 응답을 기다리므로 전송 효율이 낮음
* 수신측에 데이터를 받지 못했을 경우 NAK를 보내고, NAK를 받은 송신측은 데이터를 재전송한다.
* 만약, 데이터나 ACK가 분실되었을 경우 일정 간격의 시간을 두고 타임아웃이 되면 송신측은 데이터를 재전송한다.

<br/>  

**2) Go Back N ARQ**  
데이터를 연속적으로 보내다가 그 중 어느 데이터부터 오류가 발생했는지를 검사하는 방식  
  
![image](https://user-images.githubusercontent.com/44667299/162610307-e26b940a-1577-4ca2-ab02-b5e3121e0857.png)  
  
전송된 프레임이 손상되거나 분실될 경우, 그리고 ACK 패킷의 손실로 인한 TIME_OUT이 발생한 경우, 확인된 마지막 프레임 이후로 모두 재전송하는 기법
* 오류가 난 지점부터 전송한 지점까지 모두 재전송하는 기법
* 수신측에서 NAK을 보내면 송신측이 오류가 발생한 이후의(NAK 프레임 번호부터) 프레임을 모두 재송신
  * 수신측은 원하는 프레임이 아닐 경우, 데이터를 모두 폐기 처분한다.
  * 타임아웃(ACK 분실)의 경우, 마지막 ACK된 데이터부터 재전송한다.
* 전송오류가 발생하지 않으면 쉬지 않고 송신 가능
* 중복전송의 단점

<br/>  

**3) Selective Repeat ARQ(SR ARQ)**  
말 그대로 선택적인 재전송을 의미. Go Back N 방법도 Stop and Wait에 비하면 많이 효율적인 방법이지만, 에러가 발생하면 그 이후에 정상적으로 전송되었던 데이터까지 모두 폐기 처분되어 다시 전송해야한다는 비효율이 아직 존재. 그래서 에러난 데이터만 재전송하는 방식  
  
![image](https://user-images.githubusercontent.com/44667299/162613439-059c04ee-7dda-422f-a5d6-57a4453a986c.png)  

* 여러 프레임을 연속적으로 전송하고, 수신측에서 NAK을 보내면 송신측에서는 오류가 난 부분의 프레임만 재전송
* 수신측에서는 오류가 발생할 경우, 해당 프레임을 재전송받을 때까지, 이후의 프레임을 버퍼에 담아놨다가 재조립하는 과정이 필요

얼핏 보면 이 방식이 굉장히 효율적이고 좋기만 한 것 같지만 Stop and Wait와 Go Back N 방식과 다르게, 이 방식을 사용하는 수신 측의 버퍼에 쌓인 데이터가 연속적이지 않다는 단점이 존재한다.  
  
위 예시만 봐도 수신 측의 버퍼에는 0, 1, 2, 3, 4, 5가 순차적으로 들어있는 것이 아니라, 중간에 폐기 처분된 4를 제외한 0, 1, 2, 3, 5만 버퍼에 존재할 것이기 때문이다. 이때 송신 측이 4를 재전송하게되면 수신 측은 이 데이터를 버퍼 중간 어딘가에 끼워넣어서 데이터를 정렬해야한다.  
  
이때 같은 버퍼 안에서 데이터를 정렬할 수는 없으니, 별도의 버퍼가 필요하게 된다.
|Go Back N ARQ|Selective Repeat ARQ|
|:---:|:---:|
|손상/분실된 프레임 이후의 프레임을 모두 재전송|손상/분실된 프레임만을 재전송|
|비교적 간단, 구현이 쉬움|구조가 복잡(프레임 재배열 등의 추가 로직 필요)|
|추가 버퍼 필요 없음(데이터 폐기 방식을 사용)|정렬을 위한 추가적인 버퍼 공간이 필요|
|SR ARQ에 비해 비용이 비교적 저렴|유지 관리 비용이 큼|

<br/>  

**4) Adaptive ARQ**  
* 전송 효율을 최대로 하기위해 데이터 프레임의 길이를 (채널의 상태에 따라) 동적으로 변경
* 수신측은 오류 발생률을 판단해 송신측에 통보
* 송신측은 오류 발생률에 따라 프레임 길이를 동적으로 조절
* 효율이 좋음
* 많은 비용 발생

전송 효율이 제일 좋으나, 제어 회로가 복잡하고 비용이 많이 들어 현재는 거의 사용을 안 한다.

## UDP
UDP(User Datagram Protocol, 사용자 데이터그램 프로토콜)는 비연결형 프로토콜 이다.(3 way 같은 연결 설정을 하지 않음)  
  
TCP와는 대비되게 신뢰성(흐름/오류제어)을 포기하고 전송속도를 얻었다. Best Effort 전달 방식을 지원한다.
>Best Effort : 서비스의 quality를 보장하지 않음

프로토콜을 처리하는 기능이 작아 TCP보다 데이터 처리가 빠르므로 데이터 전송 시간에 민감한 응용 환경에서는 UDP를 사용하는 것이 유리하다.  
 → 신뢰성보다 속도가 중요한 상황에 UDP를 사용  
   
ex : 3개의 데이터(패킷)를 전송할 때, 만약 이들간에 연결성(연관성)이 있다면 UDP를 안쓰는게 좋다

|프로토콜|TCP|UDP|
|:---:|:---:|:---:|
|연결 방식|연결형 서비스|비연결형 서비스|
|패킷 교환 방식|가상회선 방식|데이터그램 방식|
|전송 순서|보장|보장하지 않음|
|수신 여부 확인|확인|확인하지 않음|
|통신 방식|Unicast 지원|Unicast, Multicast, Broadcast 지원|
|신뢰성|높음|낮음|
|속도|느림|빠름|

## HTTP
HyperText Transfer Protocol
* 분산 하이퍼미디어 환경에서 빠르고 간편하게 데이터(웹문서)를 전송하는 프로토콜
* 웹 상에서 클라이언트와 서버 간 Request/Response로 정보를 주고 받을 수 있는 프로토콜
* 주로 HTML 문서를 주고 받음
* 포트 80번 사용
* 비연결성(Connectionless) : 클라이언트가 요청을 전송하고 서버가 이에 대한 응답을 하면 바로 연결이 끊어지는 특성
* 무상태성(Stateless) : 연결 끊어진 후에 상태 정보를 유지하지 않는 특성

<br/>  

**HTTP의 요청과 응답**  
RFC 2616으로 발표된 HTTP 1.1 버전은 클라이언트의 요청과 서버의 응답에 의해 동작하는 아주 간단한 프로토콜이다.
* HTTP 클라이언트가 서버에 요청을 전송한다. 요청 내용에는 프로토콜 명령에 해당하는 요청 메서드, URL, HTTP 버전이 포함되며, 기타 클라이언트의 요청과 관련된 부가 정보도 포함한다.
* HTTP 서버는 요청의 처리 결과를 의미하는 응답 코드가 포함된 상태 정보를 회신한다. 클라이언트가 요청한 결과물이나 기타 정보도 함께 회신한다.

<br/>  

**요청 메서드(Request Method)**  
클라이언트가 서버에 실행을 요구하는 명령을 기술
|명령|설명|
|---|---|
|GET|클라이언트가 서버에 URL이 가리키는 웹 문서의 내용을 전송하도록 요구한다. 문서 내용은 서버가 회신하는 응답 메시지의 바디에 포함된다.|
|HEAD|문서 내용보다는 특정 문서의 정보를 원할 때 사용한다.|
|POST|클라이언트가 서버에 정보를 전송할 수 있도록 해준다. 보통 게시판, 방명록처럼 사용자가 입력한 정보를 서버에 전달하는 용도로 사용한다.|
|PUT|클라이언트가 서버에 문서를 전달하려고 사용한다. 문서 내용은 바디에 포함된다.|

**HTTP 상태 코드**
|코드|이름|의미|
|---|---|---|
|200|OK|요청이 성공적으로 수행되었다.|
|202|Accepted|클라이언트의 요청을 수신하였으나, 즉각 실행되지 않고 있다.|
|400|Bad Request|요청 메시지의 내용에 문법 오류가 존재한다.|
|401|Unauthorized|요청을 실행하는 데 필요한 적절한 권한이 존재하지 않는다.|
|403|Forbidden|서비스 요청이 거부되었다.|
|404|Not Found|원하는 문서를 찾을 수 없다.|
|500|Internal Server Error|서버 내부에 불가피한 오류가 발생하였다.|
|501|Not Implemented|요청 사항을 수행할 수 없다.|
|502|Bad Gateway|서버가 요청을 처리하는 데 필요한 응답을 얻기 위해 게이트웨이로 작업하는 동안 잘못된 응답을 수신했다.|
|503|Service Unavailable|서버가 요청을 처리할 준비가 되지 않았다. 일반적인 원인은 유지보수를 위해 작동이 중단되거나 과부하가 걸렸을 때|
|504|Gateway Timeout|서버가 게이트웨이나 프록시 역할을 하고 있거나 또는 업스트림 서버에서 제때 요청을 받지 못했다. 적시에 응답을 받을 수 없을 때 주어진다.|

<br/>  

**요청 메시지 예시**  
![image](https://user-images.githubusercontent.com/44667299/162615379-e7b91c0d-e7e6-4d08-a8cb-f67101cd8a83.png)  
  
요청 메서드, URL, HTTP 버전, 서버주소  

<br/>  

**응답 메시지 예시**  
![image](https://user-images.githubusercontent.com/44667299/162615460-0a6f9eb2-d1dd-4154-a1fe-3d330ae642c4.png)  
  
<br/>  

**주소창에 URL을 입력하면 일어나는 일련의 과정**
1. 사용자가 브라우저를 통해 URL 주소 입력
2. DNS 서버를 통해 해당 도메인의 IP 주소를 받아 함께 전달
3. URL 정보와 IP 주소는 HTTP 프로토콜을 사용해 HTTP request 메시지 생성
4. TCP 프로토콜을 사용해 인터넷을 거쳐 해당 IP 주소의 컴퓨터로 전송
5. HTTP Request 메시지는 HTTP 프로토콜을 사용해 URL 정보로 변환
6. 서버는 도착한 URL 정보에 해당하는 데이터 검색
7. 검색된 데이터는 HTTP 프로토콜을 사용해 HTTP response 메시지 생성
8. HTTP response 메시지는 TCP 프로토콜을 거쳐 원래 컴퓨터로 전송
9. HTTP response 메시지는 HTTP 프로토콜을 사용해 웹 페이지로 변환
10. 변환된 웹 페이지는 브라우저를 통해 사용자에게 제공

### HTTP 버전
**HTTP 0.9**  
HTTP의 초기 버전에는 버전 정보가 없었고 차후에 구분을 위해 0.9라고 불리게 되었다.
* 특징
  * HTTP 초기 버전을 구분하기 위해 부르는 버전 (1991년)
  * 요청은 단일 라인으로 구성되며, 리소스에 대한 method는 GET만 존재
  * 응답도 극도로 단순 (파일 내용 자체로만 구성)
  * HTTP 헤더도 없고, HTML파일만 전송 가능했던 것이 특징
  * 상태 혹은 오류 코드가 없기 때문에 문제의 상황시 해당 파일 내부에 문제에 대한 설명을 포함하여 보냄
* 요청/응답 예시
```html
/* 요청 */
GET /mypage.html

/* 응답 */
<HTML>
A very simple HTML page
</HTML>
```

<br/>  

**HTTP 1.0**  
HTTP/0.9는 매우 제한적이었으며 브라우저와 서버 모두 좀 더 융통성을 가지도록 빠르게 확장되었다.
* 특징
  * HTTP 헤더(header) 개념이 도입되어 요청과 응답에 추가되며, 메타데이터를 주고 받고 프로토콜을 유연하고 확장 가능하도록 개선됨 (1996년)
  * 버전 정보와 요청 method가 함께 전송되기 시작
  * 상태 코드 라인도 응답의 시작부분에 추가되어 브라우저 요청의 성공과 실패를 파악 가능해짐 (해당 결과에 대한 로컬 캐시 갱신 등의 사용이 가능해짐)
  * Content-Type 도입으로 HTML 이외의 문서 전송 기능이 가능해짐
* 한계
  * 커넥션 하나당 요청 하나와 응답 하나만 처리 가능했음
    * 지금 생각해보면 매우 비효율적인 동작으로 보이며, 서버 부하도 문제
    * HTTP 1.1에서 개선
* 요청/응답 예시
```html
/* 요청 */
GET /mypage.html HTTP/1.0
User-Agent: NCSA_Mosaic/2.0 (Windows 3.1)

/* 응답 */
200 OK
Date: Tue, 15 Nov 1994 08:12:31 GMT
Server: CERN/3.0 libwww/2.17
Content-Type: text/html
<HTML>
A page with an image
  <IMG SRC="/myimage.gif">
</HTML>
```

<br/>  

**HTTP 1.1**  
HTTP/1.1은 HTTP의 첫번째 표준 버전이다. 눈에 잘 보이는 추가점은 메서드에 OPTIONS, PUT, DELETE, TRACE 가 추가되었다. 그리고 헤더값도 몇 가지 추가되었다.  
  
추가된 헤더 예시
```text
Via : 중계서버(프록시, 게이트웨이 등)의 지원 프로토이름.버전.호스트명 (ex. via: 1.1 123abc.cloudfront.net (CloudFront))
Accept : 클라이언트의 사용가능 미디어타입 (ex. application/json, text/plain, */*)
…
```
* 특징
  * Persistent Connection(keep alive) 추가
    * 지정한 timemout 동안 커넥션을 닫지 않는 방법을 통해 커넥션의 사용성이 높아짐
    * 커넥션이 재사용될 수 있게 하여, 탐색된 단일 원본 문서 내로 임베드된 리소스들을 디스플레이하기 위해 사용된 커넥션을 다시 열어 시간을 절약
  * Pipelining 추가
    * 앞 요청의 응답을 기다리지 않고 순차적인 여러 요청을 연속적으로 보내고 그 순서에 맞춰 응답을 받는 방식이 등장
    * 순차적으로 하나씩 요청 / 응답이 처리되는 기존 방식을 개선
    * 하나의 커넥션에 여러개의 요청이 들어 있을 뿐, 동시에 여러개의 요청을 처리해 응답으로 보내주는 것은 아니다 (multiplexing 되지는 않음)
  * 추가적인 캐시 제어 메커니즘이 도입
  * 언어, 인코딩 혹은 타입을 포함한 컨텐츠 협상이 도입되어, 클라이언트와 서버로 하여금 교환하려는 가장 적합한 컨텐츠에 대한 동의를 가능케 함
  * Host 헤더 덕분에, 동일 IP 주소에 다른 도메인을 호스트하는 기능이 서버 코로케이션을 가능케 함
* 한계
  * Head Of Line Blocking(HOL)
    * 결국 앞 요청의 응답이 너무 오래걸리면 뒤 요청은 Blocking 되어버림
  * Header 구조의 중복
    * 연속된 요청의 헤더의 많은 중복이 발생
* 요청/응답 예시
```html
/* 요청 */
GET /en-US/docs/Glossary/Simple_header HTTP/1.1
Host: developer.mozilla.org
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Referer: https://developer.mozilla.org/en-US/docs/Glossary/Simple_header

/* 응답 */
200 OK
Connection: Keep-Alive
Content-Encoding: gzip
Content-Type: text/html; charset=utf-8
Date: Wed, 20 Jul 2016 10:55:30 GMT
Etag: "547fa7e369ef56031dd3bff2ace9fc0832eb251a"
Keep-Alive: timeout=5, max=1000
Last-Modified: Tue, 19 Jul 2016 00:59:33 GMT
Server: Apache
Transfer-Encoding: chunked
Vary: Cookie, Accept-Encoding

(content)
```

<br/>  

**HTTP 2.0**  
더 나은 성능을 위한 프로토콜  
Google은 SPDY 프로토콜을 구현하여 HTTP/2 프로토콜의 기초로써 기여했다.  
  
기존 HTTP 1.X 버전의 성능 향상에 초점을 맞춘 프로토콜 (2015년 등장)  
표준의 대체가 아닌 확장 (표준 : HTTP 1.1)

* HTTP 메시지 전송 방식의 전환
* 기존 : 일반 텍스트 형식
* 개선
  * Binary Framing 계층을 추가해서 보내는 메시지를 프레임(frame)이라는 단위로 분할하며 추가적으로 바이너리로 인코딩을 한다 (바이너리 형식 사용으로 파싱속도 및 전송 속도가 빠르고 오류 발생 가능성이 낮아짐)

* 특징
  * HTTP 메시지 전송 방식의 전환
  * Multiplexed Streams
  * Stream Prioritization
  * Server Push
  * Header Compression

>**Multiplexed Streams(요청 및 응답 다중화)**
>* HTTP 1.1 에서는 한번에 커넥션을 맺고 데이터를 요청하고 응답받고를 반복하는데, HTTP 2에서는 스트림(stream)으로 한번의 커넥션으로 동시에 여러 개의 데이터를 주고 받을 수 있다. 이렇게 하여 HTTP 1.x 에서의 이미지 스프라이트, 도메인 분할 같은 임시방편을 사용하지 않아도 된다.
>* Stream을 통해서 각 요청의 응답의 순서가 의미가 없어져서 HOL Blocking이 자연스럽게 해결됨

>**Stream Prioritization(스트림 우선 순위)**
>* 리소스간 우선순위를 설정하는 기능
>* 스트림의 프레임으로 다중화가 가능해짐과 동시에 클라이언트와 서버의 통신 순서를 위해 각 스트림에는 1~256 사이의 정수 가중치가 할당되어 스트림 처리 우선순위를 정한다. 그런데 이게 우선 순위를 지정하여 이를 처리할 CPU, 메모리 및 기타 리소스의 할당을 제어하는 것일 뿐 특정 순서로 처리되도록 서버에 강요될 순 없다.

>**Server Push**
>* 단일 클라이언트 요청에 여러 응답을 보낼 수 있는 특징을 통해 Server에서 Client에게 필요한 추가적인 리소스를 push해주는 기능

>**Header Compression(헤더 압축)**
>* HTTP 1.x의 경우에는 가령 두 개의 동일한 요청을 보낸다고 했을 때, 두 개의 헤더에 중복값이 존재해도 모두 전송한다, HTTP 2에서는 HPACK 압축형식을 사용해서 요청 및 응답 헤더 메타데이터를 압축하는데 이때 이 중복되는 헤더값을 색인값으로 처리해준다.
>* 기존 : 연속된 요청의 경우 많은 중복된 헤더의 전송으로 오버헤드가 많이발생했음
>* 개선
>* 요청과 응답의 헤더 메타데이터를 압축해서 오버헤드를 감소
>* 1) 전송되는 헤더 필드를 static dynamic table로 서버에서 유지
>* 2) 이전에 표시된 헤더를 제외한 필드를 허프만(huffman) 인코딩을 수행해서 데이터를 압축

* 한계
  * 각 요청마다 Stream으로 구분해서 병렬적으로 처리하지만, 결국 이에는 TCP 고유의 HOL Blocking이 존재
  * 왜냐하면, 서로 다른 Stream이 전송되고 있을 때, 하나의 Stream에서 유실이 발생되거나 문제가 생기면 결국 다른 Stream도 문제가 해결될 때 까지 지연되는 현상이 발생되기 때문
  * 즉, 이러한 TCP의 태생적인 HOL Blocking을 해결하기 위해 QUIC / HTTP3.0이 등장

<br/>  

**HTTP 3.0 / QUIC**  
* QUIC
  * Google에서 개발한 UDP 기반의 전송 프로토콜 (Quick UDP Internet Connections)
  * Google에서 TCP의 구조적 문제로 성능 향상이 어렵다고 판단하여 UDP 기반을 선택
  * QUIC은 TCP의 3 way handshake과정을 최적화 하는 것에 초점을 두고 개발됨
  * QUIC은 TCP의 Stream은 하나의 chain으로 연결되는 것과 다르게 각 Stream당 독립된 Stream chain을 구성하여 TCP HOL Blocking을 해결하였다
* HTTP 3.0
  * QUIC을 기반으로 나온 새로운 HTTP 메이저 버전

## HTTPS
* HTTP에서 보안이 강화(암호화, 인증, 완전성 보호)된 버전의 프로토콜
* HTTP 통신하는 소켓 부분을 SSL(Secure Socket Layer) / TLS(Transport Layer Security)라는 프로토콜로 대체
  * SSL 3.0 = TLS 1.0
* 보호의 수준은 웹 브라우저에서의 구현 정확도와 서버 소프트웨어가 지원하는 암호화 알고리즘에 의존

HTTP는 원래 TCP와 직접 통신했지만, HTTPS에서 HTTP는 SSL과 통신하고 SSL이 TCP와 통신 하게 된다. SSL을 사용한 HTTPS는 암호화와 증명서, 안전성 보호를 이용할 수 있게 된다.  
  
HTTPS의 SSL에서는 공통키 암호화 방식과 공개키 암호화 방식을 혼합한 하이브리드 암호 시스템을 사용한다. 공통키를 공개키 암호화 방식으로 교환한 다음에 다음부터의 통신은 공통키 암호를 사용하는 방식이다.

**장점**
* 통신 중간에 제 3자가 정보를 가로챌 수 없으므로 안전

**단점**
* 암호화 하는 과정이 웹 서버에 부하를 줌
* HTTPS는 설치 및 인증서를 유지하는데 추가 비용 발생
* 느림
* 인터넷 연결이 끊긴 경우 재인증 시간이 소요

### HTTPS가 필요 이유
**HTTP의 문제점**
* HTTP 는 평문 통신이기 때문에 도청이 가능하다. → Wireshark 등을 이용한 패킷 스니핑(Sniffing)
* 통신 상대를 확인하지 않기 때문에 위장이 가능하다. → 스푸핑(Spoofing)
* 완전성을 증명할 수 없기 때문에 변조가 가능하다. → Burp Suite 등을 활용한 패킷 위변조

<br/>  

**도청 가능**  
HTTP는 평문 통신이기 때문에 Wireshark 등을 사용하여 패킷을 캡쳐하는 것만으로도 도청할 수 있다.  
(만일 어느 페이지에 로그인을 하는데, 프로토콜이 HTTP라면 이 때 패킷을 캡쳐하면 ID/PW를 알아낼 수 있다)  
SSL/TLS를 사용하여 암호화 해야 함  
  
**위장 가능**  
HTTP에 의한 통신에는 상대가 누구인지 확인하는 처리는 없기 때문에 누구든지 리퀘스트를 보낼 수 있다.  
SSL을 사용하여 서버나 클라이언트의 실재 사실을 증명해야 함  
  
**변조 가능**  
서버와 클라이언트의 통신 사이에 누군가(중간자)가 끼어들어서 통신(패킷)을 변조할 수 있다.  
SSL에는 인증이나 암호화, 그리고 다이제스트(해시값) 기능이 있다.  
  
번외로, 요즘엔 하드웨어의 발달로 HTTPS를 사용해도 성능 저하가 거의 없다고 한다.

### HTTPS HandShake
![image](https://user-images.githubusercontent.com/44667299/162749214-8b1c9b08-c217-403a-8a18-178dc56152f6.png)  
사진 출처 : https://brunch.co.kr/@sangjinkang/38  
  
HTTPS가 TCP 기반의 프로토콜이기 때문에 암호화 협상(SSL HandShake)에 앞서 3 way handshake를 진행함
1. 컴퓨터(브라우저)가 자신의 버전, 암호 알고리즘 목록, 사용 가능한 압축 방식을 Client Hello 메시지에 담아 서버로 전송
2. 클라이언트가 제공한 암호 알고리즘 목록, 압축 방식 목록 중 선택 & 세션 ID, CA에서 사인한 서버의 공개 인증서를 Server Hello에 담아 전송
3. 브라우저는 서버의 SSL 인증서가 믿을만한지 확인. 서버가 보낸 SSL 인증서가 CA 목록에 있는지 확인
4. SSL이 확인되면 클라이언트와 서버가 사용할 대칭키를 형성하기 위해 난수 바이트를 생성해 서버의 공개키로 암호화 후 전송
5. 클라이언트가 보낸 대칭키를 서버의 개인키로 복호화

Client Hello : 가능한 암호화 알고리즘 목록 + 클라이언트 난수 바이트 값 전달  
Server Hello : 적용할 암호화 알고리즘 + 서버 난수 바이트 값 + CA로부터 발급받은 서버의 인증서(CA 개인키로 암호화됨) 전달  
Client 인증서 확인 : 클라이언트는 서버의 인증서가 CA로부터 발급되었는지 확인하기 위해 CA의 공개키를 통해 인증서를 복호화한다.  
Client 대칭키 생성 : 클라이언트는 클라이언트 난수 바이트 값 + 서버 난수 바이트 값을 통해 대칭키를 만든다.  
Clinet 대칭키 암호화 전송 : 대칭키는 인증서 내부에 있던 서버의 공개키로 암호화하여 서버에 보낸다.  
Server 대칭키 복호화 : 서버는 대칭키를 서버의 개인키로 복호화한 후 대칭키를 저장한다.  
통신 : 이후, 클라이언트와 서버는 대칭키를 통해 데이터를 주고 받는다.

## GET VS POST
둘 다 HTTP 프로토콜을 이용해서 서버에 무엇인가를 요청할 때 사용하는 방식  
둘의 특징을 제대로 이해하여 기술의 목적에 맞게 알맞은 용도에 사용해야 함

### GET(가져오다)
GET 방식은 요청하는 데이터가 HTTP Request Message의 Header 부분에 url에 담겨서 전송된다. url 상에 ? 뒤에 데이터가 붙어 request 를 보냄  
로그인 할 때 비밀번호가 url에 노출되면 안된다!  
  
GET 은 가져오는 것이다. 서버에서 어떤 데이터를 가져와서 보여준다거나 하는 용도이지 서버의 값이나 상태 등을 변경하지 않는다.  
(데이터를 조회하는 성향이며, DML의 SELECT와 비슷하다고 생각하면 되겠다)  
GET 방식의 요청은 브라우저에서 Caching 할 수 있다. 데이터의 크기가 작고 보안적인 문제가 없다는 이유로 GET 방식으로 요청한다면 기존에 caching 되었던 데이터가 응답될 가능성이 존재

### POST(게시하다)
POST 방식은 요청하는 데이터가 HTTP Request Message의 Body 부분에 데이터가 담겨서 전송된다.  
  
POST는 서버의 값이나 상태를 변경하기 위해서 또는 추가하기 위해서 사용된다.

## 쿠키와 세션
HTTP 프로토콜이 가지는 비연결성, 무상태 특징이 있다. 클라이언트의 상태를 저장하거나 이전 요청과 현재 요청이 같은 사용자로부터의 요청인지 알기 위해 상태를 유지해야 할 필요성(ex : 로그인)이 있는데, 이때 쿠키 또는 세션을 사용한다

### 쿠키
* 클라이언트에 대한 상태 정보를 key와 value의 형태로 로컬에 저장해 참조하는 방식
* 클라이언트의 상태 정보를 브라우저에 저장해 참조

<br/>  

* 동작 방식
  * 웹 브라우저가 서버에 요청
  * 상태를 유지하고 싶은 값을 쿠키(Cookie)로 생성
  * 서버가 응답할 때 HTTP 헤더(Set-cookie)에 쿠키 정보를 포함해 전송
  * 전달받은 쿠키는 웹 브라우저에서 관리하고 있다가, 다음 요청 시 쿠키를 HTTP 헤더에 넣어서 전송
  * 서버에서 쿠키 정보를 읽어 이전 상태 정보와 일치하는 지 확인 후 응답
* 사용 예
  * 아이디와 비밀번호 저장
  * 쇼핑몰 장바구니

### 세션
* 일정시간 동안 같은 브라우저로부터 들어오는 요청을 하나의 상태로 보고 그 상태를 유지하는 기술

<br/>  

* 동작 방식
  * 웹 브라우저가 서버에 요청
  * 서버가 해당 웹 브라우저(클라이언트)에 세션 ID를 부여
  * 서버가 응답할 때 HTTP 헤더(Set-cookie)에 세션 ID를 포함해 전송
  * 웹 브라우저는 이후 웹 브라우저를 닫기까지 다음 요청 때 부여된 세션 ID가 담겨있는 쿠키를 HTTP 헤더에 담아 전송
  * 서버는 세션 ID를 확인 후 해당 세션에 관련된 정보를 확인하고 응답
* 사용 예
  * 로그인

||쿠키|세션|
|:---:|:---:|:---:|
|저장위치|클라이언트|서버|
|보안|취약|비교적|안전|
|라이프|사이클|만료시간|브라우저의 종료|
|속도|빠름|느림|

## REST와 RESTful의 개념
### REST
Representational State Transfer  
* 자원을 이름 (자원의 표현)으로 구분하여 해당 자원의 상태 (정보)를 주고 받는 모든 것을 의미
* 즉, 자원(resource)의 표현(representation) 에 의한 상태 전달
* 월드 와이드 웹(WWW)과 같은 분산 하이퍼미디어 시스템을 위한 소프트웨어 개발 아키텍처의 한 형식
  * REST는 기본적으로 웹의 기존 기술과 HTTP 프로토콜을 그대로 활용하기 때문에 웹의 장점을 최대한 활용할 수 있는 아키텍처 스타일이다.
  * REST는 네트워크 상에서 Client와 Server 사이의 통신 방식 중 하나이다.
* HTTP URI를 통해 자원을 명시하고, HTTP Method (POST, GET, PUT, DELETE)를 통해 해당 자원에 대한 CRUD OPERATION을 적용하는 것을 의미한다.
* 즉, REST는 자원 기반의 구조 (ROA: Resource Oriented Architecture) 설계의 중심에 Resoure가 있고 HTTP Method를 통해 Resource를 처리하도록 설계된 아키텍쳐를 의미한다.
* 웹의 모든 자원에 고유한 ID인 HTTP URI를 부여한다.
* REST 구성 요소
  * 자원 : URI
    * 모든 자원에 고유한 ID가 존재하고, 이 자원은 Server에 존재한다.
    * Client는 URI를 이용해서 자원을 지정하고 해당 자원의 상태(정보)에 대한 조작을 Server에 요청한다.
  * 행위 : HTTP Method
    * GET, POST, PUT, DELETE
  * 표현
    * Client가 자원의 상태(정보)에 대한 조작을 요청하면 Server는 이에 적절한 응답(Representation)을 보낸다.
    * REST에서 하나의 자원은 JSON, XML, TEXT, RSS 등 여러 형태의 Representation으로 나타내어 질 수 있다.
>URI : 네트워크 상에서 자원을 식별하기 위한 문자열의 구성. 특정 리소스를 식별하는 통합 자원 식별자(Uniform Resource Identifier)  
>URL : 웹 주소. 자원의 위치를 나타내는 주소  
>URL ⊆ URI

<br/>  

**REST가 필요한 이유**
* 애플리케이션 분리 및 통합
* 다양한 클라이언트의 등장. 최근의 서버 프로그램은 다양한 브라우저와 안드로이폰, 아이폰과 같은 모바일 디바이스에서도 통신을 할 수 있어야 한다.
* 이러한 멀티 플랫폼에 대한 지원을 위해 서비스 자원에 대한 아키텍처를 세우고 이용하는 방법을 모색한 결과, REST에 관심을 가지게 되었다.

### RESTful
* RESTful은 일반적으로 REST라는 아키텍처를 구현하는 웹 서비스를 나타내기 위해 사용되는 용어이다.
  * REST API를 제공하는 웹 서비스를 RESTful하다고 할 수 있다.
* RESTful은 REST를 REST답게 쓰기 위한 방법으로, 누군가가 공식적으로 발표한 것이 아니다.
  * 즉, REST 원리를 따르는 시스템은 RESTful이란 용어로 지칭된다.

<br/>  

**왜 RESTful APIs를 만드는 것일까?**
* Client Side를 정형화된 플랫폼이 아닌 모바일, PC, 어플리케이션 등 플랫폼에 제약을 두지 않는 것을 목표로 했기 때문
* 스마트폰의 보급 전에는 Server Side에서 데이터를 전달해주는 Client 프로그램의 대상은 PC 브라우저로 그 대상이 명확 했다. 그렇다 보니 그냥 JSP ASP PHP 등을 이용한 웹페이지를 구성하고 작업을 진행하면 됐다.
* 하지만 스마트 기기들이 등장하면서 TV, 스마트 폰, 태블릿 등 Client 프로그램이 다양화 되고 그에 맞춰 Server를 일일이 만다는 것이 꽤 비효율적인 일이 되어 버렸다.
* 이 과정에서 개발자들은 Client Side를 전혀 고려하지 않고 메시지 기반, XML, JSON과 같은 Client에서 바로 객체로 치환 가능한 형태의 데이터 통신을 지향하게 되면서 Server와 Client의 역할을 분리하게 되었다.
>이런 변화를 겪으면서 필요해진 것은 HTTP 표준 규약을 지키면서 API를 만드는 것이다.

**RESTful의 목적**
* 이해하기 쉽고 사용하기 쉬운 REST API를 만드는 것
* RESTful한 API를 구현하는 근본적인 목적이 성능 향상에 있는 것이 아니라 일관적인 컨벤션을 통한 API의 이해도 및 호환성을 높이는 것이 주 동기이니, 성능이 중요한 상황에서는 굳이 RESTful한 API를 구현할 필요는 없다.

## DNS 흐름
왜 DNS를 쓰나?  
네트워크를 통해 통신하려면 IP 주소를 알아야 하는데, 숫자로 된 IP 주소를 외우는 것 보단 문자로 된 도메인 네임을 기억하는 것이 인간의 뇌엔 훨씬 편하다.  
(naver.com / 223.130.195.95 둘 중 어느것을 외우는게 더 편한가?)  
DNS는 그 변환을 해준다  
  
![image](https://user-images.githubusercontent.com/44667299/162940575-ae6d5cb5-1b35-44b1-9079-17aa9a5f68b0.png)  
사진 출처 : https://dheldh77.tistory.com/entry/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-DNSDomain-Name-System  
  
1. 사용자가 브라우저에 blog.example.com을 입력
2. 클라이언트는 가장 먼저 해당 도메인 네임이 hosts 파일과 cache 파일에 저장되어 있는지 확인
3. 클라이언트에 저장되어 있지 않다면, DNS 서버에 도메인 네임에 해당하는 IP주소를 질의
4. root DNS 서버는 "com"을 관리하는 TLD(Top Level DNS)서버를 질의
5. TLD 서버는 "example.com"을 관리하는 SLD(Second Level DNS) 서버를 질의
6. SLD 서버는 "blog.example.com"의 IP 주소를 질의
7. DNS 서버가 알아낸 "blg.example.com"의 IP 주소를 클라이언트에 응답
![image](https://user-images.githubusercontent.com/44667299/162940933-ee6b12ec-d722-466f-955e-0ed455b5d8a7.png)

### DNS round robin 방식
별도의 소프트웨어 혹은 하드웨어 로드밸런싱 장비를 사용하지 않고, DNS만을 이용하여 도메인 레코드 정보를 조회하는 시점에서 트래픽을 분산하는 기법  
  
DNS 선에서 부하를 분산시키기 때문에 로드 밸런서가 필요가 없다.

### DNS Round Robin 방식의 문제점
* 서버의 수 만큼 공인 IP 주소가 필요함

부하 분산을 위해 서버의 대수를 늘리기 위해서는 그 만큼의 공인 IP 가 필요하다.
* 균등하게 분산되지 않음

모바일 사이트 등에서 문제가 될 수 있는데, 스마트폰의 접속은 캐리어 게이트웨이 라고 하는 프록시 서버를 경유한다. 프록시 서버에서는 이름변환 결과가 일정 시간 동안 캐싱되므로 같은 프록시 서버를 경유 하는 접속은 항상 같은 서버로 접속된다. 또한 PC 용 웹 브라우저도 DNS 질의 결과를 캐싱하기 때문에 균등하게 부하분산 되지 않는다. DNS 레코드의 TTL 값을 짧게 설정함으로써 어느 정도 해소가 되지만, TTL 에 따라 캐시를 해제하는 것은 아니므로 반드시 주의가 필요하다.
* 서버가 다운되도 확인 불가

DNS 서버는 웹 서버의 부하나 접속 수 등의 상황에 따라 질의결과를 제어할 수 없다. 웹 서버가 어떤 원인으로 다운되더라도 이를 검출하지 못하고 유저들에게 제공한다. 이때문에 유저들은 간혹 다운된 서버로 연결이 되기도 한다. DNS 라운드 로빈은 어디까지나 부하분산을 위한 방법이지 다중화 방법은 아니므로 다른 S/W와 조합해서 관리할 필요가 있다.  
  
이 문제점의 해결 책으로 DNS 스케줄링 알고리즘이 존재한다.

### Weighted round robin (WRR)
각각의 웹 서버에 가중치를 가미해서 분산 비율을 변경한다. 가중치가 큰 서버일수록 빈번하게 선택되므로 처리능력이 높은 서버는 가중치를 높게 설정하는 것이 좋다.

### Least connection
접속 클라이언트 수가 가장 적은 서버를 선택한다. 로드밸런서에서 실시간으로 connection수를 관리하거나 각 서버에서 주기적으로 알려주는 것이 필요하다.

## Socket(TCP/IP Socket)
네트워크 응용 프로그램은 소켓을 통하여 데이터를 송수신한다. 소켓은 응용 프로그램이 네트워크로 데이터를 내보내거나 받기 위한 창구 역할을 한다.  
소켓은 떨어져 있는 두 호스트를 연결해주는 도구로써 인터페이스의 역할을 하는데 데이터를 주고 받을 수 있는 구조체로 소켓을 통해 데이터 통로가 만들어 진다.  
  
**소켓의 구성요소**
* 프로토콜
  * 통신에서의 프로토콜은 어떤 시스템이 다른 시스템과 통신을 원활하게 수용하도록 해주는 통신 규약, 약속
* IP
  * 전 세계 컴퓨터에 부여된 고유의 식별 주소
* 포트
  * 네트워크 상에서 통신하기 위해서 호스트 내부적으로 프로세스가 할당받아야 하는 고유한 숫자. 한 호스트 내에서 네트워크 통신을 하고 있는 프로세스를 식별하기 위해 사용되는 값이므로, 같은 호스트 내에서 서로 다른 프로세스가 같은 포트 넘버를 가질 수 없다.
  * 통신을 하는데 사용하는 도로라고 보면 된다.

<br/>

**Socket 통신**
* Server와 Client가 특정 Port를 통해 실시간으로 양방향 통신을 하는 방식

<br/>

|HTTP|Socket|
|---|---|
|Client가 요청을 보내는 경우에만 Server가 응답하는 단방향 통신<br/>Server로 부터 응답을 받은 후에는 연결이 바로 종료됨|Server와 Client가 계속 연결을 유지하는 양방향 통신|
|실시간 연결이 아니고, 필요한 경우에만 Server로 요청을 보내는 상황에 유용|Server와 Client가 실시간으로 데이터를 주고 받는 상황이 필요한 경우에 사용|
|요청을 보내 Server의 응답을 기다리는 어플리케이션의 개발에 주로 사용|실시간 동영상 Streaming이나 온라인 게임 등과 같은 경우에 자주 사용|

### Socket 이전 실시간 통신 기술들
* Polling
  * 클라이언트가 일정한 주기로 요청을 보내는 방식
  * 구현하기는 쉬우나 클라이언트가 계속 요청을 보내야 하기 때문에 불필요한 자원이 들고 서버에 부담이 생긴다.(변경사항이 없는데도 계속 요청하고 응답받아야 하는 자원 낭비가 발생)
* Long Polling
  * 클라이언트가 요청을 보내는 것은 동일하지만 Polling의 단점을 해소하기 위해 이벤트 내용이 있을 때까지 서버에서 조금 더 대기를 하여 이벤트가 발생했을 때 응답하는 방식
  * Polling에 비해 요청량이 줄어들어 서버의 부담은 작아지지만, 결국 많은 양의 요청이 들어오면 Polling과 동일해짐
* Streaming
  * 서버에 요청을 보내고 끊기지 않은 연결 상태에서 끊임없이 데이터를 수신하는 방법
  * 이벤트의 빈도수가 높을 경우는 Polling, Long Polling 보다 훨씬 효율적이지만 연결에 대한 유효성 관리라는 부담이 발생
  * 클라이언트에서 서버로의 데이터 송신이 어렵다는 단점

위 세 가지 방식을 Commet이라고 통칭하며, HTTP를 통해 통신하기 때문에 request, response 모두 헤더가 불필요하게 크다는 공통적인 단점이 있다.(오버헤드)

### 클라이언트 소켓과 서버 소켓
**클라이언트 소켓**  
클라이언트 소켓은 기다릴 필요가 없기 때문에 바로 클라이언트 소켓을 생성한다. 클라이언트 프로그램에서 클라이언트 소켓은 서버프로그램으로 연결요청을 하는것과 데이터 전송을 하는 일을 한다.  
  
**클라이언트 소켓 통신 과정**  
* 소켓을 생성
  * 클라이언트와 특정 서버와 통신을 하기 위해서는 운영체제에 socket() 시스템콜을 통해 소켓을 생성함
* 소켓을 연결
  * connect() 시스템 콜을 호출하여 서버와 클라이언트간 연결 함
  * 3 way handshake 방식을 사용해서 연결 함
* 데이터 송수신
  * read(), write() 시스템 콜로 실행함
  * 프로토콜 스택은 받은 데이터내용을 바로 송신하는것이 아니라 일단 자체 송신용 버퍼 메모리영역에 저장하고 에플리케이션이 데이터를 건내주기를 기다림
  * 데이터 양이 너무 적으면 빈번하게 송신이 일어나기 때문에 모아서 전송할 수 있고 반대로 데이터 양이 너무 크면 분할하여 보냄
* 소켓연결 종료
  * close() 시스템 콜로 실행
  * 4 way handshake 방식을 사용해서 연결을 종료

**서버 소켓**  
서버 프로그램에서 사용하는 소켓. 서버 소켓은 클라이언트로부터 연결 요청이 오기를 기다렸다가 연결 요청이 들어오면 클라이언트와 연결을 맺고 다른 소켓을 만드는 일을 한다.  
  
**서버 소켓 통신 과정**
* 소켓을 생성
  * 서버와 클라이언트 간 통신을 하기 위해서는 운영체제에 socket() 시스템콜을 통해 소켓을 생성
* 소켓을 바인딩
  * bind() 시스템 콜을 사용
  * 소켓과 포트 번호를 결합하는 과정
  * 해당 포트가 사용중인지 사용중이지 않는지 확인하고 사용을 하고 있지 않은 포트라면 결합
* 연결요청을 대기
  * listen() 시스템 콜을 사용
  * 포트번호 (또는 ip and port)가 서버소켓과 바인딩이 완료되었다면 클라이언트의 연결 요청이 수신될때까지 대기
  * 즉 클라이언트에서 connect()를 사용할때까지 대기
* 연결을 허용
  * accept() 시스템 콜을 사용
  * accept API에서 새로운 소켓을 만들어 해당 소켓으로 클라이언트와 연결
  * 상위에서 사용했던 서버 소켓은 클라이언트 연결요청을 수신하는 소켓이고 실질적으로 연결되는 소켓은 accept()를 통해 이루어짐
* 송수신
  * 데이터를 송수신 하는 과정은 클라이언트와 동일
  * read(), write() 시스템 콜을 사용
* 소켓연결 종료
  * close() 시스템콜을 사용
  * 주의할 점은 close 대상이 두개라는 점. 클라이언트와 연결에 사용했던 서버 소켓과 accept() 로 만들었던 소켓 2개를 종료해야함

### 소켓 API 실행흐름
![image](https://user-images.githubusercontent.com/44667299/162983454-9300d94b-705a-474c-a869-6fcdbf0b4008.png)  
사진 출처 : https://helloworld-88.tistory.com/215  
  
**클라이언트 실행 흐름**
* 클라이언트 소켓 생성
  * 연결 대상에 대한 정보가 들어있지 않은 Socket(껍데기 소켓)을 생성
  * 이 때 소켓의 종류를 선택해야하는데 TCP 소켓을 위해선 stream 타입을, UDP 소켓을 위해선 데이터그램 타입으로 지정이 가능
* 연결 요청(Connection)
  * 연결하고 싶은 대상한테 연결 요청을 보낸다. IP주소와 서비스 포트 번호로 연결하고 싶은 타켓대상을 특정
  * 요청을 보내고 단순히 끝나는게 아니고, 그 요청에 대한 결과가 돌아와야만 Connect의 실행이 끝난다.
* 데이터의 송수신(Send, Recieve)
  * 연결 요청과 같이 요청을 보낸다고 끝나는 게 아니라 요청에 대한 결과(신호)가 들어와야 실행이 끝난다.
  * 송신할 때에는 데이터를 보내는 것이기 때문에 데이터를 언제 얼마나 보낼것인지 알 수 있지만, 수신할 때에는 상대방이 언제, 얼만큼의 데이터를 보낼 것인지 알수가 없다는 서로의 차이점이 존재
  * 그렇기 때문에 수신하는 API는 별도의 Thread에서 진행하게 됨
* 소켓 닫기
  * 더 이상의 데이터 송수신이 없다고 판단되면 소켓을 닫음

**서버 흐름**
* 서버 소켓 생성
  * 클라이언트 소켓과 마찬가지로 연결 대상에 대한 정보가 들어있지 않은 껍데기 소켓을 생성
* 바인딩(bind)
  * 만약 서버 소켓이 받은 데이터를 다시 보내주어야 할 때 프로세스들의 포트번호가 동일하다면 혼란이 생길 수 있다. 따라서 서버 소켓이 고유한 포트 번호를 만들 수 있도록 소켓과 포트번호를 결합해주는 작업이 필요
* 클라이언트 연결 요청 대기
  * 클라이언트가 연결 요청을 할 때까지 기다리다가 연결 요청이 오면 대기 상태를 종료하고 리턴
* 클라이언트 연결 수립
  * 서버 소켓은 연결 요청을 받아들임과 동시에 새로운 소켓을 생성
  * 클라이언트 소켓으로부터 연결 요청을 받으면 새로운 소켓을 열고, 이것과 클라이언트 소켓을 맵핑하여 넘겨줌
* 데이터 송수신(Send, Recieve)
  * 클라이언트와 동일
* 소켓 닫기
  * 클라이언트와 동일함. 하지만 서버 소켓은 자신이 생성한 소켓들도 관리를 해야함

## Web Socket(HttpSocket)
* 웹 소켓
  * 양방향 통신 프로토콜로서 클라이언트와 서버는 TCP로 통신
  * 실시간 전송 가능
  * 웹 페이지의 한계에서 벗어나 실시간으로 상호작용하는 웹 서비스를 만드는 표준 기술
* 특징
  * 소켓을 이용해 데이터를 송수신
  * 클라이언트와 서버 간 적은 오버헤드
  * 실시간 전송 가능
  * HTTP 통신에서 Full-duplex 통신 제공
    * 그래서 요청과 응답을 구분하지 않음
  * HTTP Request를 사용하므로 추가적인 방화벽을 열지 않고도 양방향 통신 가능하고 CORS 적용이나 인증 등의 과정을 기존과 동일하게 적용
  * 클라이언트와 서버 모두 Web Socket을 지원해야 함

|Socket|Web Socket|
|---|---|
|Web Socket 보다 더 일반적인 개념|웹 애플리케이션을 위해 서버와 실시간 웹 통신을 지원하기 위한 프토토콜|
|HTTP 프로토콜이나 브라우저에 제한되지 않음|HTTP Request를 통해 handshaking 과정을 거침|

### Web Socket HandShake 및 실행 흐름
![image](https://user-images.githubusercontent.com/44667299/162988387-361d21cd-1ca1-43a1-80d7-c73b2d326a78.png)  
사진 출처 : https://kellis.tistory.com/65  
  
붉은 박스로 표시된 Opening Handshake와 노란 박스로 표시된 Data transfer, 보라색 박스로 표시된 Closing Handshake, 세 가지 영역으로 나눌 수 있다.  
  
(1) Opening Handshake  
웹소켓 클라이언트에서 핸드쉐이크 요청(HTTP Upgrade)을 전송하고 이에 대한 응답으로 핸드 셰이크 응답을 받는데, 이때 응답 코드는 101이다. 101은 '프로토콜 전환'을 서버가 승인했음을 알리는 코드이다.  
이 과정에서 요청과 응답의 헤더를 살펴본다. ws://localhost:8080/chat 으로 접속한다고 가정
```text
GET /chat HTTP/1.1
Host: localhost:8080
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw==
Sec-WebSocket-Protocol: chat, superchat
Sec-WebSocket-Version: 13 Origin: http://localhost:9000
```
* Upgrade : 프로토콜을 전환하기 위해 사용하는 헤더. 웹소켓 요청 시에는 반드시 websocket이라는 값을 가지며, 이 값이 없거나 다른 값이면 cross-protocol attack이라고 간주하여 웹소켓 접속을 중지시킨다.
* Connection : 현재의 전송이 완료된 후 네트워크 접속을 유지할 것인가에 대한 정보. 웹소켓 요청 시에는 반드시 Upgrade라는 값을 가지며, Upgrade와 마찬가지로 이 값이 없거나 다른 값이면 웹소켓 접속을 중지시킨다.
* Sec-WebSocket-Key : 유효한 요청인지 확인하기 위해 사용하는 키 값
* Sec-WebSocket-Protocol : 사용하고자 하는 하나 이상의 웹 소켓 프로토콜 지정. 필요한 경우에만 사용
* Sec-WebSocket-Version : 클라이언트가 사용하고자 하는 웹소켓 프로토콜 버전
* Origin : 모든 브라우저는 보안을 위해 이 헤더를 보낸다(Cross-Site WebSocket Hijacking와 같은 공격을 피하기 위해서). 대부분 어플리케이션은 이 헤더가 없는 요청을 거부하며, 이러한 이유로 CORS 정책이 만들어졌다.

(2) Data Transfer
핸드쉐이크를 통해 웹소켓 연결이 수립되면, 데이터 전송 파트가 시작된다. 여기에서는 클라이언트와 서버가 '메시지'라는 개념으로 데이터를 주고 받는데, 여기서 메시지는 한 개 이상의 '프레임'으로 구성되어 있다. (프레임은 텍스트(UTF-8) 데이터, 바이너리 데이터, 컨트롤 프레임(프로토콜 레벨의 신호) 등이 있다)  
핸드 셰이크가 끝난 시점부터 서버와 클라이언트는 서로가 살아 있는지 확인하기 위해 heartbeat 패킷을 보내며, 주기적으로 ping을 보내 체크한다. 이는 서버와 클라이언트 양측에서 설정 가능하다.  
  
(3) Close Handshake  
클라이언트와 서버 모두 커넥션을 종료하기 위한 컨트롤 프레임을 전송할 수 있다. 이 컨트롤 프레임은 Closing Handshake를 시작하라는 특정한 컨트롤 시퀀스를 포함한 데이터를 가지고 있다. 서버가 커넥션을 종료한다는 프레임을 보내고, 클라이언트가 이에 대한 응답으로 Close 프레임을 전송한다. 그러면 웹소켓 연결이 종료된다. 연결 종료 이후에 수신되는 모든 추가적인 데이터는 버려진다.

### WebSocket 한계
웹 소켓은 HTML5 이후에 나왔기 때문에, HTML5 이전의 기술에는 적용이 어려움
* Socket.io와 SockJS라는 것을 이용해서 HTML5 이전 기술로 구현된 서비스에서도 웹 소켓처럼 사용할 수 있다.  
* Javascript를 이용하여 브라우저 종류에 상관없이 실시간 웹을 구현  
* 브라우저와 웹 서버의 종류와 버전을 파악하여 가장 적합한 기술을 선택하여 사용하는 방식  
>Socket.io
>* Node.js 기반의 실시간 이벤트 서버를 개발할 수 있는 오픈 소스 라이브러리. 실시간 웹 기술을 손쉽게 사용할 수 있는 모듈
>* Websock, Polling, Streaming 등 다양한 방법을 하나의 API로 추상화
>* 브라우저의 종류에 상관없이 실시간 웹 구현 가능

웹 소켓은 문자열들을 주고 받을 수 있게 해줄 뿐 그 이상의 일은 하지 않음
* 즉 주고 받은 문자열의 해독은 온전히 애플리케이션에만 맡긴다.
* HTTP는 형식이 있으므로 애플리케이션에서 해석이 쉽지만, WS는 형식이 정해져 있지 않아서 해석하기 어려움
* 따라서 WS 방식은 Sub Protocol을 사용해서 주고 받는 메시지의 형태를 약속하는 경우가 많음
* 이러한 Sub Protocol 중 하나가 STOMP(Simple Text Oriented Message Protocol)
>STOMP
>* 채팅 통신을 하기 위한 형식을 정의
>* HTTP와 유사하게 간단히 정의되어 해석하기 편한 프로토콜
>* 일반적으로 웹 소켓 위에서 사용됨

## CORS
* 웹 브라우저에서 외부 도메인 서버와 통신하기 위한 방식을 표준화한 스펙
* 서버와 클라이언트가 정해진 헤더를 통해 서로 요청이나 응답에 반응할지 결정하는 방식
* 추가 HTTP 헤더를 사용하여, 한 출처에서 실행 중인 웹 애플리케이션이 다른 출처의 선택한 자원에 접근할 수 있는 권한을 부여하도록 브라우저에 알려주는 체제
* 웹 애플리케이션은 리소스가 자신의 출처(도메인, 프로토콜, 포트)와 다를 때 교차 출처 HTTP 요청을 실행

교차 출처 요청의 예시: `domain-a.com`의 프론트 엔드 JavaScript 코드가 `XMLHttpRequest`를 사용하여 `domain-b.com/data.json`을 요청하는 경우  
보안 상의 이유로, 브라우저는 스크립트에서 시작한 교차 출처 HTTP 요청을 제한한다.  
`XMLHttpRequest`는 동일 출처 정책을 따른다. 즉, 이 API를 사용하는 웹 애플리케이션은 자신의 출처와 동일한 리소스만 불러올 수 있으며, 다른 출처의 리소스를 불러오려면 그 출처에서 올바른 CORS 헤더를 포함한 응답을 반환해야 한다.

## OSI 7Layer VS TCP/IP 4Layer VS TCP/IP 5Layer

**왜 7계층으로 나누나?**
* 계층을 분리함으로서 각 계층은 독립적인 역할을 할 수 있음
* 역할이 분리되면서 문제 발생시 문제의 현상을 보았을 때 어떤 계층에 문제가 생겼는지도 파악이 가능
* 각 계층은 하위계층을 사용하고 현계층의 기능을 포함하여 상위 계층에 제공(그래서 계층구조는 위에서 바라보았을 때 아래층이 안보이는 구조라 볼 수 있음)
* 따라서 최상위 계층만 보면 그 아래계층을 모두 포함

TCP/IP 모델은 4 Layer 버전도 있지만 현재는 Updated된 5 Layer가 널리 사용됨  
  
![image](https://user-images.githubusercontent.com/44667299/162995383-7af4d8cb-967d-41b1-b5f5-773e1972aff0.png)  
사진 출처 : https://velog.io/@osk3856/TCP-Updated-Model

## 웹 통신 전체 흐름
인터넷 브라우저의 주소창에 URL을 입력할 때

### 브라우저
1. url 에 입력된 값을 브라우저 내부에서 결정된 규칙에 따라 그 의미를 조사
2. 조사된 의미에 따라 HTTP Request 메시지를 만듦
3. 만들어진 메시지를 웹 서버로 전송

이 때 만들어진 메시지 전송은 브라우저가 직접하는 것이 아니다. 브라우저는 메시지를 네트워크에 송출하는 기능이 없으므로 OS에 의뢰하여 메시지를 전달한다.  
OS에 송신을 의뢰할 때는 도메인명이 아니라 ip주소로 메시지를 받을 상대를 지정해야 하는데, 이 과정에서 DNS서버를 조회해야 한다.

### 프로토콜 스택, LAN 어댑터
1. 프로토콜 스택(운영체제에 내장된 네트워크 제어용 소프트웨어)이 브라우저로부터 메시지를 받음
2. 브라우저로부터 받은 메시지를 패킷 속에 저장
3. 그리고 수신처 주소 등의 제어정보를 덧붙임
4. 그런 다음, 패킷을 LAN 어댑터에 넘김
5. LAN 어댑터는 다음 Hop의 MAC주소를 붙인 프레임을 전기신호로 변환
6. 신호를 LAN 케이블에 송출

프로토콜 스택은 통신 중 오류가 발생했을 때, 이 제어 정보를 사용하여 고쳐 보내거나, 각종 상황을 조절하는 등 다양한 역할을 함. 네트워크 세계에서는 비서가 있어서 우리가 비서에게 물건만 건네주면, 받는 사람의 주소와 각종 유의사항을 써준다. 여기서는 프로토콜 스택이 비서의 역할을 한다고 볼 수 있다.

### 허브, 스위치, 라우터
1. LAN 어댑터가 송신한 프레임은 스위칭 허브를 경유하여 인터넷 접속용 라우터에 도착
2. 라우터는 패킷을 프로바이더(통신사)에게 전달
3. 인터넷으로 들어가게 됨

### 액세스 회선, 프로바이더
1. 패킷은 인터넷의 입구에 있는 액세스 회선(통신 회선)에 의해 POP(Point Of Presence, 통신사용 라우터)까지 운반
2. POP 를 거쳐 인터넷의 핵심부로 들어가게 됨
3. 수 많은 고속 라우터들 사이로 패킷이 목적지를 향해 흘러가게 됨

### 방화벽, 캐시서버
1. 패킷은 인터넷 핵심부를 통과하여 웹 서버측의 LAN 에 도착
2. 기다리고 있던 방화벽이 도착한 패킷을 검사
3. 패킷이 웹 서버까지 가야하는지 가지 않아도 되는지를 판단하는 캐시서버가 존재

굳이 서버까지 가지 않아도 되는 경우를 골라낸다. 액세스한 페이지의 데이터가 캐시서버에 있으면 웹 서버에 의뢰하지 않고 바로 그 값을 읽을 수 있다. 페이지의 데이터 중에 다시 이용할 수 있는 것이 있으면 캐시 서버에 저장된다.

### 웹 서버
1. 패킷이 물리적인 웹 서버에 도착하면 웹 서버의 프로토콜 스택은 패킷을 추출하여 메시지를 복원하고 웹 서버 애플리케이션에 넘긴다.
2. 메시지를 받은 웹 서버 애플리케이션은 요청 메시지에 따른 데이터를 응답 메시지에 넣어 클라이언트로 회송
3. 왔던 방식대로 응답 메시지가 클라이언트에게 전달

# 운영체제
## 프로세스(Process)
CPU에 의해 처리되는 사용자 프로그램, 시스템 프로그램, 즉 실행 중인 프로그램을 의미하며, 작업(Job) 또는 태스크(Task)라고도 한다.  
실행 중인 프로그램으로 디스크로부터 메모리에 적재되어 CPU의 할당을 받을 수 있는 것을 말한다. 운영체제로부터 주소 공간, 파일, 메모리 등을 할당받으며 이것들을 총칭하여 프로세스라고 한다. 구체적으로 살펴보면 프로세스는 함수의 매개변수, 복귀 주소와 로컬 변수 같은 임시 자료를 갖는 프로세스 스택과 전역 변수들을 수록하는 데이터 섹션을 포함한다. 또한 프로세스는 프로세스 실행 중에 동적으로 할당되는 메모리인 힙을 포함한다.

### 프로세스 상태
![image](https://user-images.githubusercontent.com/44667299/161418773-d365a148-fc64-43dd-8f3d-0eee5391d44e.png)  
|프로세스 상태|설명|
|:---:|---|
|생성(new)(Create)|<ul><li>사용자에 의해 프로세스가 생성된 상태</li></ul>|
|준비(Ready)|<ul><li>CPU를 할당받을 수 있는 상태</li><li>준비 리스트 : 각각 우선순위를 부여하여 가장 높은 우선순위를 갖는 프로세스가 다음 순서에 CPU를 할당 받음</li></ul>|
|실행(Running)|<ul><li>프로세스가 CPU를 할당받아 동작 중인 상태</li></ul>|
|대기(Waiting)|<ul><li>프로세스 실행 중 입출력 처리 등으로 인해 CPU를 양도하고 입출력 처리가 완료까지 대기 리스트에서 기다리는 상태</li><li>대기 리스트 : 우선순위가 존재하지 않음</li></ul>|
|완료(Complete)/<br/>종료(Terminated)|<ul><li>프로세스가 CPU를 할당받아 주어진 시간 내에 완전히 수행을 종료한 상태</li></ul>|

### 프로세스 상태 전이
|프로세스 상태 전이|설명|
|:---:|---|
|디스패치<br/>(Dispatch)|<ul><li>준비 상태에 있는 여러 프로세스(Ready List) 중 실행될 프로세스를 선정(Scheduling)하여 CPU를 할당(Dispatching) → 문맥교환 발생</li><li>프로세스는 준비 상태에서 실행 상태로 전이</li></ul>|
|할당 시간 초과<br/>(Timeout)|<ul><li>CPU를 할당받은 프로세스는 지정된 시간이 초과되면 스케줄러에 의해 PCB 저장, CPU 반납 후 다시 준비 상태로 전이됨</li><li>프로세스는 실행 상태에서 준비 상태로 전이</li><li>타임 슬라이스(Time Slice) 만료, 선점(Preemption) 시 타임아웃 발생</li></ul>|
|입출력 발생<br/>(Block)|<ul><li>실행 상태에 있는 프로세스가 지정된 할당 시간을 초과하기 전에 입출력이나 기타 사건이 발생(block)하면 CPU를 스스로 반납하고 입출력이 완료될 때 까지 대기 상태로 전이됨</li><li>프로세스는 실행 상태에서 대기 상태로 전이</li><li>즉시 실행 불가능한 시스템 콜, I/O 작업 시작, 프로세스 간 통신 시 Block 발생</li></ul>|
|깨움<br/>(Wake-up)|<ul><li>어느 순간에 입출력이 종료되면 대기 상태의 프로세스에게 입출력 종료 사실을 wait & signal 등에 의해 알려주고, 준비 상태로 전이됨</li><li>프로세스는 대기 상태에서 준비 상태로 전이</li></ul>|
>문맥교환(COntext Switching) : CPU가 현재 실행하고 있는 프로세스의 문맥 상태를 프로세스 제어블록(PCB)에 저장하고 다음 프로세스의 PCB로 부터 문맥을 복원하는 작업을 문맥교환이라고 한다.

### 프로세스 제어 블록(Process Control Block, PCB)
특정한 프로세스를 관리할 필요가 있는 정보를 포함하는 운영체제 커널의 자료 구조이다.  
프로세스의 상태 정보를 저장하는 자료구조. 운영체제가 프로세스를 표현한 것이라 할 수 있다.  
각 프로세스가 생성될 때마다 고유의 PCB가 생성되고, 메인 메모리에 의해 유지되며,  
운영체제에서 한 프로세스의 존재를 정의한다. 프로세스가 완료되면 PCB는 제거된다.  
  
프로세스는 CPU를 할당받아 작업을 처리하다가도 프로세스 전환이 발생하면 진행하던 작업을 저장하고 CPU를 반환해야 하는데, 이때 작업의 진행 상황을 모두 PCB에 저장하게 된다. 그리고 다시 CPU를 할당받게 되면 PCB에 저장되어있던 내용을 불러와 이전에 종료됬던 시점부터 다시 작업을 수행한다.
|PCB 구성요소|설명|
|:---:|---|
|프로세스 식별자<br/>(Process ID)|<ul><li>각 프로세스에 대한 고유 식별자</li></ul>|
|프로세스 상태<br/>(Process State)|<ul><li>생성, 준비, 실행, 대기, 중단 등의 상태를 표시</li></ul>|
|프로그램 카운터<br/>(Program Counter)|<ul><li>이 프로세스가 다음에 실행할 명령어의 주소를 가리킴</li></ul>|
|레지스터 저장 영역<br/>(CPU 레지스터)|<ul><li>누산기, 인덱스 레지스터, 범용 레지스터, 조건 코드 등에 관한 정보</li><li>인터럽트가 발생하면 프로그램 카운터와 함께 저장되어 다시 실행될 때 원상 복귀할 수 있게 함</li></ul>|
|프로세스(CPU) 스케줄링 정보|<ul><li>우선순위, 스케줄링 큐에 대한 포인터, 그 외 다른 스케줄 매개변수</li></ul>|
|계정(어카운팅) 정보|<ul><li>프로세서 사용 시간, 실제 사용 시간, 사용 상한 시간, 계정 번호, 작업이나 프로세스 번호 등</li></ul>|
|입출력 상태 정보|<ul><li>입출력 요구 프로세스에 할당된 입출력장치 목록, 열린 파일 목록 등</li></ul>|
|메모리 관리 정보|<ul><li>해당 프로세스의 주소 공간, 페이지 테이블, 세그먼트 테이블 정보 등</li></ul>|

## 스레드(Thread)
프로세스 실행의 단위  
동일한 일을 하는 부분이 많은 프로세스를 여러 개 생성하는 것은 메모리 낭비이다. 그래서 프로세스는 하나만 생성하고 Program Counter만 여러 개 생성한다. 즉, CPU 수행 단위를 여러 개를 두는 것이며 이를 스레드라고 한다.
* 스레드는 프로세스보다 가벼운, 독립적으로 수행되는 순차적인 제어의 흐름이며, 실행 단위이다.
* 스레드는 프로세스에서 실행 제어만 분리한 실행 단위로 한 개의 프로세스는 여러 개의 스레드를 가질 수 있다.
* 각 스레드별로 자신만의 스택과 레지스터를 가진다.

스레드 종류
|스레드 종류|설명|
|:---:|---|
|사용자 수준의 스레드|<ul><li>사용자가 만든 라이브러리를 사용하여 스레드를 운용</li><li>속도는 빠르지만 구현이 어려움</li><li>라이브러리 차원에서 지원되는 스레드이다. 프로세스 안에 스레드가 여러 개 있다는 것을 OS가 모르기 때문에 커널 입장에서는 하나의 일반적인 프로세스로 인식된다.</li></ul>|
|커널 수준의 스레드|<ul><li>운영체제의 커널에 의해 운용되는 스레드</li><li>구현은 쉽지만 속도가 느림</li><li>프로세스 내 스레드가 여러 개라는 것을 OS가 알고 있는 스레드이다. 그래서 커널이 스레드 스케줄링을 맡아서 하게 된다.</li></ul>|

프로세스와 스레드의 비교  
프로세스는 운영체제로부터 자원을 할당받는 작업의 단위이고  
스레드는 프로세스가 할당받은 자원을 이용하는 실행의 단위이다.
|구분|프로세스(Process)|스레드(Thread)|
|:---:|---|---|
|요소 기술|PCB, 텍스트, 데이터, 힙, 스택|스레드 ID, 레지스터 집합, 스택|
|통신 방법|프로세스 간 통신은 IPC, Pipe, Message, 공유메모리 등을 사용|스레드 간 통신에는 IPC, Pipe, Message뿐 아니라, 전역 변수를 사용할 수 있음|
|시스템 부하|문맥전환을 통해 프로세스 간 전환이 일어나기 때문에 시스템 부하가 큼|경량화된 문맥전환을 사용하여 시스템 부하가 적음|
|활용|운영체제의 기본 구성요소로서, Linux의 경우 Init 프로세스부터 fork하여 시스템을 동작함|Multi Thread를 사용한 서버|
|라이브러리 함수|fork()|pthread_create(), pthread_join()|
* 커널 스레드의 경우 운영체제에 의해 스레드를 운용한다.
* 사용자 스레드의 경우 사용자가 만든 라이브러리를 사용하여 스레드를 운용한다.

### 스택을 스레드마다 독립적으로 할당하는 이유
* 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이고 이는 독립적인 실행 흐름이 가능하게 한다.
* 따라서 스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당한다.

### PC Register 를 스레드마다 독립적으로 할당하는 이유
* PC값은 스레드가 명령어의 어디까지 수행하였는지를 나타내게 된다.
* 스레드는 CPU를 할당받았다가 스케줄러에 의해 다시 선점당한다.
* 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다.
* 따라서 PC 레지스터를 독립적으로 할당한다.

## 멀티 스레드
하나의 프로그램(프로세스)을 여러 개의 스레드로 구성하여 작업을 처리하도록 하는 것

### 멀티 스레딩의 장점
* 스레드들은 각자의 stack, 레지스터 영역을 제외한 모든 메모리(ex : 코드/데이터/힙 영역)를 서로 공유하기 때문에 통신의 부담이 적다. → 응답시간 단축
* 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리할 수 있다.
* 스레드간 데이터를 주고 받는 것이 간단해지고 시스템 자원 소모 감소
* 스레드 사이의 작업량이 작아 Context Switching(캐시 메모리를 비울 필요가 없음)이 빠르다.

### 멀티 스레딩의 문제점
* 설계가 빡셈
* 주의 깊은 설계가 필요하다.
* 디버깅이 까다롭다.
* 단일 프로세스 시스템의 경우 효과를 기대하기 어렵다.
* 다른 프로세스에서 스레드를 제어할 수 없다.(즉, 프로세스 밖에서 스레드 각각을 제어할 수 없다.)
* 자원 공유의 문제가 발생한다. 다수의 스레드가 특정 자원을 동시에 사용하는 것을 고려해야 한다. 즉, 동기화 처리가 필요하다.
  * 동기화를 통해 스레드의 작업 처리 순서와 공유 자원에 대한 접근을 제어해야 한다.
  * 일반적으로 락(Lock)을 이용하여 동기화 처리를 하는데, 락이 과도하면 병목 현상이 발생하여 성능 저하를 유발할 수 있다.
* 하나의 스레드에 문제가 발생하면 전체 프로세스가 영향을 받는다. → 공유하는 메모리를 소유하기 때문

### 멀티 스레드 vs 멀티 프로세스
멀티 스레드  
* 하나의 프로세스 내에 존재하는 다수의 스레드, 메모리 공간(코드, 데이터, 힙)을 공유하지만, 스택, PC 영역은 공유하지 않음
* 오류로 인해 스레드 하나가 종료되면 전체 스레드가 종료될 수 있음 + 동기화 문제

멀티 프로세스
* 독립적인 다수의 프로세스, 메모리 공간(코드, 데이터, 힙, 스택)을 공유하지 않음
* 하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 미치지 않음
* 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지함

![image](https://user-images.githubusercontent.com/44667299/161428745-baeb6167-d247-47a7-ae7e-387a8ff6ad4f.png)  
그림출처 : https://goodmilktea.tistory.com/24

## 스케줄러
* 한정적인 메모리를 여러 프로세스가 효율적으로 사용할 수 있도록 다음 실행 시간에 실행할 수 있는 프로세스 중에 하나를 선택하는 역할
* CPU를 사용하려고 하는 프로세스들 사이의 우선순위를 관리
* 처리율과 CPU 이용률을 증가시키고 오버헤드, 응답시간, 반환시간, 대기시간을 최소화시키기 위한 기법
* 특정 프로세스가 적합하게 실행되도록 프로세스 스케줄링에 의해 프로세스 사이에서 CPU 교체가 일어남

프로세스를 스케줄링하기 위한 Queue에는 세 가지 종류가 존재한다.
* Job Queue : 현재 시스템 내에 있는 모든 프로세스의 집합
* Ready Queue : 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
* Device Queue : Device I/O 작업을 대기하고 있는 프로세스의 집합

각각의 Queue에 프로세스를 넣고 빼주는 스케줄러에도 크게 세 가지 종류가 존재한다.
* 스케줄러의 유형에는 장기, 단기, 중기가 있다

프로세스 스케줄링 주요 용어
|용어|설명|
|:---:|---|
|서비스 시간|<ul><li>프로세스가 결과를 산출하기까지 소요되는 시간</li></ul>|
|응답시간<br/>(Response Time)|<ul><li>프로세스들이 입력되어 서비스를 요청하고, 반응하기 시작할 때까지 소요되는 시간</li></ul>|
|반환시간<br/>(Turnaround Time)|<ul><li>프로세스들이 입력되어 수행하고 결과를 산출하기까지 소요되는 시간</li><li>반환시간 = 대기시간 + 수행시간</li></ul>|
|대기시간|<ul><li>프로세스가 프로세서에 할당되기까지 큐에 대기하는 시간</li><li>프로세스가 도착 즉시 프로세서에 할당되면 대기시간 '0'임</li></ul>|
|평균 대기시간|<ul><li>프로세스가 대기 큐에서 대기하는 평균 시간</li><li>대기시간이 '0'인 프로세스도 평균 대기 시간에 합산하여 결과 도출</li></ul>|
|종료 시간|<ul><li>요구되는 Processing time을 모두 수행하고 종료된 시간</li></ul>|
|시간 할당량<br/>(Time Quantum 또는 Time Slice)|<ul><li>한 프로세스가 프로세서를 독점하는 것을 방지하기 위해 서비스되는 시간 할당량</li></ul>|
|응답률|<ul><li>(대기시간 + 서비스시간)/서비스 시간</li><li>HRN(Highest Responce ratio Next) 스케줄링에서 사용</li><li>HRN 스케줄에서 응답률이 높으면 우선순위가 높다 판단</li></ul>|

### 장기스케줄러(Long-term scheduler or job scheduler)
메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장된다. 이 pool에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 ready queue로 보낼지 결졍하는 역할을 한다.
* 메모리와 디스크 사이의 스케줄링을 담당
* 프로세스에 memory(및 각종 리소스)를 할당(admit)
* degree of Multiprogramming 제어 (메모리에 여러 프로그램이 올라가는 것) 몇 개의 프로그램이 올라갈 것인지를 제어
* 프로세스의 상태 : new → ready(in memory)

cf) 메모리에 프로그램이 너무 많이 올라가도, 너무 적게 올라가도 성능이 좋지 않은 것이다. 참고로 time sharing system 에서는 장기 스케줄러가 없다. 그냥 곧바로 메모리에 올라가 ready 상태가 된다.

### 단기스케줄러(Short-term scheduler or CPU scheduler)
* CPU와 메모리 사이의 스케줄링을 담당
* Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정
* 프로세스에 CPU를 할당(scheduler dispatch)
* 프로세스의 상태 : ready → running → waiting → ready

### 중기스케줄러(Medium-term scheduler or Swapper)
* 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄 (swapping)
* 프로세스에게서 memory를 deallocate
* degree of Multiprogramming 제어
* 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절하는 스케줄러
* 프로세서의 상태 : ready → suspended

## CPU 스케줄러
스케줄링 대상은 Ready Queue에 있는 프로세스들이다.
* 메모리에 있는 준비(Ready)상태의 프로세스 중 하나를 선택 해 CPU의 자원을 할당

### FCFS(First Come First Served)
* 비선점형(Non-Preemptive) 스케줄링 방식
* 먼저 도착한 프로세스가 CPU를 먼저 할당
* 큐를 이용해 쉽게 구현 가능
* 콘보이 현상 발생 가능
>콘보이 현상(Convoy Effect) : burst time이 긴 프로세스가 먼저 도착해 다른 프로세스의 실행 시간이 전부 늦춰져 효율을 떨어뜨리는 현상

### SJF(Shortest - Job - First)
* 비선점형(Non-Preemptive) 스케줄링 방식
* burst time이 짧은 프로세스가 먼저 CPU를 할당
* Starvation 발생 가능
>기아 현상(Starvation) : 계속해서 우선순위가 높은 프로세스(burst time이 짧은)가 먼저 실행되어 먼저 도착했어도 우선순위가 낮은 프로세스(burst time이 긴)가 계속해서 CPU를 할당받지 못하는 현상

### SRTF(Shortest Remaining Time First)
* 선점형(Preemptive) 스케줄링 방식
* 새로운 프로세스가 도착할 때 마다 새로운 스케줄링이 이루어짐
* 남은 burst time이 더 짧은 프로세스에 CPU를 할당
* Starvation 발생 가능
>새로운 프로세스가 도달할 때마다 스케줄링을 다시하기 때문에 CPU burst time(CPU 사용시간)을 측정할 수가 없다.

### Priority Scheduling
* 선점과 비선점 두가지 방식에 모두 적용 가능
  * 선점형(Preemptive) 스케줄링 방식
    * 더 높은 우선순위의 프로세스가 도착하면 실행중인 프로세스를 멈추고 CPU를 선점한다.
  * 비선점형(Non-Preemptive) 스케줄링 방식
    * 더 높은 우선순위의 프로세스가 도착하면 Ready Queue의 Head에 넣는다.
* 우선순위가 높은 프로세스에 CPU를 먼저 할당
  * 우선순위란 정수로 표현하게 되고 작은 숫자가 우선순위가 높다.
* 기아 현상과 무기한 봉쇄가 발생할 수 있으며 에이징 기법을 통해 해결
>무기한 봉쇄(Indefinite blocking) : 실행 준비는 되어 있으나 CPU를 사용못하는 프로세스를 CPU가 무기한 대기하는 상태

>에이징 기법(Aging) : 먼저 도착한 프로세스가 나이를 계속 먹으며 우선순위가 올라가는 기법. 아무리 우선순위가 낮은 프로세스라도 오래 기다리면 우선순위를 높여주자.

### Round Robin
* 선점형(Preemptive) 스케줄링 방식
* 현대적인 CPU 스케줄링
* 프로세스에 동일한 할당 시간(Time Quantum)만큼 순서대로 계속 CPU를 할당
* 할당 시간이 지나면 프로세스는 선점당하고 ready queue의 제일 뒤에 가서 다시 줄을 선다.
* 응답시간이 빠르며, 모든 프로세스가 공정하게 CPU를 할당받을 수 있음을 보장
* CPU 사용시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적
* 라운드 로빈이 가능한 이유는 프로세스의 context를 save 할 수 있기 때문이다.
* 단, CPU 할당 시간(Time Quantum)이 길 경우, FCFS랑 같아짐
* 또 너무 작아지면 스케줄링 알고리즘의 목적에는 이상적이지만 잦은 context switch로 overhead가 발생한다. 그렇기 때문에 적당한 time quantum을 설정하는 것이 중요하다.

## 동기와 비동기 및 Sync와 Async 차이

### 동기(Synchronous)
말 그대로 동시에 일어난다는 뜻. 요청과 그 결과가 동시에 일어난다는 약속인데, 바로 요청을 하면 시간이 얼마가 걸리던지 요청한 자리에서 결과가 주어져야 함
* 요청한 결과가 한자리에서 동시에 일어남
* A노드와 B노드 사이의 작업 처리 단위(transaction)를 동시에 맞추겠다.

설계가 매우 간단하고 직관적이지만 결과가 주어질 때까지 아무것도 못하고 대기해야 하는 단점

### 비동기(Async)
동시에 일어나지 않는다는 의미. 요청과 결과가 동시에 일어나지 않을거라는 약속.
* 요청한 그 자리에서 결과가 주어지지 않음
* 노드 사이의 작업 처리 단위를 동시에 맞추지 않아도 된다.

동기보다 복잡하지만 결과가 주어지는데 시간이 걸리더라도 그 시간 동안 다른 작업을 할 수 있으므로 자원을 효율적으로 사용할 수 있는 장점

### Sync vs Async
일반적으로 동기와 비동기의 차이는 메소드를 실행시킴과 동시에 반환 값이 기대되는 경우를 동기 라고 표현하고 그렇지 않은 경우에 대해서 비동기 라고 표현한다. 동시에라는 말은 실행되었을 때 값이 반환되기 전까지는 blocking 되어 있다는 것을 의미한다. 비동기의 경우, blocking 되지 않고 이벤트 큐에 넣거나 백그라운드 스레드에게 해당 task를 위임하고 바로 다음 코드를 실행하기 때문에 기대되는 값이 바로 반환되지 않는다.

## 동시성 문제
두 개 이상의 세션이 공통된 자원에 대해서, 모두 읽고 쓰는 작업(Read → Write)을 하려고 하는 경우 발생할 수 있는 문제를 가리킨다.

### Critical Section(임계영역)
멀티 스레딩에 문제점에서 나오듯, 동일한 자원을 동시에 접근하는 작업(ex : 공유하는 변수 사용, 동일 파일을 사용 등)을 실행하는 코드 영역  
  
**임계 영역 문제 해결조건**  
* 상호 배제(Mutual Exclusion)
  * 한 스레드가 임계 영역에서 실행 중이면 다른 스레드는 접근 불가능
  * 프로세스 P1이 Critical Section에서 실행중이라면, 다른 프로세스들은 그들이 가진 Critical Section에서 실행될 수 없다.
* 진행(Progress)
  * 임계 영역에서 실행중인 스레드가 없다면, 임계 영역으로 진입하려는 스레드 중 하나는 유한한 시간 내에 진입할 수 있어야 함
  * Critical Section에서 실행중인 프로세스가 없고, 별도의 동작이 없는 프로세스들만 Critical Section 진입 후보로서 참여될 수 있다.
* 한정된 대기(Bounded Waiting)
  * 임계 영역에 대한 진입 요청 후 만한한 시간을 기다리지 않는 것을 보장
  * P1이 Critical Section에 진입 신청 후 부터 받아들여질 때까지, 다른 프로세스들이 Critical Section에 진입하는 횟수는 제한이 있어야 한다.

### RaceCondition
두 개 이상의 프로세스(스레드)가 공통 자원을 병행적으로(concurrently) 읽거나 쓰는 동작을 할 때, 공용 데이터에 대한 접근이 어떤 순서에 따라 이루어졌는지에 따라 그 실행 결과가 같지 않고 달라지는 상황. Race의 뜻 그대로, 간단히 말하면 경쟁하는 상태, 즉 두 개의 스레드가 하나의 자원을 놓고 서로 사용하려고 경쟁하는 상황을 말한다.

### Deadlock(교착상태)
* 둘 이상의 프로세스들이 자원을 점유한 상태에서 서로 다른 프로세스가 점유하고 있는 자원을 요구하며 무한정 기다리는 현상
* 다중프로세싱 환경에서 두 개 이상의 프로세스가 특정 자원할당을 무한정 대기하는 상태
* 세마포가 Ready Queue를 가지고 있고, 둘 이상의 프로세스가 Critical Section 진입을 무한정 기다리고 있고, Critical Section에서 실행되는 프로세스는 진입 대기 중인 프로세스가 실행되야만 빠져나올 수 있는 상황

![image](https://user-images.githubusercontent.com/44667299/161562341-74cd9850-4a5e-4ded-84f2-f01aa7eac352.png)
>Semaphores(세마포) : 소프트웨어상에서 Critical Section 문제를 해결하기 위한 동기화 도구. 공유된 자원의 데이터 혹은 임계영역 등에 여러 Process 혹은 Thread가 접근하는 것을 막아줌(즉, 동기화 대상이 하나 이상)

### Deadlock 발생 조건
|발생 조건|설명|
|:---:|---|
|상호배제<br/>(Mutual Exclusive)|<ul><li>프로세스가 자원을 배타적으로 점유하여 다른 프로세스가 그 자원을 사용할 수 없는 상태</li><li>한 번에 한 프로세스만 공유 자원에 접근 가능하며, 공유 자원에 대한 접근 권한이 제한</li></ul>|
|점유와 대기<br/>(Hold & Wait)|<ul><li>한 프로세스가 자원을 점유하고 있으면서 또 다른 자원을 요청하여 대기하고 있는 상태</li><li>공유 자원에 대한 접근 권한을 가지고 있는 프로세스가 다른 자원에 대한 접근 권한을 요구</li></ul>|
|비선점<br/>(Non Preemption)|<ul><li>한 프로세스가 점유한 자원에 대해 다른 프로세스가 선점할 수 없고, 오직 점유한 프로세스만이 해제 가능한 상태</li><li>한 프로세스가 다른 프로세스의 자원을 강제로 빼앗을 수 없음</li></ul>|
|환형 대기<br/>(Circular Wait)|<ul><li>두 개 이상의 프로세스 간 자원의 점유와 대기가 하나의 원형을 구성한 상태</li></ul>|

### Deadlock 해결 방법
|해결방법|설명|세부기법|
|:---:|---|---|
|예방<br/>(Prevention)|상호배제를 제외한 나머지 교착상태 발생 조건을 위배(부정)하는 방안|점유 자원 해제 후 새 자원 요청|
|회피<br/>(Avoidance)|안전한 상태를 유지할 수 있는 요구만 수락(프로세스별 자원 최대요구량 확보)|은행가 알고리즘, Wound-wait, Wait-Die|
|발견<br/>(Detection)|시스템의 상태를 감시 알고리즘 통해 교착 상태 검사|자원할당 그래프, Wait for Graph|
|복구<br/>(Recovery)|교착상태가 없어질 때까지 프로세스를 순차적으로 Kill하여 제거, 희생자 선택해야하고 기아 상태 발생|프로세스 Kill, 자원선점|

## 메모리 관리 전략
메모리 용량이 증가함에 따라 프로그램의 크기 또한 계속 증가하고 있기 떄문에 메모리는 언제나 부족  
각 프로세스는 독립된 메모리 공간을 갖고, 운영체제나 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있음.  
(단, 운영체제만이 운영체제 메모리 영역과 사용자 메모리 영역에 접근에 제약을 받지 않음)  
  
* 메모리 관리는 중앙 처리 장치, 메모리, 스토리지, 주변 기기 등을 적절히 관리하는 기법이다.
* CPU가 프로그램을 읽어서 연속적으로 동작하기 위해서는 메모리 관리의 역할이 중요하다

메모리 관리 기본 사항
|기본사항|설명|
|:---:|---|
|가상메모리<br/>(Virtual Memory)|<ul><li>각 프로그램에 실제 메모리 주소가 아닌 가상의 메모리 주소를 부야하는 방식</li><li>가상 주소(Virtual Address), 물리 주소(Physical Address)가 있고 가상 주소의 범위를 가상 주소 공간, 물리 주소의 범위를 물리 주소 공간이라 함</li><li>가상 주소 공간은 메모리 관리 장치(MMU)에 의해서 물리 주소로 변환</li></ul>|
|메모리 관리 장치<br/>(MMU)|<ul><li>CPU가 메모리에 접근하는 것을 관리하는 컴퓨터 하드웨어 부품</li><li>가상 메모리 주소를 실제 메모리 주소로 변환</li><li>메모리 보호, 캐시 관리, 버스 중재 등의 역할을 담당</li></ul>|
|메모리 관리자|<ul><li>기억장치의 어느 부분이 사용 중인지 또는 아닌지를 조사하여 프로세스에게 필요할 때마다 기억장치를 할당 후 회수하는 작업 수행</li><li>실행 파일 심볼의 재배치 주소를 프로세스의 논리 주소로 연결시키는 작업 수행</li></ul>|
  
메모리 관리 기법  
* 운영체제의 역할에서 메모리 관리가 큰 역할을 차지하는 이유는 메모리가 고가의 자원이고, 시스템에서 중요한 역할을 수행하기 때문이다.

|기법|설명|세부기법|
|:---:|---|---|
|반입 기법|<ul><li>주기억장치에 적재할 다음 프로세스의 반입시기를 결정하는 기법</li><li>메모리로 적재 시기 결정(When)</li></ul>|<ul><li>요구 반입 기법</li><li>예상 반입 기법</li></ul>|
|배치 기법|<ul><li>디스크에 있는 프로세스를 주기억장치의 어느 위치에 저장할 것인지 결정하는 기법</li><li>메모리 적재 위치 결정(Where)</li></ul>|<ul><li>최초 적합(First Fit)</li><li>최적 적합(Best Fit)</li><li>최악 적합(Worst Fit)</li></ul>|
|할당 기법|<ul><li>실행해야 할 프로세스를 주기억장치에 어떤 방법으로 할당할 것인지 결정하는 기법</li><li>메모리 적재 방법 결정(How)</li></ul>|<ul><li>연속 할당 기법</li><li>분산 할당 기법</li></ul>|
|교체 기법|<ul><li>재배치 기법으로 주기억장치에 있는 프로세스 중 어떤 프로세스를 제거할 것 인지를 결정하는 기법</li><li>메모리 교체 대상 결정(Who)</li></ul>|<ul><li>프로세스의 Swap In/Out</li><li>FIFO, LRU, LFU</li></ul>|
  
메모리 반입 기법
|기법|설명|
|:---:|---|
|요구 반입 기법|다음에 실행될 프로세스가 참조 요구가 있을 경우에 적재하는 기법|
|예상 반입 기법|시스템의 요구를 예측하여 미리 메모리에 적재하는 방법으로 요구되는 페이지 이외 다른 페이지도 함께 적재|
  
메모리 배치 기법
|기법|설명|
|:---:|---|
|최초 적합<br/>(First Fit)|프로세스가 적재될 수 있는 가용 공간 중에서 첫 번째 분할에 할당하는 방식|
|최적 적합<br/>(Best Fit)|가용 공간 중에서 가장 크기가 비슷한 공간을 선택하여 프로세스를 적재하는 방식(공백 최소화 장점|
|최악 적합<br/>(Worst Fit)|프로세스의 가용 공간 중에서 가장 큰 공간에 할당하는 방식|
  
메모리 할당 기법  
프로세스를 실행시키기 위해 주기억장치에 어떻게 할당할 것인지에 대한 내용
|종류|설명|기법|
|:---:|---|---|
|연속 할당 기법|<ul><li>실행을 위한 각 프로세스를 주기억장치 공간내에서 인접되게 연속하여 저장하는 방법</li><li>연속 할당 기법은 프로세스를 주기억장치에 연속으로 할당하는 기법</li></ul>|<ul><li>단일 분할 할당 기법 : 오버레이, 스와핑</li><li>다중 분할 할당 기법 : 고정 분할 할당 기법, 동적 분할 할당 기법</li></ul>|
|분산 할당 기법|<ul><li>하나의 프로세스를 여러 개의 조각으로 나누어 주기억장치 공간 내 분산하여 배치하는 기법</li><li>주로 가상기억장치에서 사용</li></ul>|<ul><li>페이징 기법</li><li>세그먼테이션 기법</li><li>페이징/세그먼테이션 기법</li></ul>|
  
교체 기법
* 주기억 장치에 있는 프로세스 중 어떤 프로세스를 제거할 것인지 결정하는 기법
* 새로운 페이지를 할당하기 위해 현재 할당된 페이지 중 어느 것과 교체할지를 결정하는 방법

|세부 기법|설명|
|:---:|---|
|FIFO<br/>(First In First Out)|<ul><li>각 페이지가 주기억장치에 적재될 때마다 그때의 시간을 기억시켜 가장 먼저 들어와 가장 오래 있던 페이지를 교체하는 기법(선입선출)</li></ul>|
|LRU<br/>(Least Recently Used)|<ul><li>사용된 시간을 확인하여 가장 오랫동안 사용되지 않은 페이지를 선택하여 교체하는 기법</li><li>프로그램의 지역성의 원리에 따라서 최근에 참조된 페이지는 앞으로도 참조될 가능성이 크고, 최근에 참조되지 않은 페이지는 앞으로도 참조되지 않을 가능성이 크다는 전제로 구현된 알고리즘</li></ul>|
|LFU<br/>(Least Frequently Used)|<ul><li>사용된 횟수를 확인하여 참조 횟수가 가장 적은 페이지를 선택하여 교체하는 기법</li><li>기억장치에 저장된 페이지 중에서 사용한 횟수가 가장 적은 페이지를 교체하는 알고리즘</li></ul>|
|OPT<br/>(OPTimal Replacement)|<ul><li>앞으로 가장 오랫동안 사용하지 않을 페이지를 교체하는 기법</li><li>페이지 부재 횟수가 가장 적게 발생하는 가장 효율적인 알고리즘</li></ul>|
|NUR<br/>(Not Used Recently)|<ul><li>LRU와 비슷한 알고리즘으로, 최근에 사용하지 않은 페이지를 교체하는 기법</li><li>최근에 사용되지 않은 페이지는 앞으로도 사용되지 않을 가능성이 크다는 것을 전제로, LRU에서 나타나는 시간적인 오버헤드를 줄일 수 있음</li><li>최근의 사용 여부를 확인하기 위해서 페이지마다 참조 비트와 변형 비트 사용</li></ul>|
|SCR<br/>(Second Chance Replacement)|<ul><li>가장 오랫동안 주기억장치에 있던 페이지 중 자주 사용되는 페이지의 교체를 방지하기 위한 기법으로 FIFO 기법의 단점을 보완하는 기법</li></ul>|
  
**Swapping**  
* 메모리 관리를 위해 사용되는 기법으로, 라운드 로빈과 같은 스케줄링의 다중 프로그래밍 환경에서 CPU할당 시간이 끝난 프로세스의 메모리를 보조기억 장치(하드디스크)로 내보내고 다른 프로세스의 메모리를 불러들일 수 있음.
* 주 기억장치(RAM)으로 불러오는 과정을 swap-in, 보조 기억장치로 내보내는 과정을 swap-out이라고함.
* swap에는 큰 디스크 전송 시간이 요구되기 때문에 현재엔 메모리 공간이 부족할 때 swapping이 시작됨.

프로세스가 실행되기 위해서는 메모리에 있어야 하지만, 프로세스는 실행 중에 임시로 예비저장장치(backup store)에 내보내어 졌다가 실행을 계속하기 위해 다시 메모리로 돌아올 수 있다. 보통 예비저장장치는 속도가 빠른 디스크를 사용한다. 저장장치의 크기는 모든 사용자 메모리 이미지를 저장할 수 있을정도로 커야하며, 메모리 이미지에 대한 직접 접근이 가능하다. 스와핑의 대략적인 순서를 살펴보자.  
![image](https://user-images.githubusercontent.com/44667299/161737434-200d7351-36cb-4941-b616-3aad9772ea71.png)  
그림출처 : https://dduddublog.tistory.com/28  
  
1. 시스템은 실행 준비가 끝난 프로세스들을 준비완료 큐에 대기시킨다.
2. CPU스케쥴러는 다음 프로세스를 고를 때 Dispatcher(디스패처)를 호출한다.
3. Dispatcher는 이 큐에 있는 다음 프로세스가 메모리에 적재되어있는지 확인하고, 만약 올라와 있지 않다면 디스크에서 불러들여야 한다.
4. 만약 프로세스를 불러들이기 위한 공간이 메모리에 부족하다면 현재 메모리에 적재된 프로세스들을 내보내고(swap out) 원하는 프로세스를 불러들인다(swap in)
5. 그 후 CPU의 모든 레지스터를 실행해야 할 프로레스의 것으로 다시 적재 후 제어를 프로세스에게 넘긴다.

문맥 교환으로 인한 오버헤드가 발생할 수 있고 속도가 느려지지만, 메모리 공간 확보에는 효율적  
  
  
**단편화(Fragmentation)**
* 프로세스들이 메모리에 적재되고 제거되는 일이 반복되다 보면, 프로세스들이 차지하는 메모리 틈 사이에 사용하지 못할 크기의 작은 빈 공간들이 늘어나게되는 것.
* 분할된 주기억장치에 프로세스를 할당, 반납 과정에서 사용되지 못하고 낭비되는 기억장치가 발생하는 현상
* 유형으로는 내부 단편화와 외부 단편화가 있다.
  
* 외부 단편화 : 메모리 공간 중 일부 사용 못하게 되는 부분. 물리 메모리(RAM)에서 사이사이 남는 공간들을 모두 합치면 충분한 공간이 되는 부분들이 분산(Scattered Holes)되어 있을 때 발생

|구분|설명|
|:---:|---|
|개념|<ul><li>할당된 크기 프로세스 크기보다 작아서 사용하지 못하는 공간</li><li>가변 분할 할당 방식 또는 세그먼테이션 기법 사용 시 발생하는 메모리 단편화</li></ul>|
|개념도|<p align="center">![image](https://user-images.githubusercontent.com/44667299/161752887-19fe0ffb-fec8-46cf-a026-a32361a3483b.png)</p>|
|해결방안|<ul><li>버디 메모리 할당</li><li>통합, 압축</li></ul>|
>버디 메모리 할당(Buddy Memory Allocation) : 요청한 프로세스 크기에 가장 알맞은 크기를 할당하기 위해 메모리를 2n의 크기로 분할하여 메모리를 할당하는 기법  
>통합(Coalescing) : 인접한 단편화 영역을 찾아 하나로 통합하는 기법  
>압축(Compaction) : 메모리의 모든 단편화 영역을 하나로 압축하는 기법
>* 외부 단편화를 해소하기 위한 방법으로 Scattered Holes를 모으는 방법
>* Scattered Holes를 합치는 과정에서 메모리에 적재된 프로세스를 정지시키고 한쪽으로 이동시키는 작업이 필요해 비효율적(작업효율 안좋음)
>* 또한, Scattered Holes를 어느 자유공간을 기준으로 모을지 결정하는 알고리즘도 모호
>![image](https://user-images.githubusercontent.com/44667299/161755506-e046962b-0ec6-47dc-9829-115dab163cf9.png)

* 내부 단편화 : 프로세스가 사용하는 메모리 공간에 포함된 남는 부분. 고정 분할 방식에서 프로세스가 실제 사용해야할 메모리보다 더 큰 메모리를 할당받아 메모리가 낭비되는 현상. 요구된 메모리 보다 약간 커서 빈 곳이 쓸모는 없지만 비어있는 상태.

|구분|설명|
|:---:|---|
|개념|<ul><li>분할된 공간에 프로세스를 적재한 후 남은 공간</li><li>고정 분할 할당 방식 또는 페이징 기법 사용 시 발생하는 메모리 단편화</li></ul>|
|개념도|<p align="center">![image](https://user-images.githubusercontent.com/44667299/161756175-539946ca-d956-44fa-96c6-4c2f37803cb8.png)</p>|
|해결방안|<ul><li>Slab Allocator</li><li>통합, 압축</li></ul>|
>Slab Allocator : 페이지 프레임을 할당받아 공간을 작은 크기로 분할하고(캐시집합) 메모리 요청 시 작은 크기로 메모리를 할당/해제하는 동적 메모리 관리 기법

### Paging(페이징) : 고정 크기
하나의 프로세스가 사용하는 메모리 공간이 연속적이어야 한다는 제약을 없애는 메모리 관리 방법. 외부 단편화와 압축 작업을 해소하기 위한 방법. 물리 메모리는 Frame이라는 고정된 크기로 분리되고 논리 메모리(프로세스가 점유하는)는 page라고 불리는 고정 크기 블록으로 분리됨.  
  
페이징을 통해 논리 메모리는 물리 메모리에 저장될 때 연속되어 저장될 필요가 없고 물리 메모리의 남는 프레임에 적절하게 배치됨으로 외부 단편화 해결할 수 있는 장점  
  
하나의 프로세스가 사용하는 공간은 여러 페이지로 나뉘어 관리되고 개별 페이지는 순서에 상관없이 물리 메모리에 있는 프레임에 mapping 되어 저장된다  
  
**단점** : 역으로 내부단편화의 비중이 증가. page에 여유공간이 남게 되는 경우가 많기 때문  

>프레임(Frame) : 물리 메모리를 일정한 크기로 나눈 블록
  
  
페이징 기법 장단점
|장점|단점|
|---|---|
|<ul><li>공유 페이지 이용</li><li>메모리 활용을 통한 다중 처리 프로그래밍 가능</li></ul>|<ul><li>페이징 사상 하드웨어 비용 소요, 속도 저하</li><li>내부 단편화 현상 발생</li></ul>|
  
페이징 기법에서 페이지 크기가 작을 경우와 클 경우 발생하는 현상
|구분|설명|
|:---:|---|
|페이지 크기가 작을 경우 발생 현상|<ul><li>더 많은 페이지 사상 테이블 공간 필요</li><li>내부 단편화는 줄고, 특정한 참조 구역성만을 포함하지 않기 때문에 기억 장치 효율이 좋음</li><li>페이지 정보를 갖는 페이지 맵 테이블의 크기가 커지고, 매핑 속도가 늦어짐</li><li>디스크 접근 횟수가 많아져서 전체 입·출력 시간 증가</li></ul>|
|페이지 크기가 클 경우 발생 현상|<ul><li>테이블의 크기가 작아지므로 주기억 장치의 공간이 절약</li><li>페이지 정보를 갖는 페이지 맵 테이블의 크기가 작아져서 관리가 용이하고, 매핑 속도가 빨라짐</li><li>디스크 접근 횟수가 줄고, 전체적인 입·출력 시간 감소</li><li>페이지 단편화가 증가하고, 이에 따라 기억 공간의 낭비 초래</li></ul>|

### Segmentation(세그멘테이션) : 가변 크기
페이징에서처럼 논리 메모리와 물리 메모리를 같은 크기 블록이 아닌, 서로 다른 크기의 논리적 단위인 세그먼트로 분할함. 내부 단편화 문제를 해소하기 위한 방법  
  
메모리 사용 효율이 개선되고 동적 분할을 통한 오버헤드가 감소함  
  
논리 주소는 세그먼트 번호(s)와 변위(d)로 구성되어 있다. 세그먼트 테이블은 기준(base)(세그먼트의 시작 물리 주소)과 한계(limit)(세그먼트의 길이)를 저장  
  
**단점** : 외부 단편화 문제 해결 불가. 서로 다른 크기의 세그먼트들이 적재되고 제거되다보면 빈 공간이 많은 수의 작은 조각으로 나뉘어 사용하지 못하게 되기 때문  
  
세그먼테이션 기법 장단점
|장점|단점|
|---|---|
|<ul><li>가변적인 데이터 구조와 모듈 처리</li><li>자원의 효율적 이용</li></ul>|<ul><li>외부 단편화 현상 발생</li></ul>|
  
  
**페이징/세그먼테이션 혼용기법**  
* 외부 단편화 및 내부 단편화 최소화를 위하여 세그먼테이션 기법과 페이징 기법을 결합한 페이징/세그먼테이션 기법이 개발되었다.
* 페이징/세그먼테이션 기법은 하나의 세그먼트를 정수 배의 부분 페이지로 다시 분할하는 방식이다.
* 세그먼트가 너무 가변적인 길이이고 때로는 그 크기가 너무 커서 주기억장치에 적재할 수 없는 문제점을 해결하였다.

## 가상 메모리
다중 프로그래밍을 실현하기 위해서는 많은 프로세스들을 동시에 메모리에 올려두어야 한다. 가상메모리는 **프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법**이며, 프로그램이 물리 메모리보다 커도 된다는 장점이 있다.

### 가상 메모리 개발 배경
이전에는 실행되는 코드를 전부 물리 메모리에 올려둬야 했으며, 메모리의 용량 보다 큰 프로그램의 경우엔 실행이 불가능 했음. 여러 프로그램을 동시에 메모리에 올리기 힘든 용량의 한계, 페이지 교체등의 성능 이슈가 발행. 또한, 가끔만 사용되는 코드가 차지하는 메모리들을 확인할 수 있다는 점에서, 불필요하게 전체의 프로그램이 메모리에 올라와 있어야 하는게 아니라는 것을 알 수 있다.  
  
### 프로그램의 일부만 메모리에 올릴 수 있다면?
* 물리 메모리의 크기에 제약 받지 않게 됨
* 더 많은 프로그램들을 동시에 실행할 수 있게 됨. → 응답시간은 유지되고 CPU 이용률과 처리율은 높아짐.
* swap에 필요한 입출력이 줄어들기 때문에 프로그램들이 빠르게 실행됨.

### 가상 메모리가 하는 일
실제 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것으로 정의된다. 따라서 작은 메모리로도 얼마든지 큰 가상 주소 공간을 프로그래머에게 제공할 수 있다.

### 가상 주소 공간
한 프로세스가 메모리에저장되는 논리적은 모습을 가상 메모리에 구현한 공간. 프로세스가 요구하는 메모리 공간을 가상메모리에서 제공함으로써 현재 직접적으로 필요치 않은 메모리 공간은 실제 물리 메모리에 올리지 않는 것으로 물리 메모리 절약이 가능.

### 프로세스간의 페이지 공유
가상 메모리는 …
* 시스템 라이브러리가 여러 프로세스들 사이에 공유될 수 있도록 한다. 각 프로세스들은 공유 라이브러리를 자신의 가상 주소 공간에 두고 사용하는 것처럼 인식하지만, 라이브러리가 올라가있는 물리 메모리 페이지들은 모든 프로세스에 공유되고 있다.
* 프로세스들이 메모리를 공유하는 것을 가능하게 하고, 프로세스들은 공유 메모리를 통해 통신할 수 있다. 이 또한, 각 프로세스들은 각자 자신의 주소 공간처럼 인식하지만, 실제 물리 메모리는 공유되고 있다.
* `fork()`를 통한 프로세스 생성 과정에서 페이지들이 공유되는 것을 가능하게 한다.

### Demand Paging(요구 페이징)
프로그램 실행 시작 시에 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략으로 실행 과정에서 필요해질 때마다 페이징으로 메모리에 올린다. 따라서 한번도 접근되지 않은 페이지의 경우엔 물리 페이지에 올라가지 않는다. 가상 메모리는 대개 페이지로 관리된다.  
  
프로세스 내의 개별 페이지들은 페이저(pager)에 의해 관리되며 이는 프로세스 실행에 실제 필요한 페이지들만 메모리로 읽어오기 때문에 사용되지 않을 페이지를 가져오는 시간과 메모리 낭비를 줄여준다.

### Page fault trap(페이지 부재 트랩)
* 요구 페이징에서는 프로그램에 대한 모든 내용이 물리 메모리에 올라오지 않기 때문에 메모리에 없는 페이지에 접근하려할 때 페이지 부재 트랩이 발생
* 페이지 부재 트랩이 발생하면 원하는 페이지를 저장 장치에서 가져오게 되고, 만약 물리 메모리가 가득 차있는 상태라면 페이지 교체가 이루어짐
* 페이징 하드웨어는 페이지 테이블을 이용한 주소 변환 과정에 무효 비트를 발견하고 운영체제에 트랩을 건다.

페이지 부재 트랩 처리 과정
1. 페이지 부재 트랩 발생
2. 디스크에서 해당 페이지를 찾음
3. 빈 페이지 프레임을 찾음
4. 페이지 교체 알고리즘을 통해 Victim 페이지 선택
5. Victim 페이지를 디스크에 저장
6. 비워진 페이지 프레임에 새 페이지를 읽어옴
7. 사용자 프로세스 재시작

## 페이지 교체
요구 페이징의 내용 처럼 프로그램 실행시 모든 항목이 물리 메모리에 올라오지 않기 때문에 프로세스의 동작에 필요한 페이지를 요청하는과정에서 page fault(페이지의 부재)가 발생하면 원하는 페이지를 보조 기억 장치에서 가져온다. 그러나 만약 물리 메모리가 전부 사용중이라면 페이지의 교체가 필요하다.(또는, 운영체제가 프로세스를 강제 종료하는 방법이 있다.)  
  
기본적인 처리방법은 페이지 부재 트랩 처리 과정과 동일

### FIFO 페이지 교체
선입 선출. 물리 메모리에 올라온 페이지 순으로 페이지 교체시점에 나가게 됨. 큐를 이용해 쉽게 구현이 가능
* 장점 : 쉬운 이해, 프로그래밍
* 단점
  * 오래된 페이지가 항상 불필요하지 않은 정보를 포함하지 않을 수 있음(초기 변수 등)
  * 처음부터 활발하게 사용되는 페이지를 교체해서 페이지의 부재율을 높이는 부작용이 생길 수 있음
  * Belady의 모순 : 페이지를 저장할 수 있는 페이지 프레임의 갯수를 늘려도 오히려 부재가 더 많이 발생하는 모순이 존재

### 최적 페이지 교체(Optimal Page Replacement)
앞으로 가장 오래동안 사용되지 않을 페이지를 찾아 교체하는 것. 모든 알고리즘보다 낮은 페이지 부재율을 보이며 Belady의 모순이 발생하지 않음
* 장점 : 알고리즘 중 가장 낮은 페이지 부재율 보장
* 단점 : 구현이 어려움. 모든 프로세스의 메모리 참조 계획을 미리 파악할 방법이 없기 때문

### LRU 페이지 교체(LRU Page Replacement)
LRU : Least Recently Used  
최적 알고리즘의 근사 알고리즘. 가장 오랫동안 사용되지 않은 페이지를 선택해 교체  
대체로 FIFO보다 우수하고 OPT보다는 그렇지 못하다.

### LFU 페이지 교체(LFU Page Replacement)
LFU : Least Frequently Used  
참조 횟수가 가장 적은 페이지를 선택해 교체. 활발하게 사용되는 페이지는 참조 횟수가 많다는 가정에서 만들어진 알고리즘.
* 어떤 프로세스가 특정 페이지를 집중적으로 사용하다 다른 기능을 사용하게 되면 더 이상 사용하지 않아도 계속 메모리에 머물게 되어 초기 가정에 어긋나는 시점이 발생할 수 있음
* 최적(OPT) 페이지 교체를 제대로 근사하지 못해 잘 쓰이지 않음

### MFU 페이지 교체(MFU Page Replacement)
MFU : Most Frequently Used  
참조 횟수가 가장 작은 페이지가 최근에 메모리에 올라 왔고, 앞으로 계속 사용될 것이라는 가정에 기반  
* 최적(OPT) 페이지 교체를 제대로 근사하지 못해 잘 쓰이지 않음

## 기타 
### 동시성과 병렬성 차이
### 동시성
* 적어도 두 개의 스레드가 진행 중일 때 존재하는 조건이며, 가상 병렬 처리의 한 형태로 시간 분할(time-slicing)을 포함
* ‘동시’라고 이야기 하지만 컴퓨터(코어)는 한번에 하나의 명령어만 처리할 수 있다. 즉, 두개 이상의 알고리즘이 하나의 코어내에서 스레드간에 빠르게 교차되면서 실행되기 때문에 ‘동시’라고 느끼는 것

![image](https://user-images.githubusercontent.com/44667299/161778738-eb58c139-195a-4901-a253-e10890be679e.png)  
그림출처 : https://www.charlezz.com/?p=44646  
위의 그림은 싱글 코어내에서 다중스레드들이 실행되는 동시성을 나타내고 있다. 참고로 Thread A와 Thread B가 교차되며 실행되는 부분을 Context Switching(문맥교환)이라고 한다.

### 병렬성
* 병렬성을 이야기하려면 적어도 2개 이상의 코어가 있어야 한다. 병렬성도 동시성을 의미하지만 동시성과의 차이는 각 코어내의 스레드가 실제로 동시에 명령어를 실행할 수 있음을 말한다.
* 그러므로 두개의 알고리즘이 정확히 같은 시점에 실행될 때 이를 병렬적이라고 말할 수 있다.

### 동시성(Concurrency) vs 병렬성(Parallelism)
|동시성|병렬성|
|---|---|
|동시에 실행되는 것 같이 보이는 것|실제로 동시에 여러 작업이 처리되는 것|
|싱글 코어에서 멀티 쓰레드(Multi thread)를 동작 시키는 방식|멀티 코어에서 멀티 쓰레드(Multi thread)를 동작시키는 방식|
|한번에 많은 것을 처리|한번에 많은 일을 처리|
|논리적인 개념|물리적인 개념|
  
![image](https://user-images.githubusercontent.com/44667299/161779950-6f526491-adc9-4a28-b9e4-191ebe991fcf.png)  
  
싱글 코어와 멀티 코어에서 동작하는 모습을 비교하는 그림  
![image](https://user-images.githubusercontent.com/44667299/161780076-6f7e6cc8-766d-49c0-a889-24d2dc4d69c7.png)  
싱글 코어에서는 2개의 작업을 동시에 실행되는 것 처럼 보이기 위해 번갈아 가면서 작업을 수행. 다른 작업으로 바꾸어 실행할 때 내부적으로 Context switch가 일어남  
  
그림출처 : https://seamless.tistory.com/42  
  
**결론**  
동시성과 병렬성을 차이를 구분할 수 있어야 CPU 바운딩 또는 IO 바운딩 상황에서 소프트웨어를 어떻게 구현해야 성능을 끌어 올릴 수 있는지에 대해 판단 할 수 있을 것
>CPU 바운드
>* 프로세스 진행 속도가 CPU 속도에 의해 제한됨을 의미
>* 계산에 더 많은 시간을 소비하며 I/O 요청을 자주 생성하지 않음

>I/O 바운드
>* 프로세스가 진행되는 속도가 I/O 하위 시스템의 속도에 의해 제한됨을 의미
>* 계산보다 I/O에 더 많은 시간을 소비

### 은행원 알고리즘
내(은행) 돈을 특정 한 사람한테 다 줬을 때 상환할 수 있다면 안정
* 운영체제는 안전상태를 유지할 수 있는 요구만을 수락하고 불안전 상태를 초래할 사용자의 요구는 나중에 만족될 수 있을 때 까지 계속 거절
* 사용자 프로세스는 사전에 자기 작업에 필요한 자원의 수를 제시하고 운영체제가 자원의 상태를 감시, 안정상태일 때만 자원을 할당하는 교착상태 회피기법

> 안전상태(Safe State) : 시스템이 교착상태를 일으키지 않으면서 각 프로세스가 요구한 최대 요구량만큼 필요한 자원을 할당해 줄 수 있는 상태로 안전순서열이 존재하는 상태  
> 불안전상태(Unsafe State) : 안전순서열이 존재하지 않는 상태. 불안전상태는 교착상태이기 위한 필요조건 → 교착상태는 불안전상태에서만 발생. Unsafe state라 해서 무조건 교착상태가 발생하는 것은 아님

은행원 알고리즘에 필요한 것  
1. MAX : 각 프로세스가 자원을 최대로 얼마까지 요청할 수 있는지
2. Allocated : 각 프로세스가 현재 보유하고 있는 자원이 얼마인지
3. Available : 시스템이 자원을 얼마나 보유하고 있는지

### 캐시 메모리
속도가 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리  
  
CPU가 주기억장치에서 저장된 데이터를 읽어올 때, 자주 사용하는 데이터를 캐시 메모리에 저장한 뒤, 다음에 이용할 때 주기억장치가 아닌 캐시 메모리에서 먼저 가져오면서 속도를 향상시킨다.  
  
속도라는 장점을 얻지만, 용량이 적기도 하고 비용이 비싼 점이 있다.  

<br/>

CPU에는 이러한 캐시 메모리가 2~3개 정도 사용된다.  
![image](https://user-images.githubusercontent.com/44667299/163169601-1a6efe1f-9a32-4629-b4d8-0e8a4e6f7c7c.png)  
작업 관리자 - 성능 - CPU  
  
속도와 크기에 따라 분류한 것으로, 일반적으로 L1 캐시부터 먼저 사용된다.(CPU에서 가장 빠르게 접근하고, 여기서 데이터를 찾지 못하면 L2로 감)
* L1 : CPU 내부에 존재
* L2 : CPU와 RAM 사이에 존재
* L3 : 보통 메인보드에 존재한다고 함
>캐시 메모리 크기가 작은 이유는, SRAM 가격이 매우 비쌈

<br/>

**캐시 메모리 작동 원리**
* 시간 지역성
  * for나 while 같은 반복문에 사용하는 조건 변수처럼 한번 참조된 데이터는 잠시후 또 참조될 가능성이 높음
* 공간 지역성
  * A[0], A[1]과 같은 연속 접근 시, 참조된 데이터 근처에 있는 데이터가 잠시후 또 사용될 가능성이 높음

<br/>

**캐시 미스 경우 3가지**
* Cold miss
  * 해당 메모리 주소를 처음 불러서 나는 미스
* Conflict miss
  * 캐시 메모리에 A와 B 데이터를 저장해야 하는데, A와 B가 같은 캐시 메모리 주소에 할당되어 있어서 나는 미스(direct mapped cache에서 많이 발생)
* Capacity miss
  * 캐시 메모리의 공간이 부족해서 나는 미스 (Conflict는 주소 할당 문제, Capacity는 공간 문제)

캐시 크기를 키워서 문제를 해결하려하면, 캐시 접근속도가 느려지고 파워를 많이 먹는 단점이 생김

### 메시지 브로커
Publisher(송신자)로부터 전달받은 메시지를 Subscriber(수신자)로 전달해주는 중간 역할이며 응용 소프트웨어 간에 메시지를 교환할 수 있게 한다. 이 때 메시지가 적재되는 공간을 Message Queue(메세지 큐)라고 하며 메시지의 그룹을 Topic(토픽)이라고 한다.  
  
예를 들어 설명해보자. DW, AS라는 두 개의 서버가 있다. DW는 실시간으로 데이터를 수집하고 관리하는 서버이고, AS는 이 데이터를 가공하여 사용하는 서버이다. AS에서 DW에 있는 데이터를 사용하기위해서 어떻게 해야할까?  
  
가장 일반적인 방법은 DW에서 Oracle, MySQL과 같은 RDB에 적재하고, AS에서는 이 DB에서 조회해서 쓰는 것이다. 그러나, 실시간으로 처리하기 위해서는 최신의 데이터만 빠르게 조회를 해야하는데, 실시간으로 데이터가 계속 쌓이는 TABLE을 빠르게 조회하는 것은 힘들다. 조회 성능을 높이기위해 테이블에 INDEX를 걸면 INSERT 속도가 느려지므로 실시간 처리에는 적합하지 않다.  
  
메시지 브로커를 사용하는 방법은 어떨까? DW에서는 수집한 데이터를 바로 메세지 큐에 Publish(출판, 적재)하고 AS는 메시지를 Subscribe(구독, 소비)하여 바로 사용하게 된다. 메시지 브로커를 사용하면 AS에서는 별도의 조회과정이 필요없이, 메세지 큐에 적재되는 메시지를 감시하고 있다가 메시지가 적재되면 바로 가져다가 사용할 수 있다.  
  
이처럼 메시지 브로커는 송신자가 보낸 메시지를 메시지 큐에 적재하고 이를 수신자가 받아서 사용하는 구조이다. 이러한 구조를 Pulibsh/Subscribe(pub/sub) Pattern이라고 하며, Producer/Consumer Pattern 이라고도 한다.  
  
메시지 브로커는 대표적으로 Apache Kafka, Redis, RabbitMQ, Celery 등이 있다.  
  
**단점**  
실시간 데이터를 처리할 때 DB에서 조회하는 것보다 메시지 브로커를 이용하여 처리하는 것이 성능이 뛰어나다는 것을 알 수 있는데 단점도 존재한다. DB를 사용하는 경우 Query를 이용하여 원하는 데이터만 필터링하여 조회할 수 있지만, 메시지 브로커를 이용하면 Queue에 적재된 그대로 사용하기 때문에 불가능하다. 따라서, 적재할 때 필터링된 데이터를 적재하던가 적재된 데이터를 Logstash를 이용하여 필터링해서 사용해야 한다. 또한, 메시지 큐에 적재된 메시지는 주로 7일을 보관하기 때문에 장기간 보관해야하는 경우 별도의 저장소에 저장해야한다.  
  
출처 : https://heodolf.tistory.com/49

# 운영체제(OS)
## 프로세스(Process)
### 1. 프로그램 vs 프로세스
|프로그램|프로세스|
|:---:|:---:|
|저장장치에 저장되어 있는 정적인 상태|실행을 위해 메모리에 올라온 동적인 상태|
|"짠다", "작성한다"|"실행한다"|
|프로그램 + 프로세스 제어 블록|프로세스 - 프로세스 제어 블록|

> 프로그램 : 컴퓨터에서 실행될 때 특정 작업을 수행하는 일련의 명령어들의 모음(집합)<br>
> 프로세스 : 컴퓨터에서 연속적으로 실행되고 있는 컴퓨터 프로그램<br>
> 프로세스 제어 블록 : 특정한 프로세스를 관리할 필요가 있는 정보를 포함하는 운영체제 커널의 자료구조<br>
> 커널 : 운영체제의 주요 구성 요소이며 컴퓨터 하드웨어와 프로세스를 잇는 핵심 인터페이스

### 2. 프로세스 구조
|영역|설명|
|:---:|:---:|
|코드 영역|<ul><li>프로그램의 본문이 기술된 곳으로 텍스트 영역</li></ul><ul><li>읽기 전용</li></ul>|
|데이터 영역|<ul><li>코드가 실행되면서 사용하는 변수나 파일 등의 각종 데이터를 모아놓은 곳</li></ul><ul><li>읽기/쓰기</li></ul>|
|스택 영역|<ul><li>운영체제가 프로세스를 실행하기 위해 부수적으로 필요한 데이터를 모아놓은 곳</li></ul><ul><li>숨김 영역</li></ul>|

### 3. 프로세스 활성 상태(Active Status)

<ul><li>생성 상태</li></ul>

```
생성 상태(Create Status)는 프로그램이 메모리에 올라오고 운영체제로부터 프로세스 제어블록을 할당받은 상태이다. 
생성된 프로세스는 바로 실행되는 것이 아니라 준비 상태에서 자기 순서를 기다리며, 프로세스 제어 블록도 같이 준비 상태로 옮겨진다.
```

<ul><li>준비 상태</li></ul>

```
준비 상태(Ready Status)는 실행 대기 중인 모든 프로세스가 자기 순서를 기다리는 상태이다. 
프로세스 제어 블록은 준비 큐(Ready Queue)에서 기다리며 CPU 스케줄러에 의해 관리된다. 
CPU 스케줄러는 준비 상태에서 큐를 몇 개 운영할지, 큐에 있는 어떤 프로세스의 프로세스 제어 블록을 실행 상태로 보낼지를 결정한다.
실제로는 다수의 준비 큐가 운영된다.
```

<ul><li>실행 상태</li></ul>

```
실행 상태(Running Status)는 프로세스가 CPU를 할당받아 실행되는 상태이다.
준비 상태에 있는 많은 프로세스 중 실행 상태에 들어가는 프로세스는 CPU의 개수 만큼이다.
실행 상태에 있는 프로세스는 자신에게 주어진 시간, 즉 타임 슬라이스 동안만 작업할 수 있다.
그 시간을 다 사용하면 timeout(PID)가 실행된다.
timeout(PID)는 프로세스 제어 블록을 실행 상태에서 준비 상태로 옮긴다.
만약 실행 상태 동안 작업이 완료되면 exit(PID)가 실행되어 프로세스가 정상 종료된다.
실행 상태에 있는 프로세스가 입출력을 요청하면 CPU는 입출력 관리자에게 입출력을 요청하고 block(PID)를 실행한다.
block(PID)는 입출력이 완료될 때까지 작업을 진행할 수 없기 때무에 해당 프로세스를 대기 상태로 옮긴다.
CPU 스케줄러는 새로운 프로세스를 실행 상태로 가져온다(dispatch)
```

<ul><li>대기 상태</li></ul>

```
대기 상태(Blocking Status)는 실행 상태에 있는 프로세스가 입출력을 요청하면 입출력이 완료될 때까지 기다리는 상태로 'wait status'라고도 한다.
대기 상태는 작업의 효율을 위해 만들어진 것으로, 대기 상태의 프로세스는 입출력장치별로 마련된 큐에서 기다린다.
입출력이 완료되면 인터럽트가 발생하고, 대기 상태에 있는 여러 프로세스 중 해당 인터럽트로 깨어날 프로세스를 찾는데 이것이 wakeup(PID)이다.
wakeup(PID)로 해당 프로세스의 프로세스 제어 블록이 준비 상태로 이동하게 된다.
어떤 프로세스가 대기 상태에서 준비 상태로 이동하는 것은 인터럽트 때문이다.
인터럽트는 입출력으로 발생하지만 어떤 이벤트에 의해 발생하기도 한다.
```

<ul><li>완료 상태</li></ul>

```
완료 상태(Terminate Status)는 프로세스가 종료되는 상태이다.
완료 상태에서는 코드와 사용했던 데이터를 메모리에서 삭제하고 프로세스 제어 블록을 폐기한다.
정상적인 종료는 간단히 exit()로 처리한다.
만약 오류나 다른 프로세스에 의해 비정상적으로 종료되는 강제종료(abort)를 만나면 디버깅하기 위해 강제 종료 직전의 메모리 상태를 저장장치로 옮기는데,
이를 코어 덤프(core dump)라고 한다.
코어 덤프는 종료 직전의 메모리 상태를 확인함으로써 오류를 수정할 수 있게 해준다.
```

### 4. 프로세스 휴식 상태와 보류 
<ul><li>휴식 상태</li></ul>

```
휴식 상태(Pause Status)는 프로세스가 작업을 일시적으로 쉬고 있는 상태이다.
```

<ul><li>보류 상태</li></ul>

```
보류 상태(Suspend Status)는 프로세스가 메모리에서 잠시 쫓겨난 상태로 휴식 상태와 차이가 있다.
보류 상태는 '일시 정지 상태'라고도 불리며, 보류 상태와 비교하여 일반적인 프로세스 상태를 활성 상태라고 한다.
보류 상태에 들어간 프로세스는 메모리 밖으로 쫓겨나 스왑 영역(swap area)에 보관된다.
스왑 영역은 메모리에서 쫓겨난 데이터가 임시로 보간되는 곳이다.
보류 상태와 휴식 상태를 구분하자면, 보류 상태는 스왑 영역에 있는 상태에고 휴식 상태는 프로세스가 메모리에 있으나 멈춘 상태이다.
```

### 5. 프로세스의 다섯 가지 상태 정리
<picture>
  <img alt="process 5state" src="https://blog.kakaocdn.net/dn/bf4d6d/btq1NuS4831/dbvf4a9ah1kXaLugrMhrNK/img.png">
</picture>

|상태|설명|작업|
|:---:|:---:|:---:|
|생성 상태|<ul><li>프로그램을 메모리에 가져와 실행 준비가 완료된 상태</li></ul>|메모리 할당, 프로세스 제어 블록 생성|
|준비 상태|<ul><li>실행을 기다리는 모든 프로세스가 자기 차례를 기다리는 상태</li></ul><ul><li>실행될 프로세스를 CPU 스케줄러가 선택</li></ul>|dispatch(PID) : 준비 -> 실행|
|실행 상태|<ul><li>선택된 프로세스가 타임 슬라이스를 얻어 CPU를 사용하는 상태</li></ul><ul><li>프로세스 사이의 문맥 교환이 일어남</li></ul>|timeout(PID) : 실행 -> 준비<br>exit(PID) : 실행 -> 완료<br>block(PID) : 실행 -> 대기|
|대기 상태|<ul><li>실행 상태에 있는 프로세스가 입출력을 요청하면 입출력이 완료될 때까지 기다리는 상태</li></ul><ul><li>입출력이 완료되면 준비 상태로 감</li></ul>|wakeup(PID) : 대기 -> 준비|
|완료 상태|<ul><li>프로세스가 종료된 상태</li></ul><ul><li>사용하던 모든 데이터가 정리됨</li></ul><ul><li>정상 종료인 exit와 비정상 종료인 abort를 포함</li></ul>|메모리삭제, 프로세스 제어 블록 삭제|

### 6. 프로세스 제어 블록(PCB) 

```
프로세스 제어 블록(PCB)은 프로세스를 실행하는 데 필요한 중요한 정보를 보관하는 자료 구조로 TCB(Task Control Block)라고도 한다.
모든 프로세스는 고유의 프로세스 제어 블록을 가지며, 프로세스 제어 블록은 프로세스 생성 시 만들어져서 프로세스가 실행을 완료하면 폐기된다.
```

### 6-1. 프로세스 제어 블록의 구성
<picture>
  <img src="구성도" src="https://blog.kakaocdn.net/dn/cjrby0/btqIarikobp/wPTdGGKemxiT7XkXXEBdQ0/img.png">
</picture>

|구성 요소|설명|
|:---:|:---:|
|포인터|<ul><li>프로세스 제어 블록의 첫 번째 블록에는 포인터가 저장됨</li></ul><ul><li>준비 상태나 대기 상태는 큐로 운영되는데, 프로세스 제어 블록을 연결하여 준비 상태나 대기 상태의 큐를 구현할 때 포인터를 사용</li></ul>|
|프로세스 상태|<ul><li>프로세스가 현재 어떤 상태에 있는지 나타냄</li></ul><ul><li>프로세스 제어 블록의 두 번째 블록에 저장됨</li></ul>|
|프로세스 구분자|<ul><li>운영체제 내에 있는 여러 프로세스를 구별하기 위한 구분자를 저장</li></ul>|
|프로그램 카운터|<ul><li>다음에 실행될 명령어의 위치를 가리키는 프로그램 카운터의 값을 저장</li></ul>|
|프로세스 우선순위|<ul><li>높은 우선순위의 프로세스가 낮은 우선순위의 프로세스보다 먼저 실행되고 더 자주 실행되는데, 그 우선순위를 저장</li></ul>|
|각종 레지스터 정보|<ul><li>프로세스가 실행되는 중에 사용하던 레지스터(누산기, 색인 레지스터, 스택 포인터 등)의 값을 저장</li></ul><ul><li>이전에 실행할 때 사용한 레지스터의 값을 보관해야 다음에 실행할 수 있기 때문에 자신이 사용하던 레지스터의 중간값을 보관</li></ul>|
|메모리 관리 정보|<ul><li>메모리 위치 정보(프로세스가 메모리의 어디에 있는지 나타냄), 경계 레지스터 값과 한계 레지스터 값(메모리 보호를 위해 사용) 등을 저장</li></ul><ul><li>세그먼테이션 테이블, 페이지 테이블 등의 정보도 보관</li></ul>|
|할당된 자원 정보|<ul><li>프로세스를 실행하기 위해 사용하는 입출력 자원이나 오픈 파일 등에 대한 정보 저장</li></ul>|
|계정 정보|<ul><li>계정 번호, CPU 할당 시간, CPU 사용 시간 등의 정보를 저장</li></ul>|
|부모 프로세스 구분자와 자식 프로세스 구분자|<ul><li>PPID, CPID 정보를 저장</li></ul><ul><li>부모 - 자식 프로세스의 관계는 프로세스를 이해하는데 매우 중요</li></ul>|

> 세그먼테이션 테이블, 페이지 테이블은 뒤에서 다시 다룸

## 스레드(Thread)
### 1. 스레드란?

<picture>
  <img src="스레드" src="https://blog.kakaocdn.net/dn/cjrby0/btqIarikobp/wPTdGGKemxiT7XkXXEBdQ0/img.png">
</picture>

```
프로세스의 코드에 정의 절차에 따라 CPU에 작업 요청을 하는 실행 단위
```

* 특징
  * 스레드는 프로세스 내에서 각각 Stack만 따로 할당받고 Code, Data, Heap 영역은 공유
  * 스레드는 한 프로세스 내에서 동작되는 여러 실행의 흐름으로, 프로세스 내의 주소 공간이나 자원들(힙 공간 등)을 같은 프로세스 내에 스레드끼리 공유하면서 실행
  * 같은 프로세스 안에 있는 여러 스레드들은 같은 힙 공간을 공유 / 프로세스는 다른 프로세스의 메모리에 직접 접근 X
  * 각각의 스레드는 별도의 레지스터와 스택을 갖고 있지만, 힙 메모리는 서로 읽고 쓸 수 있음
  * 한 스레드가 프로세스 자원을 변경하면, 다른 이웃 스레드도 그 변경 결과를 즉시 볼 수 있음

### 2. 스택을 스레드마다 독립적으로 할당하는 이유

```
스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는것 -> 독립적인 실행 흐름이 추가되는 것
스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소조건으로 독립된 스택을 할당
```

### 3. PC Register를 스레드마다 독립적으로 할당하는 이유

```
스레드는 CPU를 할당받았다가 스케줄러에 의해 다시 선점당함
명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있음
따라서 PC Register를 독립적으로 할당
```

## 멀티 스레드
### 1. 헷갈리기 쉬운 스레드 관련 용어 정리
|스레드 용어|설명|
|:---:|:---:|
|멀티스레드|<ul><li>운영체제가 소프트웨어적으로 프로세스 내 작업을 여러 개의 스레드로 분할함으로써 작업의 부담을 줄이는 프로세스 운영 기법</li></ul>|
|멀티태스킹|<ul><li>운영체제가 CPU에 작업을 줄 때 시간을 잘게 나누어 배분하는 기법</li></ul><ul><li>여러 스레드에 시간을 잘게 나누어주는 시스템을 시분할 시스템(time-sharing system)이고 CPU에 전달하는 작업은 스레드</li></ul>|
|멀티프로세싱|<ul><li>하나의 응용프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 하나의 작업(Task)을 처리하도록 하는 것</li></ul><ul><li>CPU를 여러 개 사용하여 여러 개의 스레드를 동시에 처리하는 작업 환경</li></ul><ul><li>하나의 컴퓨터에 여러 개의 CPU, 하나의 CPU 내 여러 개의 코어에 스레드 배정, 네트워크로 연결된 여러 컴퓨터에 스레드를 나누어 협업하는 분산시스템 => 멀티프로세싱</li></ul>|
|CPU 멀티스레드|<ul><li>하드웨어적인 방법으로 하나의 CPU에서 여러 스레드를 동시에 처리하는 병렬 처리 기법</li></ul>|

### 2. 멀티 스레딩의 장점

```
프로세스는 크게 정적인 영역과 동적인 영역으로 구분된다. 
여러 개의 프로세스를 만들면 필요없는 정적 영역이 여러 개가 된다. 
이 문제를 해결하기 위해 하나의 프로세스 내에 여러 개의 스레드를 생성하는 멀티스레드는 
코드, 파일 등의 자원을 공유함으로써 자원의 낭비를 막고 효율성을 향상한다.
```

<picture>
  <img src="멀티스레드" src="https://jaeseongdev.github.io/assets/img/posts/development-os/2021-06-16-%EB%A9%80%ED%8B%B0%EC%8A%A4%EB%A0%88%EB%93%9C%2C%20%EB%A9%80%ED%8B%B0%EC%93%B0%EB%A0%88%EB%93%9C%20%3A%20%20%EB%A9%80%ED%8B%B0%20%ED%83%9C%EC%8A%A4%ED%82%B9%20%3A%20%EB%A9%80%ED%8B%B0%20%ED%94%84%EB%A1%9C%EC%84%B8%EC%8B%B1%20%3A%20%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80%20%EC%8A%A4%EB%A0%88%EB%93%9C%EC%9D%98%20%EC%B0%A8%EC%9D%B4/Untitled.png">
</picture>

|멀티 스레딩의 장점|설명|
|:---:|:---:|
|응답성 향상|<ul><li>한 스레드가 입출력으로 인해 작업이 진행되지 않더라도 다른 스레드가 작업을 계속하여 사용자의 작업 요구에 빨리 응답할 수 있음</li></ul>|
|자원 공유|<ul><li>한 프로세스 내에서 독립적인 스레드를 생성하면 프로세스가 가진 자원을 모든 스레드가 공유하게 되어 작업을 원활하게 진행할 수 있음</li></ul>|
|효율성 향상|<ul><li>여러 개의 프로세스를 생성하는 것과 달리 불필요한 자원의 중복을 막음으로써 시스템의 효율이 향상됨</li></ul>|
|다중 CPU 지원|<ul><li>2개 이상의 CPU를 가진 컴퓨터에서 사용하면 다중 CPU가 멀티스레드를 동시에 처리하여 CPU 사용량이 증가하고 프로세스의 처리 시간이 단축됨</li></ul>|

### 3. 멀티스레딩의 문제점
* 주의 깊은 설계가 필요함
* 디버깅이 까다로움
* 단일 프로세스 시스템의 경우 효과를 기대하기 어려움
* 다른 프로세스에서 스레드를 제어할 수 없음(즉, 프로세스 밖에서 스레드 각각을 제어할 수 없음)
* 멀티 스레드의 경우 자원 공유의 문제가 발생(동기화 문제)
* 하나의 스레드에 문제가 발생하면 전체 프로세스가 영향을 받음

> 이해하기 쉬운 예 : 인터넷 익스플로어(멀티 스레드) vs 크롬(멀티 태스킹)
> 
> 인터넷 익스플로어는 하나의 탭이 문제 생기면 익스플로어 자체가 종료됨
> 
> 크롬은 하나의 탭이 문제 생겨도 문제 있는 탭만 종료할 수 있음
> 
### 4. 멀티 프로세스의 장점
* 여러 개의 자식 프로세스 중 하나에 문제가 발생하면 그 자식 프로세스만 죽은 것 이상으로 다른 영향이 확산되지 않음

### 5. 멀티 프로세스의 문제점
|멀티 프로세스의 문제점|설명|
|:---:|:---:|
|Context Switching(문맥 교환)에서의 오버헤드|<ul><li>Context Switching 과정에서 캐시 메모리 초기화 등 무거운 작업이 진행되고 많은 시간이 소모되는 등의 오버헤드가 발생하게 됨</li></ul><ul><li>프로세스는 각각의 독립된 메모리 영역을 할당받았기 때문에 프로세스 사이에서 공유하는 메모리가 없어, Context Switching이 발생하면 캐시에 있는 모든 데이터를 모두 리셋하고 다시 캐시 정보를 불러와야 함</li></ul>|
|프로세스 사이의 어렵고 복잡한 통신 기법(IPC)|<ul><li>프로세스는 각각의 독립된 메모리 영역을 할당받았기 때문에 하나의 프로그램에 속하는 포르세스들 사이의 변수를 공유할 수 없음</li></ul>|

### 6. 멀티 스레드 vs 멀티 프로세스
|멀티 스레드|멀티 프로세스|
|:---:|:---:|
|적은 메모리 공간 차지 -> Context Switching 빠름|비교적 많은 메모리 공간 차지 -> Context Switching 느림|
|하나의 스레드 장애로 전체 스레드가 종료될 위험|하나의 스레드 장애로 전체 스레드가 종료될 위험 X|

* 멀티 프로세스로 할 수 있는 작업들을 하나의 프로세스에서 스레드로 나눠가며 하는 이유
  * 운영체제가 시스템 자원을 효율적으로 관리하기 위해 스레드를 사용
  * 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리 가능
  * 프로세스 간의 통신보다 스레드 간의 통신 비용이 적기 때문에 작업들 간 통신의 부단이 줄어듬(프로세스는 독립구조 -> 처리비용 감소)

## 스케줄러
### 1. 장기 스케줄러
* 시스템 내의 전체 작업 수를 조절하는 스케줄러 -> 풀(pool)로부터 프로세스들을 선별하고 실행을 위해 메모리에 적재
* 어떤 작업(운영체제에서 다르는 일의 가장 큰 단위로, 1개 또는 여러 개의 프로세스로 이루어짐)을 시스템이 받아들일지 또는 거불할지를 결정
* 장기 스케줄러에 의해 시스탬 내에서 동시에 실행 가능한 프로세스의 총 개수가 정해짐
* 고수준 스케줄러, 작업 스케줄러, 승인 스케줄러, CPU 스케줄러과 같은 의미

### 2. 단기 스케줄러
* 어떤 프로세스에 CPU를 할당할지, 어떤 프로세스를 대기 상태로 보낼지 등을 결정 -> 실행이 준비된 프로세스들 중 하나를 선별해 CPU에 할당
* 프로세스 상태에 관한 내용은 대부분 여기에 해당
* 저수준 스케줄링과 같은 의미

### 3. 중기 스케줄러
* 중지(suspend, 보류상태로 넘어감)와 활성화(active)로 전체 시스템의 활성화된 프로세스 수를 조절하여 과부하를 막음
* Swapper, 중간 수준 스케줄링과 같은 의미

## CPU 스케줄러
### 1. 선점형 & 비선점형
* 선점형 스케줄링 : 어떤 프로세스가 CPU를 할당받아 실행 중이더라도 운영체제가 CPU를 강제로 빼앗을 수 있는 스케줄링 방식
* 비선점형 스케줄링 : 어떤 프로세스가 CPU를 점유하면 다른 프로세스가 이를 빼앗을 수 없는 스케줄링 방식

|구분|종류|
|:---:|:---:|
|비선점형 알고리즘|FCFS 스케줄링, SJF 스케줄링, HRN 스케줄링|
|선점형 알고리즘|Round Robin 스케줄링, SRT 스케줄링, 다단계 큐 스케줄링, 다단계 피드백 큐 스케줄링|
|둘 다 가능|우선순위 스케줄링|

### 2. FCFS(First Come First Served)

```
준비 큐에 도착한 순서대로 CPU를 할당하는 비선점형 방식으로, 선입선출 스케줄링이라고도 한다.
```

<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-56.png">
</picture>
<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-57.png">
</picture>
<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-58-768x257.png">
</picture>

* 장점
  * 단순하고 공평함

* 단점
  * 처리 시간이 긴 프로세스가 CPU를 차지하면 다른 프로세스들은 하엽없이 기다려 시스템의 효율성이 떨어지는 문제 발생 => 콘보이 효과 or 호위 효과
  * 현재 작업 중인 프로세스가 입출력 작업을 요청하는 경우 CPU가 작업하지 않고 쉬는 시간이 많아져 작업 효율이 떨어짐

### 3. SJF(Shortest - Job - First)

```
준비 큐에 있는 프로세스 중에서 실행 시간이 가장 짧은 작업부터 CPU를 할당하는 비선점형 방식으로, 최단 작업 우선 스케줄링이라고도 한다.
```

> FCFS 스케줄링의 콘보이 효과를 완화하여 시스템의 효율성을 높인 것<br>
> SPF(Shortest Process First), 최단 프로세스 우선 스케줄링과 같은 말

<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-60.png">
</picture><br>
<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-61.png">
</picture><br>
<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-63.png">
</picture>

* 장점
  * 작은 작업을 먼저 실행하기 때문에 시스템의 효율성이 좋아짐

* 단점
  * 운영체제가 프로세스 종료 시간을 정확하게 예측하기 어려움
    - 현대의 프로세스는 사용자와의 상호작용이 빈번하게 발생하기 때문
  * 공평하지 않음
    - 먼저 도착해도 늦게 실행되는 프로세스가 있음
    - 작업이 계속 연기되는 현상 발생 => 아사현상(starvation) or 무한 봉쇄 현상(infinite blocking) 발생

* 단점 해결책
  * 프로세스가 자신의 작업 시간을 운영체제에 알려주어 해결
    - 프로세스가 자신의 작업 시간을 정확히 알기 어려움
    - 일부 악의적인 프로세스가 작업 시간을 속인다면 시스템의 효율성이 나빠짐
  * 에이징(나이먹기, aging)으로 완화할 수 있음
    - 프로세스가 양보할 수 있는 상한선을 정하는 방식
    - 에이징 값을 어떤 기준으로 정할 것인지가 문제

### 4. SRTF(Shortest Remaining Time First)

```
선점형 SJF 스케줄링 개념이다.
```

<picture>
  <img src="https://blog.kakaocdn.net/dn/47cG3/btqF63ctwKv/99wazY0GKJGkY5jUxCMoRk/img.png">
</picture>

* 단점
  * 아사현상(starvation)이 발생

### 5. Priority Scheduling

```
프로세스는 중요도에 따라 우선순위(Priority)를 갖는데 이러한 우선순위를 반영한 스케줄링 알고리즘
```

* 고정 & 변동
  * 고정 우선순위 알고리즘 
    - 한 번 우선순위를 부여받으면 종료될 때까지 우선순위가 고정됨
    - 단순하게 구현할 수 있지만 시시각각 변하는 시스템의 상황을 반영하지 못해 효율성이 떨어짐
  * 변동 우선순위 알고리즘 
    - 일정 시간마다 우선순위 변함
    - 일정 시간마다 우선순위를 새로 계산하고 이를 반영하기 때문에 시스템이 복잡하지만 시스템의 상황을 반영하여 효율적인 운영이 가능

* 적용 예시
  * (비선점형 방식)SJF 스케줄링 : 작업 시간이 짧은 프로세스에 높은 우선순위를 부여함
  * (비선점형 방식)HRN 스케줄링 : 작업 시간이 짧거나 대기 시간이 긴 프로세스에 높은 우선순위를 부여함
  * (선점형 방식)SRT 스케줄링 : 남은 시간이 짧은 프로세스에 높은 우선순위를 부여함

* 평가
  * 준비 큐에 있는 프로세스의 순서를 무시하고 우선순위가 높은 프로세스에 먼저 CPU를 할당 -> 공평성을 위배하고 아사 현상을 일으킴
  * 준비 큐에 있는 프로세스의 순서를 무시하고 프로세스의 우선순위를 매번 바꿔야 함 -> 오버헤드가 발생하여 시스템의 효율성을 떨어뜨림
  * 우선순위는 시스템의 효율성 보다 프로세스의 중요도에 따라 정해짐

### 6. Round Robin

```
한 프로세스가 할당받은 시간(타임 슬라이스)동안 작업을 하다가 작업을 완료하지 못하면 준비 큐의 맨 뒤로 가서 자기 차례를 기다리는 방식
선점형 알고리즘 중 가장 단순하고 대표적인 방식으로, 프로세스들이 작업을 완료할 때까지 계속 순환하면서 실행
```
> FCFS 스케줄링과 유사한데, 각 프로세스마다 CPU를 사용할 수 있는 최대 시간, 즉 타임 슬라이스 존재

<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-72.png">
</picture><br>
<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-73.png">
</picture><br>
<picture>
  <img src="https://shacoding.com/wp-content/uploads/2022/04/image-74.png">
</picture>

* 장점
  * 프로세스가 CPU를 일정 시간 동안 사용한 후 다른 프로세스에 주어야 하기 때문에 콘베이 효과가 줄어듬

* 단점
  * 타임 슬라이스가 큰 경우
    - FCFS 스케줄링과 다를 게 없음
  * 타임 슬라이스가 작은 경우
    - 문맥 교환이 너무 자주 일어나 시스템의 전반적인 성능이 떨어짐

* 타임 슬라이스는 되도록 작게 설정하되 문맥 교환에 걸리는 시간을 고려하여 적당한 크기로 하는 것이 중요

## 동기(Synchronous)와 비동기(Asynchronous) 및 Blocking 과 Non-Blocking
Synchronous와 Asynchronous는 **작업을 수행하는 주체에 대한 관점**<br>Blocking과 Non-Blocking은 **제어권이 어디에 있느냐에 대한 관점**
### 1. 동기(Synchronous)

```
두 개 이상의 주체가 작업 시간을 똑같이 맞출 때
답변을 기다리는 것
```

<picture>
  <img src="https://velog.velcdn.com/images%2Fguswns3371%2Fpost%2F1e696752-5f8c-43b2-8cf4-4cc513762189%2Fimage.png">
</picture>

> A가 끝나는 시간과 B가 시작하는 시간을 맞추면 Synchronous(동기)<br>
> ex) JAVA - synchronized, BlockingQueue

<picture>
  <img src="https://velog.velcdn.com/images%2Fguswns3371%2Fpost%2Fb50808ff-b090-4396-a3fd-4e284908fdde%2Fimage.png">
</picture>

> A와 B가 시작시간 또는 종료시간이 일치하면 Synchronous(동기)<br>
> ex) JAVA - CyclicBarrier

### 2. 비동기(Asynchronous)

```
두 개 이상의 주체가 작업 시간을 서로 맞추지 않을 때
답변을 기다리지 않는 것
```

<picture>
  <img src="https://velog.velcdn.com/images%2Fguswns3371%2Fpost%2F8d93245e-e316-4502-9774-ccae1b752636%2Fimage.png">
</picture>

> 각자 별도의 시작시간, 끝나는 시간을 가지고 있으면 Asynchronous(비동기)<br>
> 두 가지 이상의 대상이 서로 시간을 맞춰 행동하지 않는 것
> 시킨 일을 다 했는지 물어보는 것은 polling

### 3. Blocking

```
직접 제어할 수 없는 대상의 작업이 끝날 때까지 기다려야 하는 경우
```

<picture>
  <img src="https://velog.velcdn.com/images%2Fguswns3371%2Fpost%2Ff87c23bc-2194-4245-8212-6879b975bb2f%2Fimage.png">
</picture>

> 개발 부서 전체 작업의 제어권을 가진 팀장이 엔지니어 A에게 제어권을 넘김<br>
> 엔지니어 A가 작업을 수행할 동안 개발 부서 전체는 이를 기다림<br>
> 엔지니어 A가 작업을 마치고 팀장에게 알리면서 동시에 제어권도 돌려줌<br>
> 제어권이 없는 상태 => **Blocking**이 되며 다른 일을 할 수 없는 상태가 됨

### 4. Non-Blocking

```
직접 제어할 수 없는 대상의 작업이 완료되기 전에 제어권을 넘겨주는 경우
```

<picture>
  <img src="https://velog.velcdn.com/images%2Fguswns3371%2Fpost%2F1ad8b445-869d-49d9-925f-5ef7dd9cff28%2Fimage.png">
</picture>

> 제어권을 바로 팀장에게 돌려주기 때문에 개발 부서는 엔지니어 A의 작업을 기다리지 않음 -> 다른 일을 할 수 있는 상태가 됨

## 동시성 문제
### 1. Critical Section(임계영역)

```
공유 자원 접근 순서에 따라 실행 결과가 달라지는 프로그램의 영역
```

* 프로세스 간에 공유자원을 접근하는 데 있어서 문제가 발생하지 않도록 한 번에 하나의 프로세스만 이용하게끔 **보장**해줘야 하는 영역

> ex) 예금을 확인하고 입금을 한 후 예금을 저장하는 부분

### 1-1. Critical Section(임계 영역) 문제 해결 3가지 조건

* **상호 배제(Mutual exclution)** : 한 프로세스가 임계 영역에 들어가면 다른 프로세스는 임계 여역에 들어갈 수 없다.
* **한정 대기(Bounded wating)** : 어떤 프로세스도 무한 대기(infinite postpone)하지 않아야 한다. 
                         -> 한 번 임계 영역에 들어간 프로세스는 다음번 임계 영역에 들어갈 떄 제한을 두어야 한다.
* **진행의 융통성(Progress)** : 요리사 B는 요리사 A의 작업 속도와 관계없이 믹서가 비어 있으면 언제든 사용 가능 
                      -> 한 프로세스가 다른 프로세스의 진행을 방해해서는 안된다.
                      
### 2. Race Condition(경쟁 상태)

```
공유 자원에 대해 여러 프로세스가 동시에 접근을 시도할 떄, 타이밍이나 순서 등이 결과값에 영향을 줄 수 있는 상태
```

> ex) 프로세스 p1이 예금하고 프로세스 p2가 동시에 예금했을 때 총액의 결과

### 3. Deadlock(교착 상태)

```
2개 이상의 프로세스가 다른 프로세스의 작업이 끝나기만 기다리며 작업을 더 이상 진행하지 못하는 상태
```

> 프로세스가 자원을 사용하는 절차 : Request, Allocate, Use, Release<br>
> Request : 자원을 요청하고, 만약 다른 프로세스가 자원을 사용하고 있어 받을 수 없다면 대기<br>
> Allocate : 자원을 받음<br>
> Use : 프로세스가 받은 자원을 사용<br>
> Release : 프로세스가 자원을 놓아줌<br><br>
> Deadlock은 모든 프로세스가 Request인 상태

🚀 Deadlock vs Starvation

* Deadlock : 여러 프로세스가 작업을 진행하다 보니 자연적으로 일어나는 문제 -> 강압적으로 해결
* Starvation : 운영체제가 잘못된 정책을 사용하여 특정 프로세스의 작업이 지연되는 문제

### 4. Deadlock 발생 조건(필요 충분 조건)

Deadlock이 발생하기 위해선 다음 4가지 조건을 만족해야 한다.

> 자원이 가지는 특징
* **상호 배제** : 한 프로세스가 사용하는 자원은 다른 프로세스와 공유할 수 없는 배타적인 자원이어야 한다.
* **비선점** : 한 프로세스가 사용 중인 자원은 중간에 다른 프로세스가 빼앗을 수 없는 비선점 자원이어야 한다.

> 프로세스의 행위
* **점유와 대기** : 프로세스가 어떤 자원을 할당받은 상태여서 다른 자원을 기다리는 상태여야 한다.
* **원형 대기** : 점유와 대기를 하는 프로세스 간의 관계가 원을 이루어야 한다. -> 사이클이 있다면 Deadlock, 없다면 X

### 5. Deadlock 해결 방법

|해결 방안|특징|
|:---:|:---:|
|교착 상태 예방|교착 상태를 유발하는 네 가지 조건을 무력화|
|교착 상태 회피|교착 상태가 발생하지 않는 수준으로 자원을 할당|
|교착 상태 검출|자원 할당 그래프를 사용하여 교착 상태를 발견|
|교착 상태 회복|교착 상태를 검출한 후 해결|

### 5-1. 교착 상태 예방

* 상호 배제 예방
  - 독점적으로 사용할 수 있는 자원을 없애는 방법
  - 현실적으로는 모든 자원을 공유할 수 없으며 상호 배제를 적용하여 보호해야 하는 자원이 있음
  - 상호 배제를 무력화하는 것은 사실상 어려움
* 비선점 예방
  - 모든 자원을 빼앗을 수 있도록 만드는 방법
  - 임계 영역을 보호하기 위해 잠금을 사용하면 자원을 빼앗을 수 없고 상호 배제도 보장할 수 없음 -> 사실상 모든 자원을 빼앗을 수 없음
  - 어떤 기준으로 빼앗을지, 얼마나 사용할지 결정하기 어려워 아사 현상을 일으킴
  - 에이징을 사용해도 다시 비선점 자원이 되어 다시 교착상태에 빠질 수 있음
* 점유와 대기 예방
  - 프로세스가 자원을 점유한 상태에서 다른 자원을 기다리지 못하게 하는 방법 -> 전부 할당하거나 할당하지 않거나(all or nothing)
  - 자원이 아닌 프로세스의 자원 사용 방식을 변화시켜 해결하는 점에서 의의가 있음

  * 단점
  - 프로세스가 자신이 사용하는 모든 자원을 자세히 알기 어려움 : 추가로 필요한 자원이 생기면 이를 다시 확보하기 어려움
  - 자원의 활용성이 떨어짐 : 당장 사용하지도 않을 자원을 미리 선점하여 자원 낭비가 심함
  - 많은 자원을 사용하는 프로세스가 적은 자원을 사용하는 프로세스보다 불리함
  - 결국 일괄 작업 방식으로 동작함
* 원형 대기 예방
  
